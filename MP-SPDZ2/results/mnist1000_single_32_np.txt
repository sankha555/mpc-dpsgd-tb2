Setting up connection 0
***********************************************************
Training MNIST
Model: Dense([60000, 1, 1000]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 600
Num Epochs: 10
Learning Rate: 0.1 to 1 over 10 epochs
Clipping Factor: 4
Sigma: 8
***********************************************************
Epoch 1.1: Loss = 2.36139
Epoch 1.2: Loss = 2.31517
Epoch 1.3: Loss = 2.28259
Epoch 1.4: Loss = 2.21881
Epoch 1.5: Loss = 2.17357
Epoch 1.6: Loss = 2.13722
Epoch 1.7: Loss = 2.11852
Epoch 1.8: Loss = 2.0858
Epoch 1.9: Loss = 2.02467
Epoch 1.10: Loss = 1.98616
Epoch 1.11: Loss = 1.9418
Epoch 1.12: Loss = 1.91246
Epoch 1.13: Loss = 1.84863
Epoch 1.14: Loss = 1.84247
Epoch 1.15: Loss = 1.77197
Epoch 1.16: Loss = 1.75606
Epoch 1.17: Loss = 1.746
Epoch 1.18: Loss = 1.68669
Epoch 1.19: Loss = 1.67743
Epoch 1.20: Loss = 1.62865
Epoch 1.21: Loss = 1.57594
Epoch 1.22: Loss = 1.5945
Epoch 1.23: Loss = 1.52779
Epoch 1.24: Loss = 1.49319
Epoch 1.25: Loss = 1.4167
Epoch 1.26: Loss = 1.38196
Epoch 1.27: Loss = 1.40224
Epoch 1.28: Loss = 1.38188
Epoch 1.29: Loss = 1.31725
Epoch 1.30: Loss = 1.33658
Epoch 1.31: Loss = 1.24075
Epoch 1.32: Loss = 1.23898
Epoch 1.33: Loss = 1.29897
Epoch 1.34: Loss = 1.14143
Epoch 1.35: Loss = 1.25485
Epoch 1.36: Loss = 1.21342
Epoch 1.37: Loss = 1.15833
Epoch 1.38: Loss = 1.17989
Epoch 1.39: Loss = 1.16634
Epoch 1.40: Loss = 1.10844
Epoch 1.41: Loss = 1.05028
Epoch 1.42: Loss = 1.07492
Epoch 1.43: Loss = 1.14117
Epoch 1.44: Loss = 1.04286
Epoch 1.45: Loss = 1.00186
Epoch 1.46: Loss = 1.00633
Epoch 1.47: Loss = 0.983093
Epoch 1.48: Loss = 0.954132
Epoch 1.49: Loss = 0.966415
Epoch 1.50: Loss = 0.972015
Epoch 1.51: Loss = 0.946365
Epoch 1.52: Loss = 0.935379
Epoch 1.53: Loss = 0.983276
Epoch 1.54: Loss = 0.913834
Epoch 1.55: Loss = 0.990768
Epoch 1.56: Loss = 0.922318
Epoch 1.57: Loss = 0.840897
Epoch 1.58: Loss = 0.852173
Epoch 1.59: Loss = 0.852448
Epoch 1.60: Loss = 0.850159
Epoch 1.61: Loss = 0.78508
Epoch 1.62: Loss = 0.829239
Epoch 1.63: Loss = 0.799942
Epoch 1.64: Loss = 0.786697
Epoch 1.65: Loss = 0.728348
Epoch 1.66: Loss = 0.770096
Epoch 1.67: Loss = 0.787384
Epoch 1.68: Loss = 0.709641
Epoch 1.69: Loss = 0.770905
Epoch 1.70: Loss = 0.713531
Epoch 1.71: Loss = 0.716354
Epoch 1.72: Loss = 0.810181
Epoch 1.73: Loss = 0.732468
Epoch 1.74: Loss = 0.739883
Epoch 1.75: Loss = 0.749863
Epoch 1.76: Loss = 0.722992
Epoch 1.77: Loss = 0.723114
Epoch 1.78: Loss = 0.734955
Epoch 1.79: Loss = 0.697754
Epoch 1.80: Loss = 0.708527
Epoch 1.81: Loss = 0.708527
Epoch 1.82: Loss = 0.653351
Epoch 1.83: Loss = 0.708115
Epoch 1.84: Loss = 0.714539
Epoch 1.85: Loss = 0.680359
Epoch 1.86: Loss = 0.672882
Epoch 1.87: Loss = 0.63855
Epoch 1.88: Loss = 0.623596
Epoch 1.89: Loss = 0.627502
Epoch 1.90: Loss = 0.62114
Epoch 1.91: Loss = 0.616745
Epoch 1.92: Loss = 0.630737
Epoch 1.93: Loss = 0.614578
Epoch 1.94: Loss = 0.573288
Epoch 1.95: Loss = 0.659897
Epoch 1.96: Loss = 0.715271
Epoch 1.97: Loss = 0.605698
Epoch 1.98: Loss = 0.663284
Epoch 1.99: Loss = 0.628403
Epoch 1.100: Loss = 0.623566
TRAIN LOSS = 1.13225
TRAIN ACC = 68.2953 % (40979/60000)
Loss = 0.663025
Loss = 0.645767
Loss = 0.801849
Loss = 0.733795
Loss = 0.643845
Loss = 0.644073
Loss = 0.713425
Loss = 0.703995
Loss = 0.535782
Loss = 0.489227
Loss = 0.455414
Loss = 0.543167
Loss = 0.483444
Loss = 0.487152
Loss = 0.289642
Loss = 0.456345
Loss = 0.797058
TEST LOSS = 0.589279
TEST ACC = 409.79 % (8229/10000)
Reducing learning rate to 0.200012
Epoch 2.1: Loss = 0.675507
Epoch 2.2: Loss = 0.600174
Epoch 2.3: Loss = 0.632141
Epoch 2.4: Loss = 0.593903
Epoch 2.5: Loss = 0.670609
Epoch 2.6: Loss = 0.666763
Epoch 2.7: Loss = 0.606491
Epoch 2.8: Loss = 0.530594
Epoch 2.9: Loss = 0.564514
Epoch 2.10: Loss = 0.66922
Epoch 2.11: Loss = 0.620956
Epoch 2.12: Loss = 0.672867
Epoch 2.13: Loss = 0.627289
Epoch 2.14: Loss = 0.568176
Epoch 2.15: Loss = 0.56694
Epoch 2.16: Loss = 0.61882
Epoch 2.17: Loss = 0.570938
Epoch 2.18: Loss = 0.585159
Epoch 2.19: Loss = 0.51683
Epoch 2.20: Loss = 0.609161
Epoch 2.21: Loss = 0.667938
Epoch 2.22: Loss = 0.593323
Epoch 2.23: Loss = 0.592194
Epoch 2.24: Loss = 0.607254
Epoch 2.25: Loss = 0.587738
Epoch 2.26: Loss = 0.637787
Epoch 2.27: Loss = 0.61702
Epoch 2.28: Loss = 0.716736
Epoch 2.29: Loss = 0.561035
Epoch 2.30: Loss = 0.601212
Epoch 2.31: Loss = 0.666351
Epoch 2.32: Loss = 0.598343
Epoch 2.33: Loss = 0.672256
Epoch 2.34: Loss = 0.631836
Epoch 2.35: Loss = 0.611526
Epoch 2.36: Loss = 0.648453
Epoch 2.37: Loss = 0.666107
Epoch 2.38: Loss = 0.644669
Epoch 2.39: Loss = 0.579742
Epoch 2.40: Loss = 0.613174
Epoch 2.41: Loss = 0.607147
Epoch 2.42: Loss = 0.580872
Epoch 2.43: Loss = 0.701462
Epoch 2.44: Loss = 0.593079
Epoch 2.45: Loss = 0.59642
Epoch 2.46: Loss = 0.630264
Epoch 2.47: Loss = 0.567932
Epoch 2.48: Loss = 0.624954
Epoch 2.49: Loss = 0.637131
Epoch 2.50: Loss = 0.625824
Epoch 2.51: Loss = 0.667053
Epoch 2.52: Loss = 0.638931
Epoch 2.53: Loss = 0.660339
Epoch 2.54: Loss = 0.64035
Epoch 2.55: Loss = 0.59079
Epoch 2.56: Loss = 0.570724
Epoch 2.57: Loss = 0.628571
Epoch 2.58: Loss = 0.595764
Epoch 2.59: Loss = 0.636322
Epoch 2.60: Loss = 0.679718
Epoch 2.61: Loss = 0.696381
Epoch 2.62: Loss = 0.599701
Epoch 2.63: Loss = 0.6418
Epoch 2.64: Loss = 0.628937
Epoch 2.65: Loss = 0.579865
Epoch 2.66: Loss = 0.618073
Epoch 2.67: Loss = 0.648743
Epoch 2.68: Loss = 0.622833
Epoch 2.69: Loss = 0.66951
Epoch 2.70: Loss = 0.66571
Epoch 2.71: Loss = 0.707382
Epoch 2.72: Loss = 0.69519
Epoch 2.73: Loss = 0.629593
Epoch 2.74: Loss = 0.651581
Epoch 2.75: Loss = 0.692978
Epoch 2.76: Loss = 0.607086
Epoch 2.77: Loss = 0.726868
Epoch 2.78: Loss = 0.541504
Epoch 2.79: Loss = 0.612167
Epoch 2.80: Loss = 0.676514
Epoch 2.81: Loss = 0.639145
Epoch 2.82: Loss = 0.615997
Epoch 2.83: Loss = 0.676147
Epoch 2.84: Loss = 0.619598
Epoch 2.85: Loss = 0.696014
Epoch 2.86: Loss = 0.728912
Epoch 2.87: Loss = 0.710297
Epoch 2.88: Loss = 0.711716
Epoch 2.89: Loss = 0.664551
Epoch 2.90: Loss = 0.639526
Epoch 2.91: Loss = 0.812759
Epoch 2.92: Loss = 0.766464
Epoch 2.93: Loss = 0.82251
Epoch 2.94: Loss = 0.635895
Epoch 2.95: Loss = 0.775772
Epoch 2.96: Loss = 0.671158
Epoch 2.97: Loss = 0.687714
Epoch 2.98: Loss = 0.630493
Epoch 2.99: Loss = 0.689514
Epoch 2.100: Loss = 0.825928
TRAIN LOSS = 0.640869
TRAIN ACC = 80.5496 % (48332/60000)
Loss = 0.828491
Loss = 0.822495
Loss = 0.95253
Loss = 0.902466
Loss = 0.719833
Loss = 0.739655
Loss = 0.844803
Loss = 0.813339
Loss = 0.553986
Loss = 0.478989
Loss = 0.469116
Loss = 0.513962
Loss = 0.449066
Loss = 0.488098
Loss = 0.227829
Loss = 0.438324
Loss = 0.907913
TEST LOSS = 0.650895
TEST ACC = 483.319 % (8110/10000)
Reducing learning rate to 0.300018
Epoch 3.1: Loss = 0.557755
Epoch 3.2: Loss = 0.688187
Epoch 3.3: Loss = 0.699799
Epoch 3.4: Loss = 0.685104
Epoch 3.5: Loss = 0.925812
Epoch 3.6: Loss = 0.958817
Epoch 3.7: Loss = 0.780457
Epoch 3.8: Loss = 0.844513
Epoch 3.9: Loss = 0.769547
Epoch 3.10: Loss = 0.806686
Epoch 3.11: Loss = 0.882507
Epoch 3.12: Loss = 0.902969
Epoch 3.13: Loss = 0.857925
Epoch 3.14: Loss = 0.785553
Epoch 3.15: Loss = 0.950623
Epoch 3.16: Loss = 0.716812
Epoch 3.17: Loss = 0.832001
Epoch 3.18: Loss = 0.819931
Epoch 3.19: Loss = 0.890045
Epoch 3.20: Loss = 0.823425
Epoch 3.21: Loss = 0.890503
Epoch 3.22: Loss = 0.810654
Epoch 3.23: Loss = 0.914185
Epoch 3.24: Loss = 0.86879
Epoch 3.25: Loss = 0.904495
Epoch 3.26: Loss = 0.776398
Epoch 3.27: Loss = 0.884354
Epoch 3.28: Loss = 0.970581
Epoch 3.29: Loss = 0.970062
Epoch 3.30: Loss = 0.860764
Epoch 3.31: Loss = 0.824722
Epoch 3.32: Loss = 0.866043
Epoch 3.33: Loss = 0.920792
Epoch 3.34: Loss = 0.867615
Epoch 3.35: Loss = 0.993164
Epoch 3.36: Loss = 0.85585
Epoch 3.37: Loss = 0.849396
Epoch 3.38: Loss = 1.10948
Epoch 3.39: Loss = 1.0434
Epoch 3.40: Loss = 1.12569
Epoch 3.41: Loss = 1.13469
Epoch 3.42: Loss = 1.0528
Epoch 3.43: Loss = 1.09306
Epoch 3.44: Loss = 1.17949
Epoch 3.45: Loss = 0.913635
Epoch 3.46: Loss = 0.979065
Epoch 3.47: Loss = 1.20734
Epoch 3.48: Loss = 1.44331
Epoch 3.49: Loss = 1.23679
Epoch 3.50: Loss = 1.10091
Epoch 3.51: Loss = 1.13826
Epoch 3.52: Loss = 1.03334
Epoch 3.53: Loss = 1.12428
Epoch 3.54: Loss = 0.982025
Epoch 3.55: Loss = 1.11058
Epoch 3.56: Loss = 0.99971
Epoch 3.57: Loss = 1.11012
Epoch 3.58: Loss = 1.09099
Epoch 3.59: Loss = 0.864563
Epoch 3.60: Loss = 1.03717
Epoch 3.61: Loss = 1.23991
Epoch 3.62: Loss = 1.22458
Epoch 3.63: Loss = 1.0631
Epoch 3.64: Loss = 1.22108
Epoch 3.65: Loss = 1.16084
Epoch 3.66: Loss = 1.14803
Epoch 3.67: Loss = 0.965988
Epoch 3.68: Loss = 1.17107
Epoch 3.69: Loss = 1.27777
Epoch 3.70: Loss = 1.08189
Epoch 3.71: Loss = 1.05905
Epoch 3.72: Loss = 1.15277
Epoch 3.73: Loss = 1.41312
Epoch 3.74: Loss = 1.08827
Epoch 3.75: Loss = 1.15686
Epoch 3.76: Loss = 1.19144
Epoch 3.77: Loss = 1.183
Epoch 3.78: Loss = 1.08482
Epoch 3.79: Loss = 1.00882
Epoch 3.80: Loss = 1.3681
Epoch 3.81: Loss = 1.2739
Epoch 3.82: Loss = 1.64081
Epoch 3.83: Loss = 1.15601
Epoch 3.84: Loss = 1.27757
Epoch 3.85: Loss = 1.38368
Epoch 3.86: Loss = 1.35422
Epoch 3.87: Loss = 1.24667
Epoch 3.88: Loss = 1.33475
Epoch 3.89: Loss = 1.40941
Epoch 3.90: Loss = 1.45818
Epoch 3.91: Loss = 1.4162
Epoch 3.92: Loss = 1.78391
Epoch 3.93: Loss = 1.55325
Epoch 3.94: Loss = 1.25999
Epoch 3.95: Loss = 1.68829
Epoch 3.96: Loss = 1.3506
Epoch 3.97: Loss = 1.37593
Epoch 3.98: Loss = 1.50578
Epoch 3.99: Loss = 1.41829
Epoch 3.100: Loss = 1.5005
TRAIN LOSS = 1.07968
TRAIN ACC = 76.7212 % (46035/60000)
Loss = 1.66991
Loss = 1.58238
Loss = 1.89558
Loss = 1.86113
Loss = 1.44044
Loss = 1.41345
Loss = 1.79831
Loss = 1.68973
Loss = 1.20122
Loss = 1.08313
Loss = 1.11954
Loss = 1.2336
Loss = 0.931442
Loss = 1.08356
Loss = 0.607727
Loss = 1.14853
Loss = 2.01863
TEST LOSS = 1.38633
TEST ACC = 460.349 % (7547/10000)
Reducing learning rate to 0.400024
Epoch 4.1: Loss = 1.34909
Epoch 4.2: Loss = 1.32191
Epoch 4.3: Loss = 1.77831
Epoch 4.4: Loss = 1.86359
Epoch 4.5: Loss = 1.59731
Epoch 4.6: Loss = 1.56163
Epoch 4.7: Loss = 1.86879
Epoch 4.8: Loss = 1.26767
Epoch 4.9: Loss = 1.53601
Epoch 4.10: Loss = 1.64503
Epoch 4.11: Loss = 1.57887
Epoch 4.12: Loss = 1.61476
Epoch 4.13: Loss = 1.56035
Epoch 4.14: Loss = 1.85959
Epoch 4.15: Loss = 1.91202
Epoch 4.16: Loss = 1.88925
Epoch 4.17: Loss = 1.86954
Epoch 4.18: Loss = 2.06935
Epoch 4.19: Loss = 1.90327
Epoch 4.20: Loss = 1.81659
Epoch 4.21: Loss = 1.71941
Epoch 4.22: Loss = 1.67075
Epoch 4.23: Loss = 1.88309
Epoch 4.24: Loss = 1.48482
Epoch 4.25: Loss = 1.81952
Epoch 4.26: Loss = 1.98473
Epoch 4.27: Loss = 2.44719
Epoch 4.28: Loss = 2.01234
Epoch 4.29: Loss = 2.27654
Epoch 4.30: Loss = 1.81444
Epoch 4.31: Loss = 2.05321
Epoch 4.32: Loss = 1.96298
Epoch 4.33: Loss = 2.09805
Epoch 4.34: Loss = 1.99771
Epoch 4.35: Loss = 1.80373
Epoch 4.36: Loss = 1.91937
Epoch 4.37: Loss = 2.03004
Epoch 4.38: Loss = 2.50555
Epoch 4.39: Loss = 1.92055
Epoch 4.40: Loss = 2.0773
Epoch 4.41: Loss = 2.26686
Epoch 4.42: Loss = 1.95361
Epoch 4.43: Loss = 2.23907
Epoch 4.44: Loss = 2.44153
Epoch 4.45: Loss = 2.53796
Epoch 4.46: Loss = 2.49893
Epoch 4.47: Loss = 2.63281
Epoch 4.48: Loss = 1.99467
Epoch 4.49: Loss = 2.24548
Epoch 4.50: Loss = 2.19443
Epoch 4.51: Loss = 2.05853
Epoch 4.52: Loss = 2.3638
Epoch 4.53: Loss = 2.03928
Epoch 4.54: Loss = 2.00493
Epoch 4.55: Loss = 2.2222
Epoch 4.56: Loss = 2.24127
Epoch 4.57: Loss = 1.96292
Epoch 4.58: Loss = 2.08757
Epoch 4.59: Loss = 2.32692
Epoch 4.60: Loss = 2.86684
Epoch 4.61: Loss = 2.41435
Epoch 4.62: Loss = 2.61295
Epoch 4.63: Loss = 2.67615
Epoch 4.64: Loss = 2.35664
Epoch 4.65: Loss = 2.50027
Epoch 4.66: Loss = 2.52287
Epoch 4.67: Loss = 2.51126
Epoch 4.68: Loss = 2.64986
Epoch 4.69: Loss = 2.3952
Epoch 4.70: Loss = 2.47968
Epoch 4.71: Loss = 2.29147
Epoch 4.72: Loss = 2.58405
Epoch 4.73: Loss = 2.41692
Epoch 4.74: Loss = 2.38579
Epoch 4.75: Loss = 2.58292
Epoch 4.76: Loss = 2.851
Epoch 4.77: Loss = 2.84445
Epoch 4.78: Loss = 2.33615
Epoch 4.79: Loss = 2.09636
Epoch 4.80: Loss = 2.43581
Epoch 4.81: Loss = 2.50677
Epoch 4.82: Loss = 2.53197
Epoch 4.83: Loss = 2.85852
Epoch 4.84: Loss = 2.85399
Epoch 4.85: Loss = 2.83801
Epoch 4.86: Loss = 2.59305
Epoch 4.87: Loss = 2.29579
Epoch 4.88: Loss = 2.59189
Epoch 4.89: Loss = 2.963
Epoch 4.90: Loss = 2.59042
Epoch 4.91: Loss = 3.01483
Epoch 4.92: Loss = 2.5874
Epoch 4.93: Loss = 3.15556
Epoch 4.94: Loss = 3.09285
Epoch 4.95: Loss = 2.55356
Epoch 4.96: Loss = 3.38321
Epoch 4.97: Loss = 3.64854
Epoch 4.98: Loss = 2.85364
Epoch 4.99: Loss = 3.22627
Epoch 4.100: Loss = 2.89983
TRAIN LOSS = 2.2551
TRAIN ACC = 72.4197 % (43453/60000)
Loss = 2.9191
Loss = 3.13347
Loss = 3.63652
Loss = 3.10629
Loss = 2.85051
Loss = 3.24638
Loss = 3.0761
Loss = 3.03984
Loss = 2.35773
Loss = 2.00801
Loss = 2.08995
Loss = 2.55196
Loss = 2.17641
Loss = 2.89574
Loss = 1.13205
Loss = 2.12965
Loss = 3.48705
TEST LOSS = 2.68046
TEST ACC = 434.529 % (7341/10000)
Reducing learning rate to 0.500031
Epoch 5.1: Loss = 2.70331
Epoch 5.2: Loss = 2.59753
Epoch 5.3: Loss = 3.24788
Epoch 5.4: Loss = 2.90714
Epoch 5.5: Loss = 3.05444
Epoch 5.6: Loss = 3.35928
Epoch 5.7: Loss = 4.53032
Epoch 5.8: Loss = 3.16316
Epoch 5.9: Loss = 3.16696
Epoch 5.10: Loss = 3.30878
Epoch 5.11: Loss = 3.19716
Epoch 5.12: Loss = 3.42084
Epoch 5.13: Loss = 2.90881
Epoch 5.14: Loss = 3.41756
Epoch 5.15: Loss = 2.9538
Epoch 5.16: Loss = 3.27933
Epoch 5.17: Loss = 2.90665
Epoch 5.18: Loss = 3.99733
Epoch 5.19: Loss = 4.10701
Epoch 5.20: Loss = 3.58064
Epoch 5.21: Loss = 3.55461
Epoch 5.22: Loss = 3.34978
Epoch 5.23: Loss = 3.53438
Epoch 5.24: Loss = 4.66275
Epoch 5.25: Loss = 3.48581
Epoch 5.26: Loss = 3.89761
Epoch 5.27: Loss = 3.83124
Epoch 5.28: Loss = 116.558
Epoch 5.29: Loss = 38.5959
Epoch 5.30: Loss = 18.1435
Epoch 5.31: Loss = 14.3223
Epoch 5.32: Loss = 14.6492
Epoch 5.33: Loss = 13.6161
Epoch 5.34: Loss = 10.5799
Epoch 5.35: Loss = 11.699
Epoch 5.36: Loss = 10.3661
Epoch 5.37: Loss = 8.53569
Epoch 5.38: Loss = 8.92709
Epoch 5.39: Loss = 6.81471
Epoch 5.40: Loss = 6.198
Epoch 5.41: Loss = 5.7446
Epoch 5.42: Loss = 5.47626
Epoch 5.43: Loss = 5.1922
Epoch 5.44: Loss = 5.29327
Epoch 5.45: Loss = 4.62648
Epoch 5.46: Loss = 5.74776
Epoch 5.47: Loss = 6.02196
Epoch 5.48: Loss = 5.38681
Epoch 5.49: Loss = 4.0666
Epoch 5.50: Loss = 3.9254
Epoch 5.51: Loss = 4.56767
Epoch 5.52: Loss = 4609.66
Epoch 5.53: Loss = -4359.76
Epoch 5.54: Loss = -1639.75
Epoch 5.55: Loss = 1134.25
Epoch 5.56: Loss = -20.9481
Epoch 5.57: Loss = -939.459
Epoch 5.58: Loss = 190.42
Epoch 5.59: Loss = -96.5205
Epoch 5.60: Loss = 1634
Epoch 5.61: Loss = -169.161
Epoch 5.62: Loss = -2661.19
Epoch 5.63: Loss = -805.46
Epoch 5.64: Loss = -1194.46
Epoch 5.65: Loss = 1216.4
Epoch 5.66: Loss = -77.6185
Epoch 5.67: Loss = 2072.98
Epoch 5.68: Loss = 983.587
Epoch 5.69: Loss = -1438.96
Epoch 5.70: Loss = -472.434
Epoch 5.71: Loss = -1494.74
Epoch 5.72: Loss = -375.611
Epoch 5.73: Loss = 1148.23
Epoch 5.74: Loss = -655.136
Epoch 5.75: Loss = -1338.2
Epoch 5.76: Loss = -1880.99
Epoch 5.77: Loss = 429.503
Epoch 5.78: Loss = 316.253
Epoch 5.79: Loss = -226.436
Epoch 5.80: Loss = -340.795
Epoch 5.81: Loss = -65.9723
Epoch 5.82: Loss = -431.674
Epoch 5.83: Loss = -335.034
Epoch 5.84: Loss = -739.122
Epoch 5.85: Loss = 348.688
Epoch 5.86: Loss = -245.841
Epoch 5.87: Loss = -61.0912
Epoch 5.88: Loss = 1244.54
Epoch 5.89: Loss = -472.207
Epoch 5.90: Loss = -398.012
Epoch 5.91: Loss = 249.288
Epoch 5.92: Loss = 2211.06
Epoch 5.93: Loss = 1237.56
Epoch 5.94: Loss = -939.639
Epoch 5.95: Loss = -656.521
Epoch 5.96: Loss = 1439.32
Epoch 5.97: Loss = 927.45
Epoch 5.98: Loss = 1447.46
Epoch 5.99: Loss = 1276.05
Epoch 5.100: Loss = 1911.68
TRAIN LOSS = 19.2283
TRAIN ACC = 38.5498 % (23131/60000)
Loss = -380.786
Loss = 4764.01
Loss = -1372.14
Loss = 610.685
Loss = 708.161
Loss = 1593.68
Loss = 731.114
Loss = -648.282
Loss = 1526.87
Loss = -761.621
Loss = 1128.04
Loss = -316.892
Loss = 889.125
Loss = 1535.79
Loss = 1325.41
Loss = 763.723
Loss = -942.322
TEST LOSS = 1.82976
TEST ACC = 231.31 % (986/10000)
Reducing learning rate to 0.600037
Epoch 6.1: Loss = -1274.12
Epoch 6.2: Loss = 1077.02
Epoch 6.3: Loss = 1744.61
Epoch 6.4: Loss = 1120.13
Epoch 6.5: Loss = 878.102
Epoch 6.6: Loss = 1947.08
Epoch 6.7: Loss = -2323.19
Epoch 6.8: Loss = -1550
Epoch 6.9: Loss = -1880.99
Epoch 6.10: Loss = 900.494
Epoch 6.11: Loss = 1480.61
Epoch 6.12: Loss = 642.481
Epoch 6.13: Loss = 490.899
Epoch 6.14: Loss = 1850.21
Epoch 6.15: Loss = 1235.15
Epoch 6.16: Loss = 1379.63
Epoch 6.17: Loss = 997.209
Epoch 6.18: Loss = -471.676
Epoch 6.19: Loss = -882.324
Epoch 6.20: Loss = 522.913
Epoch 6.21: Loss = -246.93
Epoch 6.22: Loss = 1519.97
Epoch 6.23: Loss = 1027.67
Epoch 6.24: Loss = 946.248
Epoch 6.25: Loss = 85.2089
Epoch 6.26: Loss = 2375.3
Epoch 6.27: Loss = -297.003
Epoch 6.28: Loss = 1684.16
Epoch 6.29: Loss = 330.63
Epoch 6.30: Loss = -240.391
Epoch 6.31: Loss = -430.72
Epoch 6.32: Loss = -1033.06
Epoch 6.33: Loss = -1169.23
Epoch 6.34: Loss = 838.836
Epoch 6.35: Loss = -2194.37
Epoch 6.36: Loss = -357.788
Epoch 6.37: Loss = -1323.69
Epoch 6.38: Loss = 317.431
Epoch 6.39: Loss = 1499.02
Epoch 6.40: Loss = -1631.69
Epoch 6.41: Loss = 1901.75
Epoch 6.42: Loss = -1077.58
Epoch 6.43: Loss = -2634.79
Epoch 6.44: Loss = -546.141
Epoch 6.45: Loss = -2634.3
Epoch 6.46: Loss = -1845.01
Epoch 6.47: Loss = -943.747
Epoch 6.48: Loss = -273.651
Epoch 6.49: Loss = -476.522
Epoch 6.50: Loss = 676.011
Epoch 6.51: Loss = 216.507
Epoch 6.52: Loss = 1053.47
Epoch 6.53: Loss = -943.921
Epoch 6.54: Loss = 700.932
Epoch 6.55: Loss = -165.272
Epoch 6.56: Loss = 1342.65
Epoch 6.57: Loss = 1338.87
Epoch 6.58: Loss = 733.984
Epoch 6.59: Loss = -2321.21
Epoch 6.60: Loss = 912.876
Epoch 6.61: Loss = -339.384
Epoch 6.62: Loss = -1971.57
Epoch 6.63: Loss = -336.103
Epoch 6.64: Loss = -41.6312
Epoch 6.65: Loss = 1991.82
Epoch 6.66: Loss = 1431.28
Epoch 6.67: Loss = 104.229
Epoch 6.68: Loss = -66.3251
Epoch 6.69: Loss = -148.191
Epoch 6.70: Loss = 949.738
Epoch 6.71: Loss = -419.481
Epoch 6.72: Loss = 79.9586
Epoch 6.73: Loss = 1055.26
Epoch 6.74: Loss = 1483.61
Epoch 6.75: Loss = -751.964
Epoch 6.76: Loss = -308.472
Epoch 6.77: Loss = -1042.27
Epoch 6.78: Loss = 2158.44
Epoch 6.79: Loss = 1373.95
Epoch 6.80: Loss = 290.79
Epoch 6.81: Loss = -1012.48
Epoch 6.82: Loss = 2355.24
Epoch 6.83: Loss = -968.065
Epoch 6.84: Loss = 1169.58
Epoch 6.85: Loss = -1671.08
Epoch 6.86: Loss = -1882.51
Epoch 6.87: Loss = 701.268
Epoch 6.88: Loss = 2600.64
Epoch 6.89: Loss = 845.553
Epoch 6.90: Loss = -161.481
Epoch 6.91: Loss = 1323.9
Epoch 6.92: Loss = 635.465
Epoch 6.93: Loss = -522.1
Epoch 6.94: Loss = 1356.7
Epoch 6.95: Loss = 675.226
Epoch 6.96: Loss = -857.553
Epoch 6.97: Loss = -440.401
Epoch 6.98: Loss = 692.608
Epoch 6.99: Loss = 1597.49
Epoch 6.100: Loss = -1272.65
TRAIN LOSS = 152.58
TRAIN ACC = 10.0418 % (6025/60000)
Loss = 2516.08
Loss = 851.871
Loss = -1419.81
Loss = 135.009
Loss = -1644.42
Loss = 1626.81
Loss = 172.007
Loss = 1084.54
Loss = 439.481
Loss = -1332.6
Loss = 761.365
Loss = -285.038
Loss = 1284.7
Loss = -529.508
Loss = -253.457
Loss = -18.6076
Loss = -1243.75
TEST LOSS = 2.82178
TEST ACC = 60.2493 % (995/10000)
Reducing learning rate to 0.700043
Epoch 7.1: Loss = -1051.82
Epoch 7.2: Loss = 564.313
Epoch 7.3: Loss = 12.1647
Epoch 7.4: Loss = 238.275
Epoch 7.5: Loss = -1267.62
Epoch 7.6: Loss = 789.734
Epoch 7.7: Loss = 1354.82
Epoch 7.8: Loss = -1150.89
Epoch 7.9: Loss = -1653.49
Epoch 7.10: Loss = 87.5403
Epoch 7.11: Loss = -783.68
Epoch 7.12: Loss = 2308.05
Epoch 7.13: Loss = -68.4434
Epoch 7.14: Loss = -1408.58
Epoch 7.15: Loss = 688.337
Epoch 7.16: Loss = 63.434
Epoch 7.17: Loss = -2662.03
Epoch 7.18: Loss = 370.95
Epoch 7.19: Loss = 1776.71
Epoch 7.20: Loss = 267.38
Epoch 7.21: Loss = 491.542
Epoch 7.22: Loss = 1950.92
Epoch 7.23: Loss = -858.642
Epoch 7.24: Loss = 2191.97
Epoch 7.25: Loss = 427.899
Epoch 7.26: Loss = 258.085
Epoch 7.27: Loss = 1491.42
Epoch 7.28: Loss = 448.654
Epoch 7.29: Loss = 1682
Epoch 7.30: Loss = 258.362
Epoch 7.31: Loss = -1233.14
Epoch 7.32: Loss = 538.91
Epoch 7.33: Loss = -223.579
Epoch 7.34: Loss = 1642.24
Epoch 7.35: Loss = -248.292
Epoch 7.36: Loss = 470.083
Epoch 7.37: Loss = -2293.56
Epoch 7.38: Loss = 1787.99
Epoch 7.39: Loss = -126.888
Epoch 7.40: Loss = -401.805
Epoch 7.41: Loss = 655.672
Epoch 7.42: Loss = -2097.29
Epoch 7.43: Loss = 315.625
Epoch 7.44: Loss = 506.582
Epoch 7.45: Loss = -260.075
Epoch 7.46: Loss = -758.317
Epoch 7.47: Loss = -2181.43
Epoch 7.48: Loss = -1611.85
Epoch 7.49: Loss = -471.612
Epoch 7.50: Loss = 738.7
Epoch 7.51: Loss = 449.297
Epoch 7.52: Loss = 543.019
Epoch 7.53: Loss = -796.906
Epoch 7.54: Loss = -845
Epoch 7.55: Loss = 4243.57
Epoch 7.56: Loss = -595.301
Epoch 7.57: Loss = 1729.36
Epoch 7.58: Loss = 1268.68
Epoch 7.59: Loss = -376.991
Epoch 7.60: Loss = 991.089
Epoch 7.61: Loss = 33.4559
Epoch 7.62: Loss = 360.992
Epoch 7.63: Loss = 777.105
Epoch 7.64: Loss = 786.797
Epoch 7.65: Loss = 405.574
Epoch 7.66: Loss = -1035.15
Epoch 7.67: Loss = -1622.61
Epoch 7.68: Loss = -1695.42
Epoch 7.69: Loss = 995.307
Epoch 7.70: Loss = 255.575
Epoch 7.71: Loss = 1502.27
Epoch 7.72: Loss = -512.865
Epoch 7.73: Loss = -1551.75
Epoch 7.74: Loss = -2176.9
Epoch 7.75: Loss = -92.1924
Epoch 7.76: Loss = 725.777
Epoch 7.77: Loss = -197.948
Epoch 7.78: Loss = -1196.66
Epoch 7.79: Loss = -3061.3
Epoch 7.80: Loss = 281.093
Epoch 7.81: Loss = -1271.86
Epoch 7.82: Loss = 2475.84
Epoch 7.83: Loss = -182.718
Epoch 7.84: Loss = -126.867
Epoch 7.85: Loss = -505.82
Epoch 7.86: Loss = -501.676
Epoch 7.87: Loss = -2685.15
Epoch 7.88: Loss = 68.9268
Epoch 7.89: Loss = -314.059
Epoch 7.90: Loss = 2133.97
Epoch 7.91: Loss = 426.447
Epoch 7.92: Loss = -1951.79
Epoch 7.93: Loss = 1308.71
Epoch 7.94: Loss = 126.585
Epoch 7.95: Loss = 1688.35
Epoch 7.96: Loss = 1195.17
Epoch 7.97: Loss = -1879.05
Epoch 7.98: Loss = -999.414
Epoch 7.99: Loss = -380.455
Epoch 7.100: Loss = -1250.81
TRAIN LOSS = -14.6838
TRAIN ACC = 10.2478 % (6149/60000)
Loss = 649.527
Loss = -762.182
Loss = -2426.09
Loss = -1268.26
Loss = 715.083
Loss = -1040.84
Loss = 635.684
Loss = -939.236
Loss = -978.153
Loss = 648.166
Loss = -1057.74
Loss = -1.37546
Loss = 1146.71
Loss = 691.379
Loss = 1239.72
Loss = 1278.76
Loss = 2602.35
TEST LOSS = 2.8557
TEST ACC = 61.4899 % (1026/10000)
Reducing learning rate to 0.800049
Epoch 8.1: Loss = -423.529
Epoch 8.2: Loss = -1286.55
Epoch 8.3: Loss = -845.856
Epoch 8.4: Loss = -1032.11
Epoch 8.5: Loss = -1431.85
Epoch 8.6: Loss = 436.148
Epoch 8.7: Loss = 1122.89
Epoch 8.8: Loss = -703.497
Epoch 8.9: Loss = 721.921
Epoch 8.10: Loss = 1708.22
Epoch 8.11: Loss = -1831.83
Epoch 8.12: Loss = -559.583
Epoch 8.13: Loss = -2229.88
Epoch 8.14: Loss = 1716.04
Epoch 8.15: Loss = 110.562
Epoch 8.16: Loss = 1672.1
Epoch 8.17: Loss = 580.067
Epoch 8.18: Loss = 75.0747
Epoch 8.19: Loss = -143.162
Epoch 8.20: Loss = -398.841
Epoch 8.21: Loss = 1120.71
Epoch 8.22: Loss = 621.102
Epoch 8.23: Loss = 2453.13
Epoch 8.24: Loss = -1066.83
Epoch 8.25: Loss = -1155.61
Epoch 8.26: Loss = -1931.35
Epoch 8.27: Loss = -190.088
Epoch 8.28: Loss = 154.385
Epoch 8.29: Loss = -516.655
Epoch 8.30: Loss = -214.656
Epoch 8.31: Loss = 817.872
Epoch 8.32: Loss = 805.401
Epoch 8.33: Loss = -822.926
Epoch 8.34: Loss = 984.326
Epoch 8.35: Loss = -1524.35
Epoch 8.36: Loss = 265.082
Epoch 8.37: Loss = 688.42
Epoch 8.38: Loss = 23.5273
Epoch 8.39: Loss = -591.231
Epoch 8.40: Loss = -1294.18
Epoch 8.41: Loss = -1786.24
Epoch 8.42: Loss = 679.125
Epoch 8.43: Loss = 326.472
Epoch 8.44: Loss = 155.893
Epoch 8.45: Loss = 427.573
Epoch 8.46: Loss = 1211.32
Epoch 8.47: Loss = -252.749
Epoch 8.48: Loss = -1201.33
Epoch 8.49: Loss = -2933.63
Epoch 8.50: Loss = -689.543
Epoch 8.51: Loss = 585.322
Epoch 8.52: Loss = 286.337
Epoch 8.53: Loss = 1776.42
Epoch 8.54: Loss = -207.263
Epoch 8.55: Loss = 575.382
Epoch 8.56: Loss = 645.681
Epoch 8.57: Loss = 406.189
Epoch 8.58: Loss = 505.259
Epoch 8.59: Loss = 675.636
Epoch 8.60: Loss = 464.339
Epoch 8.61: Loss = -498.385
Epoch 8.62: Loss = -841.647
Epoch 8.63: Loss = 1837.37
Epoch 8.64: Loss = -107.501
Epoch 8.65: Loss = 1572.45
Epoch 8.66: Loss = -666.276
Epoch 8.67: Loss = 582.971
Epoch 8.68: Loss = 744.242
Epoch 8.69: Loss = -987.405
Epoch 8.70: Loss = 2194.02
Epoch 8.71: Loss = -68.8314
Epoch 8.72: Loss = 114.117
Epoch 8.73: Loss = 142.319
Epoch 8.74: Loss = 654.803
Epoch 8.75: Loss = 1728.12
Epoch 8.76: Loss = 733.136
Epoch 8.77: Loss = -79.1541
Epoch 8.78: Loss = -94.3147
Epoch 8.79: Loss = 710.349
Epoch 8.80: Loss = 1597.73
Epoch 8.81: Loss = 1161.08
Epoch 8.82: Loss = -2611.37
Epoch 8.83: Loss = -148.692
Epoch 8.84: Loss = 621.21
Epoch 8.85: Loss = 2108.99
Epoch 8.86: Loss = -663.259
Epoch 8.87: Loss = -944.347
Epoch 8.88: Loss = -1058.95
Epoch 8.89: Loss = 326.015
Epoch 8.90: Loss = -2969.24
Epoch 8.91: Loss = -260.294
Epoch 8.92: Loss = -2485.43
Epoch 8.93: Loss = -1837.08
Epoch 8.94: Loss = 10.9331
Epoch 8.95: Loss = -513.594
Epoch 8.96: Loss = -989.898
Epoch 8.97: Loss = -1186.45
Epoch 8.98: Loss = -260.158
Epoch 8.99: Loss = -1524.65
Epoch 8.100: Loss = 445.594
TRAIN LOSS = -59.7896
TRAIN ACC = 9.96399 % (5979/60000)
Loss = -1471.8
Loss = -2049.07
Loss = 27.2607
Loss = -1138.29
Loss = 559.521
Loss = 412.863
Loss = -796.223
Loss = -99.3451
Loss = 544.317
Loss = -345.955
Loss = -361.373
Loss = -218.622
Loss = 904.124
Loss = -4038.7
Loss = 1409.5
Loss = 508.318
Loss = -561.971
TEST LOSS = -0.308465
TEST ACC = 59.79 % (1015/10000)
Reducing learning rate to 0.900055
Epoch 9.1: Loss = 453.02
Epoch 9.2: Loss = 197.346
Epoch 9.3: Loss = -46.1295
Epoch 9.4: Loss = -531.419
Epoch 9.5: Loss = -1374.08
Epoch 9.6: Loss = -702.578
Epoch 9.7: Loss = -191.399
Epoch 9.8: Loss = 682.539
Epoch 9.9: Loss = -482.292
Epoch 9.10: Loss = -522.151
Epoch 9.11: Loss = 1374.94
Epoch 9.12: Loss = -314.512
Epoch 9.13: Loss = -1132.31
Epoch 9.14: Loss = 951.633
Epoch 9.15: Loss = 1340.26
Epoch 9.16: Loss = 478.453
Epoch 9.17: Loss = 1544.64
Epoch 9.18: Loss = 968.579
Epoch 9.19: Loss = -219.377
Epoch 9.20: Loss = 158.971
Epoch 9.21: Loss = 404.378
Epoch 9.22: Loss = 358.572
Epoch 9.23: Loss = 282.316
Epoch 9.24: Loss = -279.08
Epoch 9.25: Loss = 1775.13
Epoch 9.26: Loss = 525.738
Epoch 9.27: Loss = 2208.77
Epoch 9.28: Loss = -1335.69
Epoch 9.29: Loss = -1157.35
Epoch 9.30: Loss = 2927.8
Epoch 9.31: Loss = -2819.02
Epoch 9.32: Loss = -2838.13
Epoch 9.33: Loss = -442.775
Epoch 9.34: Loss = -16.1002
Epoch 9.35: Loss = 420.597
Epoch 9.36: Loss = 187.263
Epoch 9.37: Loss = -2477.29
Epoch 9.38: Loss = -628.932
Epoch 9.39: Loss = 305.082
Epoch 9.40: Loss = -1964.6
Epoch 9.41: Loss = 2384.11
Epoch 9.42: Loss = -403.25
Epoch 9.43: Loss = 445.85
Epoch 9.44: Loss = 404.008
Epoch 9.45: Loss = 400.209
Epoch 9.46: Loss = -878.728
Epoch 9.47: Loss = 111.815
Epoch 9.48: Loss = -728.438
Epoch 9.49: Loss = 142.962
Epoch 9.50: Loss = -170.667
Epoch 9.51: Loss = -244.614
Epoch 9.52: Loss = -797.891
Epoch 9.53: Loss = 1020.13
Epoch 9.54: Loss = -489.478
Epoch 9.55: Loss = 116.335
Epoch 9.56: Loss = 110.444
Epoch 9.57: Loss = -16.7489
Epoch 9.58: Loss = 928.189
Epoch 9.59: Loss = 1219.6
Epoch 9.60: Loss = -1054.4
Epoch 9.61: Loss = 397.149
Epoch 9.62: Loss = 167.338
Epoch 9.63: Loss = 1585.34
Epoch 9.64: Loss = 3678.64
Epoch 9.65: Loss = 1188.01
Epoch 9.66: Loss = 779.442
Epoch 9.67: Loss = 1257.66
Epoch 9.68: Loss = 2030.46
Epoch 9.69: Loss = 2010.72
Epoch 9.70: Loss = -389.501
Epoch 9.71: Loss = -427.886
Epoch 9.72: Loss = 877.215
Epoch 9.73: Loss = -977.593
Epoch 9.74: Loss = 628.197
Epoch 9.75: Loss = -778.83
Epoch 9.76: Loss = 43.4995
Epoch 9.77: Loss = 1894.63
Epoch 9.78: Loss = 1289.52
Epoch 9.79: Loss = -23.22
Epoch 9.80: Loss = -597.017
Epoch 9.81: Loss = -619.442
Epoch 9.82: Loss = 444.593
Epoch 9.83: Loss = -3166.22
Epoch 9.84: Loss = 226.436
Epoch 9.85: Loss = -905.445
Epoch 9.86: Loss = -131.305
Epoch 9.87: Loss = -458.051
Epoch 9.88: Loss = 294.946
Epoch 9.89: Loss = 108.602
Epoch 9.90: Loss = 995.883
Epoch 9.91: Loss = 4149.6
Epoch 9.92: Loss = 267.837
Epoch 9.93: Loss = 962.243
Epoch 9.94: Loss = -460.25
Epoch 9.95: Loss = -675.266
Epoch 9.96: Loss = -87.6802
Epoch 9.97: Loss = -2262.36
Epoch 9.98: Loss = -1507.61
Epoch 9.99: Loss = -3060.83
Epoch 9.100: Loss = -557.262
TRAIN LOSS = 87.6257
TRAIN ACC = 9.8999 % (5940/60000)
Loss = 1063.73
Loss = -388.463
Loss = -1679.43
Loss = -1666.78
Loss = -1042.58
Loss = -1885.19
Loss = 861.524
Loss = 648.797
Loss = -1767.64
Loss = -1156.51
Loss = 1822.5
Loss = 221.241
Loss = -1102.96
Loss = 1181.48
Loss = 664.757
Loss = 745.542
Loss = -1601.9
TEST LOSS = -0.083439
TEST ACC = 59.3994 % (1008/10000)
Reducing learning rate to 1.00006
Epoch 10.1: Loss = 2588.59
Epoch 10.2: Loss = -653.563
Epoch 10.3: Loss = -472.986
Epoch 10.4: Loss = -536.546
Epoch 10.5: Loss = -318.369
Epoch 10.6: Loss = 20.6599
Epoch 10.7: Loss = -1.6658
Epoch 10.8: Loss = -767.434
Epoch 10.9: Loss = 24.8484
Epoch 10.10: Loss = -915.051
Epoch 10.11: Loss = -364.766
Epoch 10.12: Loss = -384.441
Epoch 10.13: Loss = -692.164
Epoch 10.14: Loss = 1936.26
Epoch 10.15: Loss = 1800.96
Epoch 10.16: Loss = -1023.86
Epoch 10.17: Loss = 522.254
Epoch 10.18: Loss = -1089.47
Epoch 10.19: Loss = -1972.58
Epoch 10.20: Loss = -447.572
Epoch 10.21: Loss = -958.937
Epoch 10.22: Loss = -2319.77
Epoch 10.23: Loss = 290.24
Epoch 10.24: Loss = 571.107
Epoch 10.25: Loss = 514.72
Epoch 10.26: Loss = 203
Epoch 10.27: Loss = -250.384
Epoch 10.28: Loss = -928.532
Epoch 10.29: Loss = 982.731
Epoch 10.30: Loss = -1483.63
Epoch 10.31: Loss = -777.58
Epoch 10.32: Loss = 119.136
Epoch 10.33: Loss = -1189.44
Epoch 10.34: Loss = 1186.87
Epoch 10.35: Loss = 1199.65
Epoch 10.36: Loss = -1438.44
Epoch 10.37: Loss = -183.689
Epoch 10.38: Loss = -759.207
Epoch 10.39: Loss = -702.863
Epoch 10.40: Loss = 1666.92
Epoch 10.41: Loss = -3.48082
Epoch 10.42: Loss = -686.882
Epoch 10.43: Loss = 795.097
Epoch 10.44: Loss = -89.8726
Epoch 10.45: Loss = 265.932
Epoch 10.46: Loss = 1333.4
Epoch 10.47: Loss = 206.332
Epoch 10.48: Loss = -23.2668
Epoch 10.49: Loss = -16.9488
Epoch 10.50: Loss = 1902.55
Epoch 10.51: Loss = 2435.39
Epoch 10.52: Loss = 2199.98
Epoch 10.53: Loss = 157.718
Epoch 10.54: Loss = 2237.3
Epoch 10.55: Loss = -729.351
Epoch 10.56: Loss = -1450.13
Epoch 10.57: Loss = -1882.39
Epoch 10.58: Loss = -613.146
Epoch 10.59: Loss = -613.955
Epoch 10.60: Loss = -563.618
Epoch 10.61: Loss = -1739.59
Epoch 10.62: Loss = -2659.57
Epoch 10.63: Loss = -1131.55
Epoch 10.64: Loss = 40.0795
Epoch 10.65: Loss = 755.599
Epoch 10.66: Loss = -78.2694
Epoch 10.67: Loss = 1121.35
Epoch 10.68: Loss = -1441.31
Epoch 10.69: Loss = 843.941
Epoch 10.70: Loss = -69.1945
Epoch 10.71: Loss = -447.851
Epoch 10.72: Loss = 662.922
Epoch 10.73: Loss = -724.21
Epoch 10.74: Loss = -1051.33
Epoch 10.75: Loss = -603.881
Epoch 10.76: Loss = -810.119
Epoch 10.77: Loss = -234.005
Epoch 10.78: Loss = -460.771
Epoch 10.79: Loss = -1865.89
Epoch 10.80: Loss = -1427.34
Epoch 10.81: Loss = 823.771
Epoch 10.82: Loss = -954.776
Epoch 10.83: Loss = -1476.8
Epoch 10.84: Loss = 1745.22
Epoch 10.85: Loss = -816.028
Epoch 10.86: Loss = 1132.56
Epoch 10.87: Loss = 841.154
Epoch 10.88: Loss = -2209.86
Epoch 10.89: Loss = -266.14
Epoch 10.90: Loss = 2322.25
Epoch 10.91: Loss = -443.086
Epoch 10.92: Loss = -1756.55
Epoch 10.93: Loss = 738.06
Epoch 10.94: Loss = -2132.7
Epoch 10.95: Loss = 416.557
Epoch 10.96: Loss = 145.612
Epoch 10.97: Loss = -1682.71
Epoch 10.98: Loss = -1037.63
Epoch 10.99: Loss = -2048.53
Epoch 10.100: Loss = -1110.38
TRAIN LOSS = -212.357
TRAIN ACC = 9.86633 % (5920/60000)
Loss = 905.252
Loss = -368.097
Loss = 2484.43
Loss = -1363.02
Loss = -1328.67
Loss = -1025.14
Loss = 1653.8
Loss = 1123.79
Loss = -328.117
Loss = -860.617
Loss = 15.2199
Loss = 520.283
Loss = 113.674
Loss = 872.484
Loss = 1677.59
Loss = -684.115
Loss = -2237.63
TEST LOSS = 3.60826
TEST ACC = 59.1995 % (1028/10000)
