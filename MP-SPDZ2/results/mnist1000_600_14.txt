Using statistical security parameter 40
Trying to run 64-bit computation
Setting up connection 0
***********************************************************
Training MNIST
Model: Dense([60000, 1, 1000]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 600
Num Epochs: 20
Learning Rate: 0.1 to 0.05 over 10 epochs
Clipping Factor: 4
Sigma: 3.5
***********************************************************
Epoch 1.1: Loss = 2.34395
Epoch 1.2: Loss = 2.26825
Epoch 1.3: Loss = 2.24396
Epoch 1.4: Loss = 2.19731
Epoch 1.5: Loss = 2.14424
Epoch 1.6: Loss = 2.10515
Epoch 1.7: Loss = 2.0631
Epoch 1.8: Loss = 1.99451
Epoch 1.9: Loss = 1.95508
Epoch 1.10: Loss = 1.86465
Epoch 1.11: Loss = 1.88785
Epoch 1.12: Loss = 1.85312
Epoch 1.13: Loss = 1.79202
Epoch 1.14: Loss = 1.7709
Epoch 1.15: Loss = 1.7338
Epoch 1.16: Loss = 1.64485
Epoch 1.17: Loss = 1.6161
Epoch 1.18: Loss = 1.60446
Epoch 1.19: Loss = 1.5708
Epoch 1.20: Loss = 1.51996
Epoch 1.21: Loss = 1.53717
Epoch 1.22: Loss = 1.50731
Epoch 1.23: Loss = 1.40511
Epoch 1.24: Loss = 1.4064
Epoch 1.25: Loss = 1.37886
Epoch 1.26: Loss = 1.36856
Epoch 1.27: Loss = 1.31015
Epoch 1.28: Loss = 1.33461
Epoch 1.29: Loss = 1.27672
Epoch 1.30: Loss = 1.2592
Epoch 1.31: Loss = 1.179
Epoch 1.32: Loss = 1.18825
Epoch 1.33: Loss = 1.17116
Epoch 1.34: Loss = 1.14883
Epoch 1.35: Loss = 1.15544
Epoch 1.36: Loss = 1.09903
Epoch 1.37: Loss = 1.09735
Epoch 1.38: Loss = 1.10637
Epoch 1.39: Loss = 1.04222
Epoch 1.40: Loss = 1.01205
Epoch 1.41: Loss = 1.0522
Epoch 1.42: Loss = 1.05652
Epoch 1.43: Loss = 0.978394
Epoch 1.44: Loss = 1.03302
Epoch 1.45: Loss = 1.02469
Epoch 1.46: Loss = 0.996796
Epoch 1.47: Loss = 0.981613
Epoch 1.48: Loss = 0.893036
Epoch 1.49: Loss = 0.992172
Epoch 1.50: Loss = 0.93219
Epoch 1.51: Loss = 0.934204
Epoch 1.52: Loss = 0.924149
Epoch 1.53: Loss = 0.927139
Epoch 1.54: Loss = 0.932785
Epoch 1.55: Loss = 0.859131
Epoch 1.56: Loss = 0.842636
Epoch 1.57: Loss = 0.779724
Epoch 1.58: Loss = 0.833618
Epoch 1.59: Loss = 0.856415
Epoch 1.60: Loss = 0.785309
Epoch 1.61: Loss = 0.857315
Epoch 1.62: Loss = 0.827286
Epoch 1.63: Loss = 0.847534
Epoch 1.64: Loss = 0.833954
Epoch 1.65: Loss = 0.829208
Epoch 1.66: Loss = 0.791382
Epoch 1.67: Loss = 0.78595
Epoch 1.68: Loss = 0.749283
Epoch 1.69: Loss = 0.74353
Epoch 1.70: Loss = 0.62767
Epoch 1.71: Loss = 0.674576
Epoch 1.72: Loss = 0.693527
Epoch 1.73: Loss = 0.730087
Epoch 1.74: Loss = 0.736298
Epoch 1.75: Loss = 0.73056
Epoch 1.76: Loss = 0.696014
Epoch 1.77: Loss = 0.707458
Epoch 1.78: Loss = 0.677582
Epoch 1.79: Loss = 0.733627
Epoch 1.80: Loss = 0.676804
Epoch 1.81: Loss = 0.675949
Epoch 1.82: Loss = 0.658096
Epoch 1.83: Loss = 0.645584
Epoch 1.84: Loss = 0.6436
Epoch 1.85: Loss = 0.653671
Epoch 1.86: Loss = 0.594574
Epoch 1.87: Loss = 0.626587
Epoch 1.88: Loss = 0.668289
Epoch 1.89: Loss = 0.59166
Epoch 1.90: Loss = 0.662369
Epoch 1.91: Loss = 0.621002
Epoch 1.92: Loss = 0.633667
Epoch 1.93: Loss = 0.646988
Epoch 1.94: Loss = 0.566788
Epoch 1.95: Loss = 0.60083
Epoch 1.96: Loss = 0.599365
Epoch 1.97: Loss = 0.605453
Epoch 1.98: Loss = 0.549637
Epoch 1.99: Loss = 0.572906
Epoch 1.100: Loss = 0.619659
TRAIN LOSS = 1.09161
TRAIN ACC = 71.1441 % (42688/60000)
Loss = 0.632233
Loss = 0.625656
Loss = 0.756714
Loss = 0.691422
Loss = 0.627182
Loss = 0.617462
Loss = 0.704941
Loss = 0.659363
Loss = 0.514816
Loss = 0.444061
Loss = 0.413223
Loss = 0.505356
Loss = 0.431564
Loss = 0.443649
Loss = 0.261383
Loss = 0.421326
Loss = 0.738678
TEST LOSS = 0.554568
TEST ACC = 426.88 % (8504/10000)
Reducing learning rate to 0.0944519
Epoch 2.1: Loss = 0.539398
Epoch 2.2: Loss = 0.629959
Epoch 2.3: Loss = 0.52951
Epoch 2.4: Loss = 0.626938
Epoch 2.5: Loss = 0.615875
Epoch 2.6: Loss = 0.561127
Epoch 2.7: Loss = 0.578156
Epoch 2.8: Loss = 0.525787
Epoch 2.9: Loss = 0.605759
Epoch 2.10: Loss = 0.566956
Epoch 2.11: Loss = 0.537781
Epoch 2.12: Loss = 0.527176
Epoch 2.13: Loss = 0.538925
Epoch 2.14: Loss = 0.510147
Epoch 2.15: Loss = 0.548691
Epoch 2.16: Loss = 0.570084
Epoch 2.17: Loss = 0.620102
Epoch 2.18: Loss = 0.546295
Epoch 2.19: Loss = 0.573151
Epoch 2.20: Loss = 0.53125
Epoch 2.21: Loss = 0.567383
Epoch 2.22: Loss = 0.552414
Epoch 2.23: Loss = 0.549637
Epoch 2.24: Loss = 0.494949
Epoch 2.25: Loss = 0.574265
Epoch 2.26: Loss = 0.552872
Epoch 2.27: Loss = 0.550797
Epoch 2.28: Loss = 0.567245
Epoch 2.29: Loss = 0.545273
Epoch 2.30: Loss = 0.5513
Epoch 2.31: Loss = 0.468979
Epoch 2.32: Loss = 0.426559
Epoch 2.33: Loss = 0.47937
Epoch 2.34: Loss = 0.522705
Epoch 2.35: Loss = 0.54039
Epoch 2.36: Loss = 0.492386
Epoch 2.37: Loss = 0.488098
Epoch 2.38: Loss = 0.483978
Epoch 2.39: Loss = 0.541412
Epoch 2.40: Loss = 0.502625
Epoch 2.41: Loss = 0.57106
Epoch 2.42: Loss = 0.547455
Epoch 2.43: Loss = 0.50528
Epoch 2.44: Loss = 0.503464
Epoch 2.45: Loss = 0.536026
Epoch 2.46: Loss = 0.455643
Epoch 2.47: Loss = 0.43718
Epoch 2.48: Loss = 0.507751
Epoch 2.49: Loss = 0.513199
Epoch 2.50: Loss = 0.50238
Epoch 2.51: Loss = 0.498016
Epoch 2.52: Loss = 0.491409
Epoch 2.53: Loss = 0.462982
Epoch 2.54: Loss = 0.550354
Epoch 2.55: Loss = 0.504517
Epoch 2.56: Loss = 0.546417
Epoch 2.57: Loss = 0.473648
Epoch 2.58: Loss = 0.465652
Epoch 2.59: Loss = 0.530075
Epoch 2.60: Loss = 0.548721
Epoch 2.61: Loss = 0.586227
Epoch 2.62: Loss = 0.458176
Epoch 2.63: Loss = 0.463379
Epoch 2.64: Loss = 0.526566
Epoch 2.65: Loss = 0.507324
Epoch 2.66: Loss = 0.486069
Epoch 2.67: Loss = 0.438995
Epoch 2.68: Loss = 0.472824
Epoch 2.69: Loss = 0.478729
Epoch 2.70: Loss = 0.453781
Epoch 2.71: Loss = 0.458496
Epoch 2.72: Loss = 0.487305
Epoch 2.73: Loss = 0.49118
Epoch 2.74: Loss = 0.467636
Epoch 2.75: Loss = 0.459091
Epoch 2.76: Loss = 0.521225
Epoch 2.77: Loss = 0.551941
Epoch 2.78: Loss = 0.557251
Epoch 2.79: Loss = 0.431717
Epoch 2.80: Loss = 0.411346
Epoch 2.81: Loss = 0.489319
Epoch 2.82: Loss = 0.455948
Epoch 2.83: Loss = 0.461044
Epoch 2.84: Loss = 0.479218
Epoch 2.85: Loss = 0.458679
Epoch 2.86: Loss = 0.418137
Epoch 2.87: Loss = 0.494324
Epoch 2.88: Loss = 0.465988
Epoch 2.89: Loss = 0.486679
Epoch 2.90: Loss = 0.456863
Epoch 2.91: Loss = 0.475784
Epoch 2.92: Loss = 0.521652
Epoch 2.93: Loss = 0.477158
Epoch 2.94: Loss = 0.508102
Epoch 2.95: Loss = 0.459549
Epoch 2.96: Loss = 0.484055
Epoch 2.97: Loss = 0.47023
Epoch 2.98: Loss = 0.462814
Epoch 2.99: Loss = 0.406845
Epoch 2.100: Loss = 0.450012
TRAIN LOSS = 0.509781
TRAIN ACC = 85.0357 % (51024/60000)
Loss = 0.498718
Loss = 0.501709
Loss = 0.648544
Loss = 0.586182
Loss = 0.464691
Loss = 0.488495
Loss = 0.595886
Loss = 0.52713
Loss = 0.392395
Loss = 0.322113
Loss = 0.340134
Loss = 0.366714
Loss = 0.288406
Loss = 0.328247
Loss = 0.149704
Loss = 0.289032
Loss = 0.62117
TEST LOSS = 0.432133
TEST ACC = 510.239 % (8729/10000)
Reducing learning rate to 0.0888977
Epoch 3.1: Loss = 0.442383
Epoch 3.2: Loss = 0.458893
Epoch 3.3: Loss = 0.411072
Epoch 3.4: Loss = 0.448196
Epoch 3.5: Loss = 0.401443
Epoch 3.6: Loss = 0.474335
Epoch 3.7: Loss = 0.471466
Epoch 3.8: Loss = 0.478836
Epoch 3.9: Loss = 0.520203
Epoch 3.10: Loss = 0.488464
Epoch 3.11: Loss = 0.451797
Epoch 3.12: Loss = 0.448441
Epoch 3.13: Loss = 0.46286
Epoch 3.14: Loss = 0.445572
Epoch 3.15: Loss = 0.498322
Epoch 3.16: Loss = 0.457916
Epoch 3.17: Loss = 0.464447
Epoch 3.18: Loss = 0.474777
Epoch 3.19: Loss = 0.42308
Epoch 3.20: Loss = 0.460709
Epoch 3.21: Loss = 0.484192
Epoch 3.22: Loss = 0.458847
Epoch 3.23: Loss = 0.406631
Epoch 3.24: Loss = 0.432907
Epoch 3.25: Loss = 0.438889
Epoch 3.26: Loss = 0.427124
Epoch 3.27: Loss = 0.392822
Epoch 3.28: Loss = 0.435638
Epoch 3.29: Loss = 0.484299
Epoch 3.30: Loss = 0.422272
Epoch 3.31: Loss = 0.383011
Epoch 3.32: Loss = 0.396469
Epoch 3.33: Loss = 0.381927
Epoch 3.34: Loss = 0.472473
Epoch 3.35: Loss = 0.51297
Epoch 3.36: Loss = 0.452332
Epoch 3.37: Loss = 0.460709
Epoch 3.38: Loss = 0.396057
Epoch 3.39: Loss = 0.43454
Epoch 3.40: Loss = 0.398712
Epoch 3.41: Loss = 0.39682
Epoch 3.42: Loss = 0.451111
Epoch 3.43: Loss = 0.434097
Epoch 3.44: Loss = 0.386322
Epoch 3.45: Loss = 0.415924
Epoch 3.46: Loss = 0.527863
Epoch 3.47: Loss = 0.462021
Epoch 3.48: Loss = 0.544754
Epoch 3.49: Loss = 0.414368
Epoch 3.50: Loss = 0.373672
Epoch 3.51: Loss = 0.476624
Epoch 3.52: Loss = 0.413269
Epoch 3.53: Loss = 0.429794
Epoch 3.54: Loss = 0.467743
Epoch 3.55: Loss = 0.442261
Epoch 3.56: Loss = 0.457169
Epoch 3.57: Loss = 0.459122
Epoch 3.58: Loss = 0.459579
Epoch 3.59: Loss = 0.463684
Epoch 3.60: Loss = 0.41304
Epoch 3.61: Loss = 0.428131
Epoch 3.62: Loss = 0.396576
Epoch 3.63: Loss = 0.484192
Epoch 3.64: Loss = 0.454941
Epoch 3.65: Loss = 0.446808
Epoch 3.66: Loss = 0.421921
Epoch 3.67: Loss = 0.419342
Epoch 3.68: Loss = 0.377426
Epoch 3.69: Loss = 0.435287
Epoch 3.70: Loss = 0.368454
Epoch 3.71: Loss = 0.509903
Epoch 3.72: Loss = 0.418732
Epoch 3.73: Loss = 0.486038
Epoch 3.74: Loss = 0.390717
Epoch 3.75: Loss = 0.390335
Epoch 3.76: Loss = 0.451889
Epoch 3.77: Loss = 0.48494
Epoch 3.78: Loss = 0.396591
Epoch 3.79: Loss = 0.388184
Epoch 3.80: Loss = 0.457596
Epoch 3.81: Loss = 0.390381
Epoch 3.82: Loss = 0.369995
Epoch 3.83: Loss = 0.437134
Epoch 3.84: Loss = 0.440536
Epoch 3.85: Loss = 0.460953
Epoch 3.86: Loss = 0.387482
Epoch 3.87: Loss = 0.472107
Epoch 3.88: Loss = 0.384979
Epoch 3.89: Loss = 0.3992
Epoch 3.90: Loss = 0.377472
Epoch 3.91: Loss = 0.406372
Epoch 3.92: Loss = 0.40097
Epoch 3.93: Loss = 0.418945
Epoch 3.94: Loss = 0.399902
Epoch 3.95: Loss = 0.398636
Epoch 3.96: Loss = 0.463181
Epoch 3.97: Loss = 0.458405
Epoch 3.98: Loss = 0.403839
Epoch 3.99: Loss = 0.429794
Epoch 3.100: Loss = 0.596741
TRAIN LOSS = 0.438522
TRAIN ACC = 86.7996 % (52082/60000)
Loss = 0.445999
Loss = 0.458679
Loss = 0.602066
Loss = 0.554291
Loss = 0.422302
Loss = 0.436996
Loss = 0.566238
Loss = 0.487274
Loss = 0.353821
Loss = 0.28891
Loss = 0.316345
Loss = 0.31424
Loss = 0.251328
Loss = 0.32872
Loss = 0.113205
Loss = 0.250031
Loss = 0.614044
TEST LOSS = 0.395988
TEST ACC = 520.819 % (8819/10000)
Reducing learning rate to 0.0833435
Epoch 4.1: Loss = 0.434784
Epoch 4.2: Loss = 0.327179
Epoch 4.3: Loss = 0.412766
Epoch 4.4: Loss = 0.513687
Epoch 4.5: Loss = 0.370041
Epoch 4.6: Loss = 0.412308
Epoch 4.7: Loss = 0.370453
Epoch 4.8: Loss = 0.465363
Epoch 4.9: Loss = 0.378265
Epoch 4.10: Loss = 0.413055
Epoch 4.11: Loss = 0.364029
Epoch 4.12: Loss = 0.414658
Epoch 4.13: Loss = 0.494522
Epoch 4.14: Loss = 0.432632
Epoch 4.15: Loss = 0.406067
Epoch 4.16: Loss = 0.378662
Epoch 4.17: Loss = 0.484512
Epoch 4.18: Loss = 0.378586
Epoch 4.19: Loss = 0.452347
Epoch 4.20: Loss = 0.453705
Epoch 4.21: Loss = 0.441559
Epoch 4.22: Loss = 0.429901
Epoch 4.23: Loss = 0.435181
Epoch 4.24: Loss = 0.46199
Epoch 4.25: Loss = 0.456665
Epoch 4.26: Loss = 0.393875
Epoch 4.27: Loss = 0.418564
Epoch 4.28: Loss = 0.378204
Epoch 4.29: Loss = 0.441513
Epoch 4.30: Loss = 0.438522
Epoch 4.31: Loss = 0.356842
Epoch 4.32: Loss = 0.401871
Epoch 4.33: Loss = 0.36557
Epoch 4.34: Loss = 0.444855
Epoch 4.35: Loss = 0.407822
Epoch 4.36: Loss = 0.384583
Epoch 4.37: Loss = 0.349274
Epoch 4.38: Loss = 0.363998
Epoch 4.39: Loss = 0.415039
Epoch 4.40: Loss = 0.352966
Epoch 4.41: Loss = 0.450027
Epoch 4.42: Loss = 0.416153
Epoch 4.43: Loss = 0.399536
Epoch 4.44: Loss = 0.446304
Epoch 4.45: Loss = 0.390076
Epoch 4.46: Loss = 0.366302
Epoch 4.47: Loss = 0.365891
Epoch 4.48: Loss = 0.390701
Epoch 4.49: Loss = 0.39946
Epoch 4.50: Loss = 0.438309
Epoch 4.51: Loss = 0.407227
Epoch 4.52: Loss = 0.427155
Epoch 4.53: Loss = 0.432037
Epoch 4.54: Loss = 0.450653
Epoch 4.55: Loss = 0.463959
Epoch 4.56: Loss = 0.424911
Epoch 4.57: Loss = 0.498032
Epoch 4.58: Loss = 0.461761
Epoch 4.59: Loss = 0.451767
Epoch 4.60: Loss = 0.317612
Epoch 4.61: Loss = 0.411545
Epoch 4.62: Loss = 0.425476
Epoch 4.63: Loss = 0.383347
Epoch 4.64: Loss = 0.401993
Epoch 4.65: Loss = 0.366714
Epoch 4.66: Loss = 0.455597
Epoch 4.67: Loss = 0.391144
Epoch 4.68: Loss = 0.365295
Epoch 4.69: Loss = 0.407623
Epoch 4.70: Loss = 0.399506
Epoch 4.71: Loss = 0.492432
Epoch 4.72: Loss = 0.45256
Epoch 4.73: Loss = 0.425995
Epoch 4.74: Loss = 0.480255
Epoch 4.75: Loss = 0.401337
Epoch 4.76: Loss = 0.366379
Epoch 4.77: Loss = 0.457855
Epoch 4.78: Loss = 0.452011
Epoch 4.79: Loss = 0.400482
Epoch 4.80: Loss = 0.422638
Epoch 4.81: Loss = 0.409515
Epoch 4.82: Loss = 0.417313
Epoch 4.83: Loss = 0.379761
Epoch 4.84: Loss = 0.400284
Epoch 4.85: Loss = 0.485031
Epoch 4.86: Loss = 0.41037
Epoch 4.87: Loss = 0.3909
Epoch 4.88: Loss = 0.370392
Epoch 4.89: Loss = 0.392532
Epoch 4.90: Loss = 0.387192
Epoch 4.91: Loss = 0.397736
Epoch 4.92: Loss = 0.472977
Epoch 4.93: Loss = 0.408966
Epoch 4.94: Loss = 0.345139
Epoch 4.95: Loss = 0.363419
Epoch 4.96: Loss = 0.41745
Epoch 4.97: Loss = 0.485168
Epoch 4.98: Loss = 0.407715
Epoch 4.99: Loss = 0.430283
Epoch 4.100: Loss = 0.357849
TRAIN LOSS = 0.413849
TRAIN ACC = 87.5351 % (52523/60000)
Loss = 0.424088
Loss = 0.454987
Loss = 0.600998
Loss = 0.551468
Loss = 0.389969
Loss = 0.412262
Loss = 0.559525
Loss = 0.474045
Loss = 0.350616
Loss = 0.275436
Loss = 0.325897
Loss = 0.298477
Loss = 0.222595
Loss = 0.305176
Loss = 0.0986633
Loss = 0.219223
Loss = 0.615509
TEST LOSS = 0.382426
TEST ACC = 525.229 % (8857/10000)
Reducing learning rate to 0.0777893
Epoch 5.1: Loss = 0.385742
Epoch 5.2: Loss = 0.299011
Epoch 5.3: Loss = 0.436508
Epoch 5.4: Loss = 0.45517
Epoch 5.5: Loss = 0.458694
Epoch 5.6: Loss = 0.466446
Epoch 5.7: Loss = 0.336823
Epoch 5.8: Loss = 0.421341
Epoch 5.9: Loss = 0.41893
Epoch 5.10: Loss = 0.358704
Epoch 5.11: Loss = 0.396118
Epoch 5.12: Loss = 0.347305
Epoch 5.13: Loss = 0.408981
Epoch 5.14: Loss = 0.475784
Epoch 5.15: Loss = 0.366898
Epoch 5.16: Loss = 0.398956
Epoch 5.17: Loss = 0.389999
Epoch 5.18: Loss = 0.339127
Epoch 5.19: Loss = 0.387344
Epoch 5.20: Loss = 0.381592
Epoch 5.21: Loss = 0.449387
Epoch 5.22: Loss = 0.392944
Epoch 5.23: Loss = 0.415009
Epoch 5.24: Loss = 0.448471
Epoch 5.25: Loss = 0.377625
Epoch 5.26: Loss = 0.443954
Epoch 5.27: Loss = 0.318649
Epoch 5.28: Loss = 0.408066
Epoch 5.29: Loss = 0.419174
Epoch 5.30: Loss = 0.363449
Epoch 5.31: Loss = 0.433075
Epoch 5.32: Loss = 0.450928
Epoch 5.33: Loss = 0.379486
Epoch 5.34: Loss = 0.359528
Epoch 5.35: Loss = 0.439163
Epoch 5.36: Loss = 0.412994
Epoch 5.37: Loss = 0.456207
Epoch 5.38: Loss = 0.375412
Epoch 5.39: Loss = 0.500473
Epoch 5.40: Loss = 0.426071
Epoch 5.41: Loss = 0.447128
Epoch 5.42: Loss = 0.426117
Epoch 5.43: Loss = 0.418381
Epoch 5.44: Loss = 0.498505
Epoch 5.45: Loss = 0.379639
Epoch 5.46: Loss = 0.366623
Epoch 5.47: Loss = 0.396255
Epoch 5.48: Loss = 0.459961
Epoch 5.49: Loss = 0.379883
Epoch 5.50: Loss = 0.390121
Epoch 5.51: Loss = 0.401184
Epoch 5.52: Loss = 0.359024
Epoch 5.53: Loss = 0.452713
Epoch 5.54: Loss = 0.405319
Epoch 5.55: Loss = 0.339966
Epoch 5.56: Loss = 0.376312
Epoch 5.57: Loss = 0.44722
Epoch 5.58: Loss = 0.38913
Epoch 5.59: Loss = 0.406982
Epoch 5.60: Loss = 0.378693
Epoch 5.61: Loss = 0.435455
Epoch 5.62: Loss = 0.35907
Epoch 5.63: Loss = 0.35704
Epoch 5.64: Loss = 0.484421
Epoch 5.65: Loss = 0.353043
Epoch 5.66: Loss = 0.381348
Epoch 5.67: Loss = 0.402802
Epoch 5.68: Loss = 0.470108
Epoch 5.69: Loss = 0.388336
Epoch 5.70: Loss = 0.345612
Epoch 5.71: Loss = 0.38562
Epoch 5.72: Loss = 0.42067
Epoch 5.73: Loss = 0.366974
Epoch 5.74: Loss = 0.425369
Epoch 5.75: Loss = 0.378418
Epoch 5.76: Loss = 0.446564
Epoch 5.77: Loss = 0.362518
Epoch 5.78: Loss = 0.429138
Epoch 5.79: Loss = 0.416763
Epoch 5.80: Loss = 0.440369
Epoch 5.81: Loss = 0.354965
Epoch 5.82: Loss = 0.314774
Epoch 5.83: Loss = 0.424316
Epoch 5.84: Loss = 0.32692
Epoch 5.85: Loss = 0.337875
Epoch 5.86: Loss = 0.446014
Epoch 5.87: Loss = 0.42952
Epoch 5.88: Loss = 0.346909
Epoch 5.89: Loss = 0.316269
Epoch 5.90: Loss = 0.373871
Epoch 5.91: Loss = 0.439178
Epoch 5.92: Loss = 0.341797
Epoch 5.93: Loss = 0.374283
Epoch 5.94: Loss = 0.492462
Epoch 5.95: Loss = 0.447144
Epoch 5.96: Loss = 0.45961
Epoch 5.97: Loss = 0.403824
Epoch 5.98: Loss = 0.419357
Epoch 5.99: Loss = 0.42894
Epoch 5.100: Loss = 0.355377
TRAIN LOSS = 0.402039
TRAIN ACC = 88.1378 % (52885/60000)
Loss = 0.420044
Loss = 0.463089
Loss = 0.595322
Loss = 0.549728
Loss = 0.38768
Loss = 0.410645
Loss = 0.568359
Loss = 0.473267
Loss = 0.334763
Loss = 0.284393
Loss = 0.322205
Loss = 0.278488
Loss = 0.202988
Loss = 0.273224
Loss = 0.0900269
Loss = 0.225525
Loss = 0.589478
TEST LOSS = 0.376364
TEST ACC = 528.85 % (8886/10000)
Reducing learning rate to 0.0722351
Epoch 6.1: Loss = 0.379456
Epoch 6.2: Loss = 0.402222
Epoch 6.3: Loss = 0.398712
Epoch 6.4: Loss = 0.466034
Epoch 6.5: Loss = 0.462997
Epoch 6.6: Loss = 0.40892
Epoch 6.7: Loss = 0.371887
Epoch 6.8: Loss = 0.331238
Epoch 6.9: Loss = 0.397476
Epoch 6.10: Loss = 0.418198
Epoch 6.11: Loss = 0.317261
Epoch 6.12: Loss = 0.443802
Epoch 6.13: Loss = 0.421753
Epoch 6.14: Loss = 0.399414
Epoch 6.15: Loss = 0.459183
Epoch 6.16: Loss = 0.416992
Epoch 6.17: Loss = 0.366623
Epoch 6.18: Loss = 0.383316
Epoch 6.19: Loss = 0.362015
Epoch 6.20: Loss = 0.391922
Epoch 6.21: Loss = 0.423233
Epoch 6.22: Loss = 0.407333
Epoch 6.23: Loss = 0.415634
Epoch 6.24: Loss = 0.304428
Epoch 6.25: Loss = 0.400848
Epoch 6.26: Loss = 0.359406
Epoch 6.27: Loss = 0.371658
Epoch 6.28: Loss = 0.39357
Epoch 6.29: Loss = 0.421341
Epoch 6.30: Loss = 0.429123
Epoch 6.31: Loss = 0.300369
Epoch 6.32: Loss = 0.3797
Epoch 6.33: Loss = 0.339417
Epoch 6.34: Loss = 0.37204
Epoch 6.35: Loss = 0.409637
Epoch 6.36: Loss = 0.383896
Epoch 6.37: Loss = 0.379135
Epoch 6.38: Loss = 0.392258
Epoch 6.39: Loss = 0.353958
Epoch 6.40: Loss = 0.384018
Epoch 6.41: Loss = 0.345749
Epoch 6.42: Loss = 0.353851
Epoch 6.43: Loss = 0.376465
Epoch 6.44: Loss = 0.349167
Epoch 6.45: Loss = 0.318619
Epoch 6.46: Loss = 0.45784
Epoch 6.47: Loss = 0.437973
Epoch 6.48: Loss = 0.378815
Epoch 6.49: Loss = 0.37674
Epoch 6.50: Loss = 0.343414
Epoch 6.51: Loss = 0.470917
Epoch 6.52: Loss = 0.471939
Epoch 6.53: Loss = 0.435028
Epoch 6.54: Loss = 0.406891
Epoch 6.55: Loss = 0.353714
Epoch 6.56: Loss = 0.446579
Epoch 6.57: Loss = 0.392624
Epoch 6.58: Loss = 0.362259
Epoch 6.59: Loss = 0.455658
Epoch 6.60: Loss = 0.386612
Epoch 6.61: Loss = 0.390381
Epoch 6.62: Loss = 0.313736
Epoch 6.63: Loss = 0.358994
Epoch 6.64: Loss = 0.436127
Epoch 6.65: Loss = 0.367218
Epoch 6.66: Loss = 0.388077
Epoch 6.67: Loss = 0.408371
Epoch 6.68: Loss = 0.427155
Epoch 6.69: Loss = 0.405823
Epoch 6.70: Loss = 0.49263
Epoch 6.71: Loss = 0.407913
Epoch 6.72: Loss = 0.428848
Epoch 6.73: Loss = 0.376068
Epoch 6.74: Loss = 0.360519
Epoch 6.75: Loss = 0.347092
Epoch 6.76: Loss = 0.438766
Epoch 6.77: Loss = 0.420303
Epoch 6.78: Loss = 0.36998
Epoch 6.79: Loss = 0.400986
Epoch 6.80: Loss = 0.325012
Epoch 6.81: Loss = 0.333588
Epoch 6.82: Loss = 0.344269
Epoch 6.83: Loss = 0.373978
Epoch 6.84: Loss = 0.397308
Epoch 6.85: Loss = 0.367188
Epoch 6.86: Loss = 0.363434
Epoch 6.87: Loss = 0.422043
Epoch 6.88: Loss = 0.383682
Epoch 6.89: Loss = 0.505798
Epoch 6.90: Loss = 0.39856
Epoch 6.91: Loss = 0.448502
Epoch 6.92: Loss = 0.394882
Epoch 6.93: Loss = 0.472778
Epoch 6.94: Loss = 0.408722
Epoch 6.95: Loss = 0.367279
Epoch 6.96: Loss = 0.507172
Epoch 6.97: Loss = 0.385529
Epoch 6.98: Loss = 0.422241
Epoch 6.99: Loss = 0.353546
Epoch 6.100: Loss = 0.344559
TRAIN LOSS = 0.394012
TRAIN ACC = 88.4949 % (53098/60000)
Loss = 0.405685
Loss = 0.438019
Loss = 0.593262
Loss = 0.546204
Loss = 0.36969
Loss = 0.391693
Loss = 0.549469
Loss = 0.448517
Loss = 0.331833
Loss = 0.284698
Loss = 0.31778
Loss = 0.259796
Loss = 0.187119
Loss = 0.281891
Loss = 0.0890503
Loss = 0.22554
Loss = 0.564102
TEST LOSS = 0.365779
TEST ACC = 530.978 % (8916/10000)
Reducing learning rate to 0.0666809
Epoch 7.1: Loss = 0.397156
Epoch 7.2: Loss = 0.36911
Epoch 7.3: Loss = 0.353088
Epoch 7.4: Loss = 0.411377
Epoch 7.5: Loss = 0.420837
Epoch 7.6: Loss = 0.427338
Epoch 7.7: Loss = 0.331284
Epoch 7.8: Loss = 0.358536
Epoch 7.9: Loss = 0.361191
Epoch 7.10: Loss = 0.428864
Epoch 7.11: Loss = 0.434555
Epoch 7.12: Loss = 0.494339
Epoch 7.13: Loss = 0.344254
Epoch 7.14: Loss = 0.453201
Epoch 7.15: Loss = 0.447449
Epoch 7.16: Loss = 0.334518
Epoch 7.17: Loss = 0.388062
Epoch 7.18: Loss = 0.350388
Epoch 7.19: Loss = 0.484512
Epoch 7.20: Loss = 0.351349
Epoch 7.21: Loss = 0.435944
Epoch 7.22: Loss = 0.383484
Epoch 7.23: Loss = 0.380875
Epoch 7.24: Loss = 0.381317
Epoch 7.25: Loss = 0.46109
Epoch 7.26: Loss = 0.43248
Epoch 7.27: Loss = 0.44696
Epoch 7.28: Loss = 0.401489
Epoch 7.29: Loss = 0.389557
Epoch 7.30: Loss = 0.342026
Epoch 7.31: Loss = 0.360764
Epoch 7.32: Loss = 0.361832
Epoch 7.33: Loss = 0.298767
Epoch 7.34: Loss = 0.479523
Epoch 7.35: Loss = 0.389618
Epoch 7.36: Loss = 0.397034
Epoch 7.37: Loss = 0.457932
Epoch 7.38: Loss = 0.354477
Epoch 7.39: Loss = 0.422852
Epoch 7.40: Loss = 0.481003
Epoch 7.41: Loss = 0.428162
Epoch 7.42: Loss = 0.27562
Epoch 7.43: Loss = 0.317703
Epoch 7.44: Loss = 0.368317
Epoch 7.45: Loss = 0.380203
Epoch 7.46: Loss = 0.449966
Epoch 7.47: Loss = 0.31485
Epoch 7.48: Loss = 0.367996
Epoch 7.49: Loss = 0.408203
Epoch 7.50: Loss = 0.394241
Epoch 7.51: Loss = 0.361099
Epoch 7.52: Loss = 0.448181
Epoch 7.53: Loss = 0.451782
Epoch 7.54: Loss = 0.317078
Epoch 7.55: Loss = 0.422867
Epoch 7.56: Loss = 0.356522
Epoch 7.57: Loss = 0.293625
Epoch 7.58: Loss = 0.357086
Epoch 7.59: Loss = 0.457291
Epoch 7.60: Loss = 0.331512
Epoch 7.61: Loss = 0.417358
Epoch 7.62: Loss = 0.390198
Epoch 7.63: Loss = 0.425247
Epoch 7.64: Loss = 0.427643
Epoch 7.65: Loss = 0.447083
Epoch 7.66: Loss = 0.353195
Epoch 7.67: Loss = 0.352051
Epoch 7.68: Loss = 0.413147
Epoch 7.69: Loss = 0.372025
Epoch 7.70: Loss = 0.445053
Epoch 7.71: Loss = 0.332672
Epoch 7.72: Loss = 0.33429
Epoch 7.73: Loss = 0.385956
Epoch 7.74: Loss = 0.331696
Epoch 7.75: Loss = 0.408371
Epoch 7.76: Loss = 0.286987
Epoch 7.77: Loss = 0.413467
Epoch 7.78: Loss = 0.366745
Epoch 7.79: Loss = 0.508331
Epoch 7.80: Loss = 0.333023
Epoch 7.81: Loss = 0.326782
Epoch 7.82: Loss = 0.437363
Epoch 7.83: Loss = 0.391968
Epoch 7.84: Loss = 0.312607
Epoch 7.85: Loss = 0.420776
Epoch 7.86: Loss = 0.492661
Epoch 7.87: Loss = 0.317505
Epoch 7.88: Loss = 0.367523
Epoch 7.89: Loss = 0.416
Epoch 7.90: Loss = 0.373199
Epoch 7.91: Loss = 0.407547
Epoch 7.92: Loss = 0.343674
Epoch 7.93: Loss = 0.373352
Epoch 7.94: Loss = 0.404572
Epoch 7.95: Loss = 0.381622
Epoch 7.96: Loss = 0.413422
Epoch 7.97: Loss = 0.354614
Epoch 7.98: Loss = 0.387634
Epoch 7.99: Loss = 0.349609
Epoch 7.100: Loss = 0.405197
TRAIN LOSS = 0.389252
TRAIN ACC = 88.739 % (53246/60000)
Loss = 0.411789
Loss = 0.449646
Loss = 0.599121
Loss = 0.548615
Loss = 0.37529
Loss = 0.403778
Loss = 0.553207
Loss = 0.463226
Loss = 0.323029
Loss = 0.283401
Loss = 0.310181
Loss = 0.237656
Loss = 0.189575
Loss = 0.265533
Loss = 0.0955048
Loss = 0.227814
Loss = 0.583313
TEST LOSS = 0.367574
TEST ACC = 532.458 % (8917/10000)
Reducing learning rate to 0.0611267
Epoch 8.1: Loss = 0.369461
Epoch 8.2: Loss = 0.353195
Epoch 8.3: Loss = 0.275955
Epoch 8.4: Loss = 0.425095
Epoch 8.5: Loss = 0.493912
Epoch 8.6: Loss = 0.411057
Epoch 8.7: Loss = 0.334305
Epoch 8.8: Loss = 0.338821
Epoch 8.9: Loss = 0.397247
Epoch 8.10: Loss = 0.503677
Epoch 8.11: Loss = 0.364197
Epoch 8.12: Loss = 0.465088
Epoch 8.13: Loss = 0.396759
Epoch 8.14: Loss = 0.328537
Epoch 8.15: Loss = 0.330444
Epoch 8.16: Loss = 0.37915
Epoch 8.17: Loss = 0.426727
Epoch 8.18: Loss = 0.368423
Epoch 8.19: Loss = 0.310898
Epoch 8.20: Loss = 0.267395
Epoch 8.21: Loss = 0.413651
Epoch 8.22: Loss = 0.425079
Epoch 8.23: Loss = 0.398056
Epoch 8.24: Loss = 0.388596
Epoch 8.25: Loss = 0.383911
Epoch 8.26: Loss = 0.339386
Epoch 8.27: Loss = 0.44104
Epoch 8.28: Loss = 0.342133
Epoch 8.29: Loss = 0.292923
Epoch 8.30: Loss = 0.428864
Epoch 8.31: Loss = 0.388397
Epoch 8.32: Loss = 0.36409
Epoch 8.33: Loss = 0.431702
Epoch 8.34: Loss = 0.398254
Epoch 8.35: Loss = 0.350815
Epoch 8.36: Loss = 0.358154
Epoch 8.37: Loss = 0.428757
Epoch 8.38: Loss = 0.356552
Epoch 8.39: Loss = 0.439041
Epoch 8.40: Loss = 0.391296
Epoch 8.41: Loss = 0.481979
Epoch 8.42: Loss = 0.379715
Epoch 8.43: Loss = 0.391602
Epoch 8.44: Loss = 0.478149
Epoch 8.45: Loss = 0.315567
Epoch 8.46: Loss = 0.365234
Epoch 8.47: Loss = 0.414673
Epoch 8.48: Loss = 0.426712
Epoch 8.49: Loss = 0.392761
Epoch 8.50: Loss = 0.390839
Epoch 8.51: Loss = 0.463348
Epoch 8.52: Loss = 0.441086
Epoch 8.53: Loss = 0.325089
Epoch 8.54: Loss = 0.367996
Epoch 8.55: Loss = 0.310593
Epoch 8.56: Loss = 0.444229
Epoch 8.57: Loss = 0.377335
Epoch 8.58: Loss = 0.334183
Epoch 8.59: Loss = 0.337296
Epoch 8.60: Loss = 0.392578
Epoch 8.61: Loss = 0.400391
Epoch 8.62: Loss = 0.435974
Epoch 8.63: Loss = 0.368713
Epoch 8.64: Loss = 0.492661
Epoch 8.65: Loss = 0.406464
Epoch 8.66: Loss = 0.365936
Epoch 8.67: Loss = 0.315369
Epoch 8.68: Loss = 0.383484
Epoch 8.69: Loss = 0.414413
Epoch 8.70: Loss = 0.448624
Epoch 8.71: Loss = 0.432358
Epoch 8.72: Loss = 0.394623
Epoch 8.73: Loss = 0.388504
Epoch 8.74: Loss = 0.306366
Epoch 8.75: Loss = 0.312531
Epoch 8.76: Loss = 0.43161
Epoch 8.77: Loss = 0.380234
Epoch 8.78: Loss = 0.330673
Epoch 8.79: Loss = 0.432358
Epoch 8.80: Loss = 0.357147
Epoch 8.81: Loss = 0.438126
Epoch 8.82: Loss = 0.417603
Epoch 8.83: Loss = 0.400467
Epoch 8.84: Loss = 0.418762
Epoch 8.85: Loss = 0.352692
Epoch 8.86: Loss = 0.422714
Epoch 8.87: Loss = 0.337891
Epoch 8.88: Loss = 0.328156
Epoch 8.89: Loss = 0.438385
Epoch 8.90: Loss = 0.445541
Epoch 8.91: Loss = 0.368668
Epoch 8.92: Loss = 0.379333
Epoch 8.93: Loss = 0.402939
Epoch 8.94: Loss = 0.391022
Epoch 8.95: Loss = 0.343658
Epoch 8.96: Loss = 0.324631
Epoch 8.97: Loss = 0.406845
Epoch 8.98: Loss = 0.345886
Epoch 8.99: Loss = 0.372284
Epoch 8.100: Loss = 0.343506
TRAIN LOSS = 0.386093
TRAIN ACC = 88.8535 % (53314/60000)
Loss = 0.405121
Loss = 0.437759
Loss = 0.584244
Loss = 0.544983
Loss = 0.374435
Loss = 0.394943
Loss = 0.543854
Loss = 0.45993
Loss = 0.32019
Loss = 0.266693
Loss = 0.316742
Loss = 0.2258
Loss = 0.188004
Loss = 0.272018
Loss = 0.0870819
Loss = 0.234589
Loss = 0.562439
TEST LOSS = 0.361881
TEST ACC = 533.139 % (8945/10000)
Reducing learning rate to 0.0555725
Epoch 9.1: Loss = 0.394867
Epoch 9.2: Loss = 0.439972
Epoch 9.3: Loss = 0.377502
Epoch 9.4: Loss = 0.378632
Epoch 9.5: Loss = 0.330322
Epoch 9.6: Loss = 0.475204
Epoch 9.7: Loss = 0.443268
Epoch 9.8: Loss = 0.404221
Epoch 9.9: Loss = 0.316055
Epoch 9.10: Loss = 0.373199
Epoch 9.11: Loss = 0.411484
Epoch 9.12: Loss = 0.320587
Epoch 9.13: Loss = 0.33255
Epoch 9.14: Loss = 0.381744
Epoch 9.15: Loss = 0.365982
Epoch 9.16: Loss = 0.413544
Epoch 9.17: Loss = 0.338165
Epoch 9.18: Loss = 0.344604
Epoch 9.19: Loss = 0.335297
Epoch 9.20: Loss = 0.306549
Epoch 9.21: Loss = 0.4104
Epoch 9.22: Loss = 0.412979
Epoch 9.23: Loss = 0.426041
Epoch 9.24: Loss = 0.444183
Epoch 9.25: Loss = 0.306503
Epoch 9.26: Loss = 0.377975
Epoch 9.27: Loss = 0.467194
Epoch 9.28: Loss = 0.296463
Epoch 9.29: Loss = 0.32373
Epoch 9.30: Loss = 0.373932
Epoch 9.31: Loss = 0.413055
Epoch 9.32: Loss = 0.37648
Epoch 9.33: Loss = 0.392136
Epoch 9.34: Loss = 0.351746
Epoch 9.35: Loss = 0.387558
Epoch 9.36: Loss = 0.380295
Epoch 9.37: Loss = 0.368851
Epoch 9.38: Loss = 0.407486
Epoch 9.39: Loss = 0.346542
Epoch 9.40: Loss = 0.401428
Epoch 9.41: Loss = 0.299042
Epoch 9.42: Loss = 0.344574
Epoch 9.43: Loss = 0.30188
Epoch 9.44: Loss = 0.366608
Epoch 9.45: Loss = 0.425064
Epoch 9.46: Loss = 0.283463
Epoch 9.47: Loss = 0.39946
Epoch 9.48: Loss = 0.352005
Epoch 9.49: Loss = 0.466721
Epoch 9.50: Loss = 0.433121
Epoch 9.51: Loss = 0.358643
Epoch 9.52: Loss = 0.406036
Epoch 9.53: Loss = 0.355148
Epoch 9.54: Loss = 0.46347
Epoch 9.55: Loss = 0.309464
Epoch 9.56: Loss = 0.412933
Epoch 9.57: Loss = 0.551376
Epoch 9.58: Loss = 0.49501
Epoch 9.59: Loss = 0.322723
Epoch 9.60: Loss = 0.433273
Epoch 9.61: Loss = 0.329163
Epoch 9.62: Loss = 0.324432
Epoch 9.63: Loss = 0.396118
Epoch 9.64: Loss = 0.402817
Epoch 9.65: Loss = 0.401016
Epoch 9.66: Loss = 0.376816
Epoch 9.67: Loss = 0.387894
Epoch 9.68: Loss = 0.340256
Epoch 9.69: Loss = 0.303909
Epoch 9.70: Loss = 0.391861
Epoch 9.71: Loss = 0.336746
Epoch 9.72: Loss = 0.384354
Epoch 9.73: Loss = 0.371841
Epoch 9.74: Loss = 0.401413
Epoch 9.75: Loss = 0.455963
Epoch 9.76: Loss = 0.369293
Epoch 9.77: Loss = 0.353241
Epoch 9.78: Loss = 0.410828
Epoch 9.79: Loss = 0.418106
Epoch 9.80: Loss = 0.345413
Epoch 9.81: Loss = 0.395126
Epoch 9.82: Loss = 0.306259
Epoch 9.83: Loss = 0.375961
Epoch 9.84: Loss = 0.399033
Epoch 9.85: Loss = 0.340134
Epoch 9.86: Loss = 0.319351
Epoch 9.87: Loss = 0.402542
Epoch 9.88: Loss = 0.375778
Epoch 9.89: Loss = 0.28183
Epoch 9.90: Loss = 0.412384
Epoch 9.91: Loss = 0.393417
Epoch 9.92: Loss = 0.373749
Epoch 9.93: Loss = 0.441757
Epoch 9.94: Loss = 0.381027
Epoch 9.95: Loss = 0.495102
Epoch 9.96: Loss = 0.436646
Epoch 9.97: Loss = 0.360321
Epoch 9.98: Loss = 0.310486
Epoch 9.99: Loss = 0.414337
Epoch 9.100: Loss = 0.403198
TRAIN LOSS = 0.380493
TRAIN ACC = 89.1434 % (53487/60000)
Loss = 0.392105
Loss = 0.427856
Loss = 0.572937
Loss = 0.532547
Loss = 0.364761
Loss = 0.386398
Loss = 0.54863
Loss = 0.461502
Loss = 0.307999
Loss = 0.241989
Loss = 0.317123
Loss = 0.211838
Loss = 0.177231
Loss = 0.257706
Loss = 0.0861053
Loss = 0.230942
Loss = 0.573181
TEST LOSS = 0.353987
TEST ACC = 534.869 % (8980/10000)
Reducing learning rate to 0.0500183
Epoch 10.1: Loss = 0.475403
Epoch 10.2: Loss = 0.416992
Epoch 10.3: Loss = 0.371002
Epoch 10.4: Loss = 0.307922
Epoch 10.5: Loss = 0.397003
Epoch 10.6: Loss = 0.380402
Epoch 10.7: Loss = 0.365112
Epoch 10.8: Loss = 0.437149
Epoch 10.9: Loss = 0.378143
Epoch 10.10: Loss = 0.420181
Epoch 10.11: Loss = 0.373306
Epoch 10.12: Loss = 0.396866
Epoch 10.13: Loss = 0.370926
Epoch 10.14: Loss = 0.361938
Epoch 10.15: Loss = 0.341339
Epoch 10.16: Loss = 0.44136
Epoch 10.17: Loss = 0.316132
Epoch 10.18: Loss = 0.351852
Epoch 10.19: Loss = 0.388641
Epoch 10.20: Loss = 0.421204
Epoch 10.21: Loss = 0.423416
Epoch 10.22: Loss = 0.333847
Epoch 10.23: Loss = 0.478958
Epoch 10.24: Loss = 0.409851
Epoch 10.25: Loss = 0.439926
Epoch 10.26: Loss = 0.354324
Epoch 10.27: Loss = 0.322144
Epoch 10.28: Loss = 0.333725
Epoch 10.29: Loss = 0.372986
Epoch 10.30: Loss = 0.337967
Epoch 10.31: Loss = 0.320404
Epoch 10.32: Loss = 0.315247
Epoch 10.33: Loss = 0.470627
Epoch 10.34: Loss = 0.457535
Epoch 10.35: Loss = 0.440262
Epoch 10.36: Loss = 0.373688
Epoch 10.37: Loss = 0.375458
Epoch 10.38: Loss = 0.416504
Epoch 10.39: Loss = 0.359116
Epoch 10.40: Loss = 0.291412
Epoch 10.41: Loss = 0.359314
Epoch 10.42: Loss = 0.321793
Epoch 10.43: Loss = 0.376984
Epoch 10.44: Loss = 0.343811
Epoch 10.45: Loss = 0.291855
Epoch 10.46: Loss = 0.423798
Epoch 10.47: Loss = 0.323105
Epoch 10.48: Loss = 0.418396
Epoch 10.49: Loss = 0.361908
Epoch 10.50: Loss = 0.337845
Epoch 10.51: Loss = 0.333054
Epoch 10.52: Loss = 0.278976
Epoch 10.53: Loss = 0.425415
Epoch 10.54: Loss = 0.333008
Epoch 10.55: Loss = 0.331848
Epoch 10.56: Loss = 0.4384
Epoch 10.57: Loss = 0.370468
Epoch 10.58: Loss = 0.414734
Epoch 10.59: Loss = 0.351578
Epoch 10.60: Loss = 0.48613
Epoch 10.61: Loss = 0.330841
Epoch 10.62: Loss = 0.41423
Epoch 10.63: Loss = 0.343155
Epoch 10.64: Loss = 0.431946
Epoch 10.65: Loss = 0.359222
Epoch 10.66: Loss = 0.377655
Epoch 10.67: Loss = 0.36351
Epoch 10.68: Loss = 0.377426
Epoch 10.69: Loss = 0.332352
Epoch 10.70: Loss = 0.340439
Epoch 10.71: Loss = 0.341721
Epoch 10.72: Loss = 0.440353
Epoch 10.73: Loss = 0.445282
Epoch 10.74: Loss = 0.473373
Epoch 10.75: Loss = 0.466476
Epoch 10.76: Loss = 0.365479
Epoch 10.77: Loss = 0.400925
Epoch 10.78: Loss = 0.388519
Epoch 10.79: Loss = 0.311157
Epoch 10.80: Loss = 0.328674
Epoch 10.81: Loss = 0.365463
Epoch 10.82: Loss = 0.35376
Epoch 10.83: Loss = 0.395462
Epoch 10.84: Loss = 0.312607
Epoch 10.85: Loss = 0.4534
Epoch 10.86: Loss = 0.404663
Epoch 10.87: Loss = 0.409515
Epoch 10.88: Loss = 0.340073
Epoch 10.89: Loss = 0.280807
Epoch 10.90: Loss = 0.292191
Epoch 10.91: Loss = 0.336075
Epoch 10.92: Loss = 0.372238
Epoch 10.93: Loss = 0.41423
Epoch 10.94: Loss = 0.446548
Epoch 10.95: Loss = 0.431427
Epoch 10.96: Loss = 0.322189
Epoch 10.97: Loss = 0.415039
Epoch 10.98: Loss = 0.440857
Epoch 10.99: Loss = 0.305222
Epoch 10.100: Loss = 0.331894
TRAIN LOSS = 0.377182
TRAIN ACC = 89.3265 % (53598/60000)
Loss = 0.395569
Loss = 0.424438
Loss = 0.570313
Loss = 0.527588
Loss = 0.363281
Loss = 0.381729
Loss = 0.555878
Loss = 0.456467
Loss = 0.303131
Loss = 0.233551
Loss = 0.342331
Loss = 0.216873
Loss = 0.16803
Loss = 0.262589
Loss = 0.08284
Loss = 0.227524
Loss = 0.588379
TEST LOSS = 0.354263
TEST ACC = 535.979 % (8983/10000)
Epoch 11.1: Loss = 0.405487
Epoch 11.2: Loss = 0.457108
Epoch 11.3: Loss = 0.343582
Epoch 11.4: Loss = 0.405884
Epoch 11.5: Loss = 0.3806
Epoch 11.6: Loss = 0.316956
Epoch 11.7: Loss = 0.461365
Epoch 11.8: Loss = 0.342163
Epoch 11.9: Loss = 0.560837
Epoch 11.10: Loss = 0.340073
Epoch 11.11: Loss = 0.45134
Epoch 11.12: Loss = 0.298889
Epoch 11.13: Loss = 0.41156
Epoch 11.14: Loss = 0.405228
Epoch 11.15: Loss = 0.360107
Epoch 11.16: Loss = 0.4254
Epoch 11.17: Loss = 0.350067
Epoch 11.18: Loss = 0.324768
Epoch 11.19: Loss = 0.312607
Epoch 11.20: Loss = 0.307892
Epoch 11.21: Loss = 0.395462
Epoch 11.22: Loss = 0.34404
Epoch 11.23: Loss = 0.378799
Epoch 11.24: Loss = 0.348755
Epoch 11.25: Loss = 0.334946
Epoch 11.26: Loss = 0.384827
Epoch 11.27: Loss = 0.379059
Epoch 11.28: Loss = 0.429764
Epoch 11.29: Loss = 0.395203
Epoch 11.30: Loss = 0.343872
Epoch 11.31: Loss = 0.366928
Epoch 11.32: Loss = 0.349487
Epoch 11.33: Loss = 0.315079
Epoch 11.34: Loss = 0.341904
Epoch 11.35: Loss = 0.38446
Epoch 11.36: Loss = 0.410782
Epoch 11.37: Loss = 0.442291
Epoch 11.38: Loss = 0.306747
Epoch 11.39: Loss = 0.377014
Epoch 11.40: Loss = 0.373459
Epoch 11.41: Loss = 0.385086
Epoch 11.42: Loss = 0.434616
Epoch 11.43: Loss = 0.410522
Epoch 11.44: Loss = 0.385132
Epoch 11.45: Loss = 0.347198
Epoch 11.46: Loss = 0.340256
Epoch 11.47: Loss = 0.359512
Epoch 11.48: Loss = 0.408508
Epoch 11.49: Loss = 0.285721
Epoch 11.50: Loss = 0.441269
Epoch 11.51: Loss = 0.355972
Epoch 11.52: Loss = 0.343552
Epoch 11.53: Loss = 0.418152
Epoch 11.54: Loss = 0.380203
Epoch 11.55: Loss = 0.350815
Epoch 11.56: Loss = 0.360764
Epoch 11.57: Loss = 0.306198
Epoch 11.58: Loss = 0.401611
Epoch 11.59: Loss = 0.315201
Epoch 11.60: Loss = 0.266296
Epoch 11.61: Loss = 0.350601
Epoch 11.62: Loss = 0.353058
Epoch 11.63: Loss = 0.348709
Epoch 11.64: Loss = 0.38176
Epoch 11.65: Loss = 0.397217
Epoch 11.66: Loss = 0.336334
Epoch 11.67: Loss = 0.356766
Epoch 11.68: Loss = 0.404785
Epoch 11.69: Loss = 0.330994
Epoch 11.70: Loss = 0.31105
Epoch 11.71: Loss = 0.451691
Epoch 11.72: Loss = 0.384689
Epoch 11.73: Loss = 0.38591
Epoch 11.74: Loss = 0.361618
Epoch 11.75: Loss = 0.372101
Epoch 11.76: Loss = 0.532959
Epoch 11.77: Loss = 0.372589
Epoch 11.78: Loss = 0.382904
Epoch 11.79: Loss = 0.473145
Epoch 11.80: Loss = 0.304977
Epoch 11.81: Loss = 0.3936
Epoch 11.82: Loss = 0.323776
Epoch 11.83: Loss = 0.281387
Epoch 11.84: Loss = 0.449005
Epoch 11.85: Loss = 0.389908
Epoch 11.86: Loss = 0.386826
Epoch 11.87: Loss = 0.38884
Epoch 11.88: Loss = 0.404999
Epoch 11.89: Loss = 0.360229
Epoch 11.90: Loss = 0.378113
Epoch 11.91: Loss = 0.36554
Epoch 11.92: Loss = 0.333298
Epoch 11.93: Loss = 0.321335
Epoch 11.94: Loss = 0.376663
Epoch 11.95: Loss = 0.344315
Epoch 11.96: Loss = 0.478439
Epoch 11.97: Loss = 0.318771
Epoch 11.98: Loss = 0.33252
Epoch 11.99: Loss = 0.424057
Epoch 11.100: Loss = 0.351334
TRAIN LOSS = 0.373611
TRAIN ACC = 89.5966 % (53760/60000)
Loss = 0.386002
Loss = 0.412308
Loss = 0.56398
Loss = 0.53363
Loss = 0.342361
Loss = 0.374252
Loss = 0.546448
Loss = 0.453354
Loss = 0.295334
Loss = 0.228333
Loss = 0.353088
Loss = 0.221298
Loss = 0.162979
Loss = 0.27272
Loss = 0.0830994
Loss = 0.218613
Loss = 0.590195
TEST LOSS = 0.350476
TEST ACC = 537.599 % (9007/10000)
Epoch 12.1: Loss = 0.437042
Epoch 12.2: Loss = 0.352112
Epoch 12.3: Loss = 0.365158
Epoch 12.4: Loss = 0.392166
Epoch 12.5: Loss = 0.28566
Epoch 12.6: Loss = 0.426804
Epoch 12.7: Loss = 0.450714
Epoch 12.8: Loss = 0.372879
Epoch 12.9: Loss = 0.379395
Epoch 12.10: Loss = 0.395172
Epoch 12.11: Loss = 0.387451
Epoch 12.12: Loss = 0.368652
Epoch 12.13: Loss = 0.413544
Epoch 12.14: Loss = 0.346664
Epoch 12.15: Loss = 0.44664
Epoch 12.16: Loss = 0.381409
Epoch 12.17: Loss = 0.296265
Epoch 12.18: Loss = 0.448059
Epoch 12.19: Loss = 0.374893
Epoch 12.20: Loss = 0.382751
Epoch 12.21: Loss = 0.342926
Epoch 12.22: Loss = 0.361908
Epoch 12.23: Loss = 0.322403
Epoch 12.24: Loss = 0.343323
Epoch 12.25: Loss = 0.42128
Epoch 12.26: Loss = 0.403793
Epoch 12.27: Loss = 0.360901
Epoch 12.28: Loss = 0.391586
Epoch 12.29: Loss = 0.362946
Epoch 12.30: Loss = 0.3918
Epoch 12.31: Loss = 0.402313
Epoch 12.32: Loss = 0.46759
Epoch 12.33: Loss = 0.310303
Epoch 12.34: Loss = 0.389374
Epoch 12.35: Loss = 0.422256
Epoch 12.36: Loss = 0.33992
Epoch 12.37: Loss = 0.358627
Epoch 12.38: Loss = 0.397522
Epoch 12.39: Loss = 0.415283
Epoch 12.40: Loss = 0.395859
Epoch 12.41: Loss = 0.371689
Epoch 12.42: Loss = 0.340134
Epoch 12.43: Loss = 0.369049
Epoch 12.44: Loss = 0.291672
Epoch 12.45: Loss = 0.334534
Epoch 12.46: Loss = 0.433716
Epoch 12.47: Loss = 0.385361
Epoch 12.48: Loss = 0.291519
Epoch 12.49: Loss = 0.352951
Epoch 12.50: Loss = 0.39212
Epoch 12.51: Loss = 0.312469
Epoch 12.52: Loss = 0.28183
Epoch 12.53: Loss = 0.400452
Epoch 12.54: Loss = 0.365631
Epoch 12.55: Loss = 0.344162
Epoch 12.56: Loss = 0.416031
Epoch 12.57: Loss = 0.441544
Epoch 12.58: Loss = 0.322479
Epoch 12.59: Loss = 0.344849
Epoch 12.60: Loss = 0.324005
Epoch 12.61: Loss = 0.318314
Epoch 12.62: Loss = 0.30365
Epoch 12.63: Loss = 0.28476
Epoch 12.64: Loss = 0.480988
Epoch 12.65: Loss = 0.366531
Epoch 12.66: Loss = 0.394989
Epoch 12.67: Loss = 0.3703
Epoch 12.68: Loss = 0.414948
Epoch 12.69: Loss = 0.36232
Epoch 12.70: Loss = 0.358017
Epoch 12.71: Loss = 0.383286
Epoch 12.72: Loss = 0.35437
Epoch 12.73: Loss = 0.374939
Epoch 12.74: Loss = 0.308731
Epoch 12.75: Loss = 0.415649
Epoch 12.76: Loss = 0.305878
Epoch 12.77: Loss = 0.378006
Epoch 12.78: Loss = 0.352936
Epoch 12.79: Loss = 0.38681
Epoch 12.80: Loss = 0.311386
Epoch 12.81: Loss = 0.408005
Epoch 12.82: Loss = 0.406799
Epoch 12.83: Loss = 0.37532
Epoch 12.84: Loss = 0.41394
Epoch 12.85: Loss = 0.341064
Epoch 12.86: Loss = 0.394806
Epoch 12.87: Loss = 0.361755
Epoch 12.88: Loss = 0.45047
Epoch 12.89: Loss = 0.323624
Epoch 12.90: Loss = 0.438583
Epoch 12.91: Loss = 0.316147
Epoch 12.92: Loss = 0.305542
Epoch 12.93: Loss = 0.290131
Epoch 12.94: Loss = 0.354645
Epoch 12.95: Loss = 0.321503
Epoch 12.96: Loss = 0.350342
Epoch 12.97: Loss = 0.322754
Epoch 12.98: Loss = 0.430878
Epoch 12.99: Loss = 0.346252
Epoch 12.100: Loss = 0.33725
TRAIN LOSS = 0.36937
TRAIN ACC = 89.8178 % (53893/60000)
Loss = 0.376877
Loss = 0.393692
Loss = 0.5504
Loss = 0.516418
Loss = 0.333633
Loss = 0.364212
Loss = 0.537994
Loss = 0.445206
Loss = 0.292068
Loss = 0.234314
Loss = 0.353683
Loss = 0.220535
Loss = 0.165024
Loss = 0.264755
Loss = 0.0809021
Loss = 0.220901
Loss = 0.578842
TEST LOSS = 0.344191
TEST ACC = 538.93 % (9047/10000)
Epoch 13.1: Loss = 0.43721
Epoch 13.2: Loss = 0.3255
Epoch 13.3: Loss = 0.45961
Epoch 13.4: Loss = 0.365219
Epoch 13.5: Loss = 0.339188
Epoch 13.6: Loss = 0.314224
Epoch 13.7: Loss = 0.369812
Epoch 13.8: Loss = 0.397079
Epoch 13.9: Loss = 0.287674
Epoch 13.10: Loss = 0.379578
Epoch 13.11: Loss = 0.360031
Epoch 13.12: Loss = 0.339005
Epoch 13.13: Loss = 0.283493
Epoch 13.14: Loss = 0.368927
Epoch 13.15: Loss = 0.268799
Epoch 13.16: Loss = 0.370224
Epoch 13.17: Loss = 0.385864
Epoch 13.18: Loss = 0.446808
Epoch 13.19: Loss = 0.35257
Epoch 13.20: Loss = 0.315063
Epoch 13.21: Loss = 0.376541
Epoch 13.22: Loss = 0.310791
Epoch 13.23: Loss = 0.366943
Epoch 13.24: Loss = 0.456543
Epoch 13.25: Loss = 0.36055
Epoch 13.26: Loss = 0.306091
Epoch 13.27: Loss = 0.356277
Epoch 13.28: Loss = 0.31694
Epoch 13.29: Loss = 0.3293
Epoch 13.30: Loss = 0.383057
Epoch 13.31: Loss = 0.331833
Epoch 13.32: Loss = 0.397034
Epoch 13.33: Loss = 0.36972
Epoch 13.34: Loss = 0.363251
Epoch 13.35: Loss = 0.297714
Epoch 13.36: Loss = 0.285828
Epoch 13.37: Loss = 0.272934
Epoch 13.38: Loss = 0.331146
Epoch 13.39: Loss = 0.314117
Epoch 13.40: Loss = 0.325623
Epoch 13.41: Loss = 0.372437
Epoch 13.42: Loss = 0.361542
Epoch 13.43: Loss = 0.330017
Epoch 13.44: Loss = 0.340515
Epoch 13.45: Loss = 0.317276
Epoch 13.46: Loss = 0.378754
Epoch 13.47: Loss = 0.384262
Epoch 13.48: Loss = 0.376343
Epoch 13.49: Loss = 0.424408
Epoch 13.50: Loss = 0.380142
Epoch 13.51: Loss = 0.351044
Epoch 13.52: Loss = 0.373032
Epoch 13.53: Loss = 0.452057
Epoch 13.54: Loss = 0.439941
Epoch 13.55: Loss = 0.366318
Epoch 13.56: Loss = 0.432114
Epoch 13.57: Loss = 0.293106
Epoch 13.58: Loss = 0.267181
Epoch 13.59: Loss = 0.410629
Epoch 13.60: Loss = 0.423111
Epoch 13.61: Loss = 0.323059
Epoch 13.62: Loss = 0.398026
Epoch 13.63: Loss = 0.420593
Epoch 13.64: Loss = 0.376663
Epoch 13.65: Loss = 0.359818
Epoch 13.66: Loss = 0.283432
Epoch 13.67: Loss = 0.449966
Epoch 13.68: Loss = 0.300278
Epoch 13.69: Loss = 0.341248
Epoch 13.70: Loss = 0.437393
Epoch 13.71: Loss = 0.385406
Epoch 13.72: Loss = 0.289169
Epoch 13.73: Loss = 0.479614
Epoch 13.74: Loss = 0.365509
Epoch 13.75: Loss = 0.294449
Epoch 13.76: Loss = 0.401627
Epoch 13.77: Loss = 0.385834
Epoch 13.78: Loss = 0.385361
Epoch 13.79: Loss = 0.460342
Epoch 13.80: Loss = 0.381912
Epoch 13.81: Loss = 0.370956
Epoch 13.82: Loss = 0.37944
Epoch 13.83: Loss = 0.362915
Epoch 13.84: Loss = 0.32785
Epoch 13.85: Loss = 0.338501
Epoch 13.86: Loss = 0.271774
Epoch 13.87: Loss = 0.403473
Epoch 13.88: Loss = 0.388748
Epoch 13.89: Loss = 0.39296
Epoch 13.90: Loss = 0.38147
Epoch 13.91: Loss = 0.352081
Epoch 13.92: Loss = 0.468124
Epoch 13.93: Loss = 0.466537
Epoch 13.94: Loss = 0.359955
Epoch 13.95: Loss = 0.42009
Epoch 13.96: Loss = 0.416672
Epoch 13.97: Loss = 0.394485
Epoch 13.98: Loss = 0.363495
Epoch 13.99: Loss = 0.324554
Epoch 13.100: Loss = 0.377304
TRAIN LOSS = 0.365738
TRAIN ACC = 89.9689 % (53983/60000)
Loss = 0.375946
Loss = 0.398163
Loss = 0.54834
Loss = 0.525009
Loss = 0.32959
Loss = 0.363022
Loss = 0.527802
Loss = 0.434738
Loss = 0.286713
Loss = 0.241409
Loss = 0.34024
Loss = 0.217026
Loss = 0.159592
Loss = 0.260544
Loss = 0.0750275
Loss = 0.21077
Loss = 0.574371
TEST LOSS = 0.340611
TEST ACC = 539.828 % (9052/10000)
Epoch 14.1: Loss = 0.36615
Epoch 14.2: Loss = 0.453354
Epoch 14.3: Loss = 0.33786
Epoch 14.4: Loss = 0.363052
Epoch 14.5: Loss = 0.272751
Epoch 14.6: Loss = 0.383133
Epoch 14.7: Loss = 0.379181
Epoch 14.8: Loss = 0.334885
Epoch 14.9: Loss = 0.365356
Epoch 14.10: Loss = 0.404007
Epoch 14.11: Loss = 0.284317
Epoch 14.12: Loss = 0.35054
Epoch 14.13: Loss = 0.35379
Epoch 14.14: Loss = 0.370392
Epoch 14.15: Loss = 0.38504
Epoch 14.16: Loss = 0.345047
Epoch 14.17: Loss = 0.314728
Epoch 14.18: Loss = 0.318039
Epoch 14.19: Loss = 0.402664
Epoch 14.20: Loss = 0.323029
Epoch 14.21: Loss = 0.370621
Epoch 14.22: Loss = 0.424225
Epoch 14.23: Loss = 0.410034
Epoch 14.24: Loss = 0.387466
Epoch 14.25: Loss = 0.350967
Epoch 14.26: Loss = 0.314957
Epoch 14.27: Loss = 0.360764
Epoch 14.28: Loss = 0.471893
Epoch 14.29: Loss = 0.376663
Epoch 14.30: Loss = 0.39711
Epoch 14.31: Loss = 0.419937
Epoch 14.32: Loss = 0.352036
Epoch 14.33: Loss = 0.366241
Epoch 14.34: Loss = 0.395599
Epoch 14.35: Loss = 0.346375
Epoch 14.36: Loss = 0.444778
Epoch 14.37: Loss = 0.355057
Epoch 14.38: Loss = 0.411285
Epoch 14.39: Loss = 0.363083
Epoch 14.40: Loss = 0.332825
Epoch 14.41: Loss = 0.375824
Epoch 14.42: Loss = 0.465332
Epoch 14.43: Loss = 0.346405
Epoch 14.44: Loss = 0.413437
Epoch 14.45: Loss = 0.35611
Epoch 14.46: Loss = 0.430054
Epoch 14.47: Loss = 0.357956
Epoch 14.48: Loss = 0.318695
Epoch 14.49: Loss = 0.35701
Epoch 14.50: Loss = 0.349716
Epoch 14.51: Loss = 0.375809
Epoch 14.52: Loss = 0.336868
Epoch 14.53: Loss = 0.438812
Epoch 14.54: Loss = 0.440979
Epoch 14.55: Loss = 0.34906
Epoch 14.56: Loss = 0.447556
Epoch 14.57: Loss = 0.330902
Epoch 14.58: Loss = 0.342499
Epoch 14.59: Loss = 0.392731
Epoch 14.60: Loss = 0.421814
Epoch 14.61: Loss = 0.337097
Epoch 14.62: Loss = 0.366714
Epoch 14.63: Loss = 0.374619
Epoch 14.64: Loss = 0.220337
Epoch 14.65: Loss = 0.275192
Epoch 14.66: Loss = 0.347351
Epoch 14.67: Loss = 0.424149
Epoch 14.68: Loss = 0.411743
Epoch 14.69: Loss = 0.28154
Epoch 14.70: Loss = 0.440353
Epoch 14.71: Loss = 0.313049
Epoch 14.72: Loss = 0.416199
Epoch 14.73: Loss = 0.380798
Epoch 14.74: Loss = 0.393463
Epoch 14.75: Loss = 0.26886
Epoch 14.76: Loss = 0.329346
Epoch 14.77: Loss = 0.354172
Epoch 14.78: Loss = 0.354965
Epoch 14.79: Loss = 0.432343
Epoch 14.80: Loss = 0.36824
Epoch 14.81: Loss = 0.347885
Epoch 14.82: Loss = 0.348892
Epoch 14.83: Loss = 0.277313
Epoch 14.84: Loss = 0.401596
Epoch 14.85: Loss = 0.259369
Epoch 14.86: Loss = 0.296066
Epoch 14.87: Loss = 0.269058
Epoch 14.88: Loss = 0.32843
Epoch 14.89: Loss = 0.408997
Epoch 14.90: Loss = 0.356018
Epoch 14.91: Loss = 0.357468
Epoch 14.92: Loss = 0.444275
Epoch 14.93: Loss = 0.385895
Epoch 14.94: Loss = 0.37175
Epoch 14.95: Loss = 0.309174
Epoch 14.96: Loss = 0.353119
Epoch 14.97: Loss = 0.327881
Epoch 14.98: Loss = 0.398422
Epoch 14.99: Loss = 0.39209
Epoch 14.100: Loss = 0.281433
TRAIN LOSS = 0.36412
TRAIN ACC = 90.0955 % (54059/60000)
Loss = 0.371475
Loss = 0.396652
Loss = 0.542694
Loss = 0.534943
Loss = 0.335022
Loss = 0.363953
Loss = 0.536926
Loss = 0.428513
Loss = 0.281097
Loss = 0.235367
Loss = 0.341446
Loss = 0.214371
Loss = 0.155838
Loss = 0.250839
Loss = 0.0768433
Loss = 0.222488
Loss = 0.598099
TEST LOSS = 0.341232
TEST ACC = 540.588 % (9087/10000)
Epoch 15.1: Loss = 0.4263
Epoch 15.2: Loss = 0.371811
Epoch 15.3: Loss = 0.405212
Epoch 15.4: Loss = 0.328888
Epoch 15.5: Loss = 0.3759
Epoch 15.6: Loss = 0.329865
Epoch 15.7: Loss = 0.409042
Epoch 15.8: Loss = 0.327621
Epoch 15.9: Loss = 0.287567
Epoch 15.10: Loss = 0.25354
Epoch 15.11: Loss = 0.281769
Epoch 15.12: Loss = 0.383682
Epoch 15.13: Loss = 0.393784
Epoch 15.14: Loss = 0.324356
Epoch 15.15: Loss = 0.380951
Epoch 15.16: Loss = 0.406265
Epoch 15.17: Loss = 0.321457
Epoch 15.18: Loss = 0.370361
Epoch 15.19: Loss = 0.414597
Epoch 15.20: Loss = 0.333176
Epoch 15.21: Loss = 0.297455
Epoch 15.22: Loss = 0.410675
Epoch 15.23: Loss = 0.379517
Epoch 15.24: Loss = 0.326828
Epoch 15.25: Loss = 0.389587
Epoch 15.26: Loss = 0.297775
Epoch 15.27: Loss = 0.329391
Epoch 15.28: Loss = 0.32988
Epoch 15.29: Loss = 0.430466
Epoch 15.30: Loss = 0.393082
Epoch 15.31: Loss = 0.439255
Epoch 15.32: Loss = 0.333878
Epoch 15.33: Loss = 0.372879
Epoch 15.34: Loss = 0.28212
Epoch 15.35: Loss = 0.382462
Epoch 15.36: Loss = 0.4021
Epoch 15.37: Loss = 0.440948
Epoch 15.38: Loss = 0.382034
Epoch 15.39: Loss = 0.441757
Epoch 15.40: Loss = 0.493805
Epoch 15.41: Loss = 0.405563
Epoch 15.42: Loss = 0.264252
Epoch 15.43: Loss = 0.431381
Epoch 15.44: Loss = 0.304138
Epoch 15.45: Loss = 0.376587
Epoch 15.46: Loss = 0.354233
Epoch 15.47: Loss = 0.336731
Epoch 15.48: Loss = 0.348389
Epoch 15.49: Loss = 0.363327
Epoch 15.50: Loss = 0.432556
Epoch 15.51: Loss = 0.36972
Epoch 15.52: Loss = 0.375198
Epoch 15.53: Loss = 0.297607
Epoch 15.54: Loss = 0.390579
Epoch 15.55: Loss = 0.332382
Epoch 15.56: Loss = 0.398651
Epoch 15.57: Loss = 0.279007
Epoch 15.58: Loss = 0.38765
Epoch 15.59: Loss = 0.342133
Epoch 15.60: Loss = 0.373734
Epoch 15.61: Loss = 0.354507
Epoch 15.62: Loss = 0.323898
Epoch 15.63: Loss = 0.370544
Epoch 15.64: Loss = 0.335876
Epoch 15.65: Loss = 0.422287
Epoch 15.66: Loss = 0.425323
Epoch 15.67: Loss = 0.410645
Epoch 15.68: Loss = 0.371796
Epoch 15.69: Loss = 0.357376
Epoch 15.70: Loss = 0.406464
Epoch 15.71: Loss = 0.384628
Epoch 15.72: Loss = 0.393265
Epoch 15.73: Loss = 0.279037
Epoch 15.74: Loss = 0.362473
Epoch 15.75: Loss = 0.397232
Epoch 15.76: Loss = 0.299545
Epoch 15.77: Loss = 0.403488
Epoch 15.78: Loss = 0.36145
Epoch 15.79: Loss = 0.32106
Epoch 15.80: Loss = 0.331375
Epoch 15.81: Loss = 0.341644
Epoch 15.82: Loss = 0.418716
Epoch 15.83: Loss = 0.403641
Epoch 15.84: Loss = 0.388107
Epoch 15.85: Loss = 0.297638
Epoch 15.86: Loss = 0.296188
Epoch 15.87: Loss = 0.331802
Epoch 15.88: Loss = 0.362869
Epoch 15.89: Loss = 0.387299
Epoch 15.90: Loss = 0.339142
Epoch 15.91: Loss = 0.388367
Epoch 15.92: Loss = 0.372116
Epoch 15.93: Loss = 0.369537
Epoch 15.94: Loss = 0.405914
Epoch 15.95: Loss = 0.396805
Epoch 15.96: Loss = 0.359665
Epoch 15.97: Loss = 0.357101
Epoch 15.98: Loss = 0.31015
Epoch 15.99: Loss = 0.32341
Epoch 15.100: Loss = 0.416656
TRAIN LOSS = 0.364243
TRAIN ACC = 90.1779 % (54109/60000)
Loss = 0.3806
Loss = 0.399933
Loss = 0.543655
Loss = 0.529633
Loss = 0.331802
Loss = 0.370514
Loss = 0.532135
Loss = 0.428131
Loss = 0.275406
Loss = 0.237015
Loss = 0.339798
Loss = 0.211777
Loss = 0.1474
Loss = 0.259827
Loss = 0.0736084
Loss = 0.211411
Loss = 0.619873
TEST LOSS = 0.341153
TEST ACC = 541.089 % (9092/10000)
Epoch 16.1: Loss = 0.348175
Epoch 16.2: Loss = 0.425476
Epoch 16.3: Loss = 0.25032
Epoch 16.4: Loss = 0.290894
Epoch 16.5: Loss = 0.343323
Epoch 16.6: Loss = 0.386444
Epoch 16.7: Loss = 0.456116
Epoch 16.8: Loss = 0.320374
Epoch 16.9: Loss = 0.349884
Epoch 16.10: Loss = 0.334976
Epoch 16.11: Loss = 0.353638
Epoch 16.12: Loss = 0.386444
Epoch 16.13: Loss = 0.44136
Epoch 16.14: Loss = 0.356705
Epoch 16.15: Loss = 0.287064
Epoch 16.16: Loss = 0.376389
Epoch 16.17: Loss = 0.327423
Epoch 16.18: Loss = 0.491837
Epoch 16.19: Loss = 0.377457
Epoch 16.20: Loss = 0.555099
Epoch 16.21: Loss = 0.334534
Epoch 16.22: Loss = 0.344589
Epoch 16.23: Loss = 0.321182
Epoch 16.24: Loss = 0.307678
Epoch 16.25: Loss = 0.306183
Epoch 16.26: Loss = 0.292404
Epoch 16.27: Loss = 0.326263
Epoch 16.28: Loss = 0.251312
Epoch 16.29: Loss = 0.397125
Epoch 16.30: Loss = 0.366501
Epoch 16.31: Loss = 0.366348
Epoch 16.32: Loss = 0.3405
Epoch 16.33: Loss = 0.429749
Epoch 16.34: Loss = 0.451569
Epoch 16.35: Loss = 0.374573
Epoch 16.36: Loss = 0.378265
Epoch 16.37: Loss = 0.379501
Epoch 16.38: Loss = 0.374222
Epoch 16.39: Loss = 0.346115
Epoch 16.40: Loss = 0.33461
Epoch 16.41: Loss = 0.431808
Epoch 16.42: Loss = 0.424942
Epoch 16.43: Loss = 0.312943
Epoch 16.44: Loss = 0.388641
Epoch 16.45: Loss = 0.36969
Epoch 16.46: Loss = 0.373596
Epoch 16.47: Loss = 0.42572
Epoch 16.48: Loss = 0.412918
Epoch 16.49: Loss = 0.395142
Epoch 16.50: Loss = 0.372162
Epoch 16.51: Loss = 0.375076
Epoch 16.52: Loss = 0.40564
Epoch 16.53: Loss = 0.460846
Epoch 16.54: Loss = 0.277695
Epoch 16.55: Loss = 0.379822
Epoch 16.56: Loss = 0.373047
Epoch 16.57: Loss = 0.441605
Epoch 16.58: Loss = 0.29277
Epoch 16.59: Loss = 0.474152
Epoch 16.60: Loss = 0.284073
Epoch 16.61: Loss = 0.366486
Epoch 16.62: Loss = 0.393784
Epoch 16.63: Loss = 0.339752
Epoch 16.64: Loss = 0.39801
Epoch 16.65: Loss = 0.366333
Epoch 16.66: Loss = 0.421448
Epoch 16.67: Loss = 0.275253
Epoch 16.68: Loss = 0.323013
Epoch 16.69: Loss = 0.370621
Epoch 16.70: Loss = 0.323669
Epoch 16.71: Loss = 0.3172
Epoch 16.72: Loss = 0.333389
Epoch 16.73: Loss = 0.323776
Epoch 16.74: Loss = 0.394608
Epoch 16.75: Loss = 0.364151
Epoch 16.76: Loss = 0.341064
Epoch 16.77: Loss = 0.344452
Epoch 16.78: Loss = 0.288864
Epoch 16.79: Loss = 0.463943
Epoch 16.80: Loss = 0.399384
Epoch 16.81: Loss = 0.290802
Epoch 16.82: Loss = 0.356415
Epoch 16.83: Loss = 0.351578
Epoch 16.84: Loss = 0.398682
Epoch 16.85: Loss = 0.309189
Epoch 16.86: Loss = 0.369156
Epoch 16.87: Loss = 0.376053
Epoch 16.88: Loss = 0.303467
Epoch 16.89: Loss = 0.401978
Epoch 16.90: Loss = 0.376221
Epoch 16.91: Loss = 0.365265
Epoch 16.92: Loss = 0.336243
Epoch 16.93: Loss = 0.399506
Epoch 16.94: Loss = 0.356308
Epoch 16.95: Loss = 0.371857
Epoch 16.96: Loss = 0.368332
Epoch 16.97: Loss = 0.248474
Epoch 16.98: Loss = 0.362457
Epoch 16.99: Loss = 0.28447
Epoch 16.100: Loss = 0.422104
TRAIN LOSS = 0.363525
TRAIN ACC = 90.303 % (54185/60000)
Loss = 0.373367
Loss = 0.398193
Loss = 0.527176
Loss = 0.516815
Loss = 0.336273
Loss = 0.367111
Loss = 0.517761
Loss = 0.428238
Loss = 0.267029
Loss = 0.230972
Loss = 0.342331
Loss = 0.208237
Loss = 0.141129
Loss = 0.258286
Loss = 0.0726776
Loss = 0.209305
Loss = 0.593399
TEST LOSS = 0.33543
TEST ACC = 541.849 % (9102/10000)
Epoch 17.1: Loss = 0.385788
Epoch 17.2: Loss = 0.339554
Epoch 17.3: Loss = 0.33316
Epoch 17.4: Loss = 0.480713
Epoch 17.5: Loss = 0.341125
Epoch 17.6: Loss = 0.453979
Epoch 17.7: Loss = 0.331009
Epoch 17.8: Loss = 0.426804
Epoch 17.9: Loss = 0.381744
Epoch 17.10: Loss = 0.378204
Epoch 17.11: Loss = 0.36673
Epoch 17.12: Loss = 0.279984
Epoch 17.13: Loss = 0.341431
Epoch 17.14: Loss = 0.377304
Epoch 17.15: Loss = 0.313843
Epoch 17.16: Loss = 0.424805
Epoch 17.17: Loss = 0.352036
Epoch 17.18: Loss = 0.459778
Epoch 17.19: Loss = 0.338715
Epoch 17.20: Loss = 0.422226
Epoch 17.21: Loss = 0.39975
Epoch 17.22: Loss = 0.332794
Epoch 17.23: Loss = 0.386581
Epoch 17.24: Loss = 0.371201
Epoch 17.25: Loss = 0.280884
Epoch 17.26: Loss = 0.365417
Epoch 17.27: Loss = 0.351807
Epoch 17.28: Loss = 0.365845
Epoch 17.29: Loss = 0.286942
Epoch 17.30: Loss = 0.348297
Epoch 17.31: Loss = 0.345016
Epoch 17.32: Loss = 0.358231
Epoch 17.33: Loss = 0.382675
Epoch 17.34: Loss = 0.309814
Epoch 17.35: Loss = 0.324661
Epoch 17.36: Loss = 0.340988
Epoch 17.37: Loss = 0.360321
Epoch 17.38: Loss = 0.35321
Epoch 17.39: Loss = 0.432892
Epoch 17.40: Loss = 0.356155
Epoch 17.41: Loss = 0.337784
Epoch 17.42: Loss = 0.394012
Epoch 17.43: Loss = 0.397522
Epoch 17.44: Loss = 0.34346
Epoch 17.45: Loss = 0.276199
Epoch 17.46: Loss = 0.275909
Epoch 17.47: Loss = 0.478928
Epoch 17.48: Loss = 0.435669
Epoch 17.49: Loss = 0.319992
Epoch 17.50: Loss = 0.274963
Epoch 17.51: Loss = 0.345963
Epoch 17.52: Loss = 0.404541
Epoch 17.53: Loss = 0.367081
Epoch 17.54: Loss = 0.347076
Epoch 17.55: Loss = 0.391525
Epoch 17.56: Loss = 0.375473
Epoch 17.57: Loss = 0.340866
Epoch 17.58: Loss = 0.416153
Epoch 17.59: Loss = 0.371826
Epoch 17.60: Loss = 0.364899
Epoch 17.61: Loss = 0.313278
Epoch 17.62: Loss = 0.426224
Epoch 17.63: Loss = 0.303787
Epoch 17.64: Loss = 0.284714
Epoch 17.65: Loss = 0.356873
Epoch 17.66: Loss = 0.361771
Epoch 17.67: Loss = 0.456192
Epoch 17.68: Loss = 0.325195
Epoch 17.69: Loss = 0.267731
Epoch 17.70: Loss = 0.455124
Epoch 17.71: Loss = 0.383698
Epoch 17.72: Loss = 0.347122
Epoch 17.73: Loss = 0.286194
Epoch 17.74: Loss = 0.389221
Epoch 17.75: Loss = 0.41185
Epoch 17.76: Loss = 0.389069
Epoch 17.77: Loss = 0.411163
Epoch 17.78: Loss = 0.399155
Epoch 17.79: Loss = 0.29805
Epoch 17.80: Loss = 0.309113
Epoch 17.81: Loss = 0.338913
Epoch 17.82: Loss = 0.368576
Epoch 17.83: Loss = 0.292847
Epoch 17.84: Loss = 0.352737
Epoch 17.85: Loss = 0.372894
Epoch 17.86: Loss = 0.352539
Epoch 17.87: Loss = 0.367798
Epoch 17.88: Loss = 0.38269
Epoch 17.89: Loss = 0.327545
Epoch 17.90: Loss = 0.37056
Epoch 17.91: Loss = 0.399734
Epoch 17.92: Loss = 0.419403
Epoch 17.93: Loss = 0.261597
Epoch 17.94: Loss = 0.286285
Epoch 17.95: Loss = 0.333771
Epoch 17.96: Loss = 0.43512
Epoch 17.97: Loss = 0.410446
Epoch 17.98: Loss = 0.41806
Epoch 17.99: Loss = 0.412994
Epoch 17.100: Loss = 0.328995
TRAIN LOSS = 0.362518
TRAIN ACC = 90.3351 % (54203/60000)
Loss = 0.358521
Loss = 0.390396
Loss = 0.508881
Loss = 0.524368
Loss = 0.335922
Loss = 0.362
Loss = 0.513092
Loss = 0.434036
Loss = 0.271225
Loss = 0.232132
Loss = 0.363342
Loss = 0.217484
Loss = 0.148315
Loss = 0.254974
Loss = 0.0710144
Loss = 0.204407
Loss = 0.617538
TEST LOSS = 0.336108
TEST ACC = 542.029 % (9104/10000)
Epoch 18.1: Loss = 0.299194
Epoch 18.2: Loss = 0.349854
Epoch 18.3: Loss = 0.393616
Epoch 18.4: Loss = 0.289474
Epoch 18.5: Loss = 0.315094
Epoch 18.6: Loss = 0.369385
Epoch 18.7: Loss = 0.334427
Epoch 18.8: Loss = 0.382599
Epoch 18.9: Loss = 0.336746
Epoch 18.10: Loss = 0.39328
Epoch 18.11: Loss = 0.351898
Epoch 18.12: Loss = 0.366379
Epoch 18.13: Loss = 0.315628
Epoch 18.14: Loss = 0.476288
Epoch 18.15: Loss = 0.386047
Epoch 18.16: Loss = 0.401062
Epoch 18.17: Loss = 0.424561
Epoch 18.18: Loss = 0.263626
Epoch 18.19: Loss = 0.35379
Epoch 18.20: Loss = 0.508118
Epoch 18.21: Loss = 0.449783
Epoch 18.22: Loss = 0.287918
Epoch 18.23: Loss = 0.441208
Epoch 18.24: Loss = 0.360794
Epoch 18.25: Loss = 0.315689
Epoch 18.26: Loss = 0.281204
Epoch 18.27: Loss = 0.321594
Epoch 18.28: Loss = 0.365723
Epoch 18.29: Loss = 0.384964
Epoch 18.30: Loss = 0.339554
Epoch 18.31: Loss = 0.357056
Epoch 18.32: Loss = 0.325409
Epoch 18.33: Loss = 0.39801
Epoch 18.34: Loss = 0.389832
Epoch 18.35: Loss = 0.478012
Epoch 18.36: Loss = 0.319
Epoch 18.37: Loss = 0.277191
Epoch 18.38: Loss = 0.31781
Epoch 18.39: Loss = 0.310577
Epoch 18.40: Loss = 0.25882
Epoch 18.41: Loss = 0.461594
Epoch 18.42: Loss = 0.294846
Epoch 18.43: Loss = 0.418716
Epoch 18.44: Loss = 0.378967
Epoch 18.45: Loss = 0.377594
Epoch 18.46: Loss = 0.414078
Epoch 18.47: Loss = 0.332291
Epoch 18.48: Loss = 0.376083
Epoch 18.49: Loss = 0.344467
Epoch 18.50: Loss = 0.420731
Epoch 18.51: Loss = 0.324356
Epoch 18.52: Loss = 0.335999
Epoch 18.53: Loss = 0.333603
Epoch 18.54: Loss = 0.29834
Epoch 18.55: Loss = 0.328705
Epoch 18.56: Loss = 0.316971
Epoch 18.57: Loss = 0.387161
Epoch 18.58: Loss = 0.397018
Epoch 18.59: Loss = 0.354416
Epoch 18.60: Loss = 0.270569
Epoch 18.61: Loss = 0.333862
Epoch 18.62: Loss = 0.440674
Epoch 18.63: Loss = 0.395905
Epoch 18.64: Loss = 0.272736
Epoch 18.65: Loss = 0.321243
Epoch 18.66: Loss = 0.327164
Epoch 18.67: Loss = 0.337875
Epoch 18.68: Loss = 0.382965
Epoch 18.69: Loss = 0.320328
Epoch 18.70: Loss = 0.289093
Epoch 18.71: Loss = 0.375061
Epoch 18.72: Loss = 0.316879
Epoch 18.73: Loss = 0.452774
Epoch 18.74: Loss = 0.423737
Epoch 18.75: Loss = 0.32045
Epoch 18.76: Loss = 0.399796
Epoch 18.77: Loss = 0.352097
Epoch 18.78: Loss = 0.322586
Epoch 18.79: Loss = 0.345627
Epoch 18.80: Loss = 0.425934
Epoch 18.81: Loss = 0.388916
Epoch 18.82: Loss = 0.395721
Epoch 18.83: Loss = 0.384857
Epoch 18.84: Loss = 0.544968
Epoch 18.85: Loss = 0.309387
Epoch 18.86: Loss = 0.342987
Epoch 18.87: Loss = 0.366379
Epoch 18.88: Loss = 0.412628
Epoch 18.89: Loss = 0.301392
Epoch 18.90: Loss = 0.353241
Epoch 18.91: Loss = 0.425125
Epoch 18.92: Loss = 0.373947
Epoch 18.93: Loss = 0.358246
Epoch 18.94: Loss = 0.424271
Epoch 18.95: Loss = 0.414612
Epoch 18.96: Loss = 0.461884
Epoch 18.97: Loss = 0.31459
Epoch 18.98: Loss = 0.344406
Epoch 18.99: Loss = 0.476563
Epoch 18.100: Loss = 0.308701
TRAIN LOSS = 0.363174
TRAIN ACC = 90.3854 % (54234/60000)
Loss = 0.3638
Loss = 0.397278
Loss = 0.510574
Loss = 0.530533
Loss = 0.339203
Loss = 0.371552
Loss = 0.511734
Loss = 0.446472
Loss = 0.269012
Loss = 0.237366
Loss = 0.361923
Loss = 0.21492
Loss = 0.149185
Loss = 0.26741
Loss = 0.0680847
Loss = 0.207062
Loss = 0.623169
TEST LOSS = 0.339693
TEST ACC = 542.339 % (9090/10000)
Epoch 19.1: Loss = 0.419556
Epoch 19.2: Loss = 0.384766
Epoch 19.3: Loss = 0.352951
Epoch 19.4: Loss = 0.430649
Epoch 19.5: Loss = 0.411591
Epoch 19.6: Loss = 0.265533
Epoch 19.7: Loss = 0.322464
Epoch 19.8: Loss = 0.320801
Epoch 19.9: Loss = 0.410629
Epoch 19.10: Loss = 0.334061
Epoch 19.11: Loss = 0.303528
Epoch 19.12: Loss = 0.402512
Epoch 19.13: Loss = 0.459473
Epoch 19.14: Loss = 0.334579
Epoch 19.15: Loss = 0.382828
Epoch 19.16: Loss = 0.360992
Epoch 19.17: Loss = 0.283752
Epoch 19.18: Loss = 0.309128
Epoch 19.19: Loss = 0.389969
Epoch 19.20: Loss = 0.392776
Epoch 19.21: Loss = 0.347168
Epoch 19.22: Loss = 0.392776
Epoch 19.23: Loss = 0.460861
Epoch 19.24: Loss = 0.415985
Epoch 19.25: Loss = 0.419205
Epoch 19.26: Loss = 0.433701
Epoch 19.27: Loss = 0.338242
Epoch 19.28: Loss = 0.377579
Epoch 19.29: Loss = 0.366287
Epoch 19.30: Loss = 0.330048
Epoch 19.31: Loss = 0.408951
Epoch 19.32: Loss = 0.253143
Epoch 19.33: Loss = 0.242218
Epoch 19.34: Loss = 0.414627
Epoch 19.35: Loss = 0.335587
Epoch 19.36: Loss = 0.433823
Epoch 19.37: Loss = 0.322937
Epoch 19.38: Loss = 0.375931
Epoch 19.39: Loss = 0.296951
Epoch 19.40: Loss = 0.438385
Epoch 19.41: Loss = 0.466705
Epoch 19.42: Loss = 0.400284
Epoch 19.43: Loss = 0.344589
Epoch 19.44: Loss = 0.312164
Epoch 19.45: Loss = 0.371445
Epoch 19.46: Loss = 0.382431
Epoch 19.47: Loss = 0.325012
Epoch 19.48: Loss = 0.360153
Epoch 19.49: Loss = 0.380203
Epoch 19.50: Loss = 0.34436
Epoch 19.51: Loss = 0.279602
Epoch 19.52: Loss = 0.402893
Epoch 19.53: Loss = 0.291367
Epoch 19.54: Loss = 0.413895
Epoch 19.55: Loss = 0.28241
Epoch 19.56: Loss = 0.305725
Epoch 19.57: Loss = 0.373444
Epoch 19.58: Loss = 0.339172
Epoch 19.59: Loss = 0.29248
Epoch 19.60: Loss = 0.338852
Epoch 19.61: Loss = 0.372803
Epoch 19.62: Loss = 0.458328
Epoch 19.63: Loss = 0.310043
Epoch 19.64: Loss = 0.341675
Epoch 19.65: Loss = 0.401993
Epoch 19.66: Loss = 0.383286
Epoch 19.67: Loss = 0.384628
Epoch 19.68: Loss = 0.272385
Epoch 19.69: Loss = 0.408112
Epoch 19.70: Loss = 0.327942
Epoch 19.71: Loss = 0.353851
Epoch 19.72: Loss = 0.316208
Epoch 19.73: Loss = 0.334045
Epoch 19.74: Loss = 0.40477
Epoch 19.75: Loss = 0.351486
Epoch 19.76: Loss = 0.339325
Epoch 19.77: Loss = 0.357513
Epoch 19.78: Loss = 0.361145
Epoch 19.79: Loss = 0.400055
Epoch 19.80: Loss = 0.414856
Epoch 19.81: Loss = 0.313171
Epoch 19.82: Loss = 0.372345
Epoch 19.83: Loss = 0.466339
Epoch 19.84: Loss = 0.288925
Epoch 19.85: Loss = 0.455688
Epoch 19.86: Loss = 0.325867
Epoch 19.87: Loss = 0.297882
Epoch 19.88: Loss = 0.363525
Epoch 19.89: Loss = 0.390411
Epoch 19.90: Loss = 0.312515
Epoch 19.91: Loss = 0.297852
Epoch 19.92: Loss = 0.517319
Epoch 19.93: Loss = 0.354797
Epoch 19.94: Loss = 0.465744
Epoch 19.95: Loss = 0.295288
Epoch 19.96: Loss = 0.411957
Epoch 19.97: Loss = 0.354721
Epoch 19.98: Loss = 0.328506
Epoch 19.99: Loss = 0.349884
Epoch 19.100: Loss = 0.422607
TRAIN LOSS = 0.363663
TRAIN ACC = 90.3809 % (54231/60000)
Loss = 0.371979
Loss = 0.401215
Loss = 0.531189
Loss = 0.539642
Loss = 0.340027
Loss = 0.371246
Loss = 0.520935
Loss = 0.438553
Loss = 0.266083
Loss = 0.23056
Loss = 0.361099
Loss = 0.218506
Loss = 0.146652
Loss = 0.273926
Loss = 0.0724487
Loss = 0.212219
Loss = 0.644073
TEST LOSS = 0.34354
TEST ACC = 542.31 % (9078/10000)
Epoch 20.1: Loss = 0.422333
Epoch 20.2: Loss = 0.429199
Epoch 20.3: Loss = 0.336761
Epoch 20.4: Loss = 0.445328
Epoch 20.5: Loss = 0.379059
Epoch 20.6: Loss = 0.397888
Epoch 20.7: Loss = 0.347488
Epoch 20.8: Loss = 0.447662
Epoch 20.9: Loss = 0.371124
Epoch 20.10: Loss = 0.342621
Epoch 20.11: Loss = 0.317291
Epoch 20.12: Loss = 0.310394
Epoch 20.13: Loss = 0.34343
Epoch 20.14: Loss = 0.343979
Epoch 20.15: Loss = 0.397919
Epoch 20.16: Loss = 0.35376
Epoch 20.17: Loss = 0.446991
Epoch 20.18: Loss = 0.381256
Epoch 20.19: Loss = 0.363907
Epoch 20.20: Loss = 0.279114
Epoch 20.21: Loss = 0.342026
Epoch 20.22: Loss = 0.352798
Epoch 20.23: Loss = 0.387497
Epoch 20.24: Loss = 0.359497
Epoch 20.25: Loss = 0.426285
Epoch 20.26: Loss = 0.34343
Epoch 20.27: Loss = 0.307236
Epoch 20.28: Loss = 0.454666
Epoch 20.29: Loss = 0.270447
Epoch 20.30: Loss = 0.457535
Epoch 20.31: Loss = 0.283203
Epoch 20.32: Loss = 0.409439
Epoch 20.33: Loss = 0.316864
Epoch 20.34: Loss = 0.287888
Epoch 20.35: Loss = 0.304001
Epoch 20.36: Loss = 0.345856
Epoch 20.37: Loss = 0.375229
Epoch 20.38: Loss = 0.295715
Epoch 20.39: Loss = 0.374771
Epoch 20.40: Loss = 0.43576
terminate called after throwing an instance of 'std::runtime_error'
  what():  client 0 already connected
