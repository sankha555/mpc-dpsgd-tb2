Setting up connection 0
***********************************************************
Training MNIST
Model: Dense([60000, 1, 500]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 3
***********************************************************
Epoch 1.1: Loss = 2.42647
Epoch 1.2: Loss = 2.02377
Epoch 1.3: Loss = 1.78319
Epoch 1.4: Loss = 1.58601
Epoch 1.5: Loss = 1.45509
Epoch 1.6: Loss = 1.35051
Epoch 1.7: Loss = 1.23286
Epoch 1.8: Loss = 1.18439
Epoch 1.9: Loss = 1.11201
Epoch 1.10: Loss = 1.03754
Epoch 1.11: Loss = 1.03975
Epoch 1.12: Loss = 1.01208
Epoch 1.13: Loss = 0.951782
Epoch 1.14: Loss = 0.913055
Epoch 1.15: Loss = 0.885147
Epoch 1.16: Loss = 0.899216
Epoch 1.17: Loss = 0.862701
Epoch 1.18: Loss = 0.862396
Epoch 1.19: Loss = 0.861145
Epoch 1.20: Loss = 0.828293
Epoch 1.21: Loss = 0.837936
Epoch 1.22: Loss = 0.786209
Epoch 1.23: Loss = 0.80838
Epoch 1.24: Loss = 0.805389
Epoch 1.25: Loss = 0.772324
Epoch 1.26: Loss = 0.748062
Epoch 1.27: Loss = 0.779968
Epoch 1.28: Loss = 0.761078
Epoch 1.29: Loss = 0.72229
Epoch 1.30: Loss = 0.742233
TRAIN LOSS = 1.06906
TRAIN ACC = 64.2899 % (38575/60000)
Loss = 0.741119
Loss = 0.809219
Loss = 0.75769
Loss = 0.775269
Loss = 0.764099
TEST LOSS = 0.769479
TEST ACC = 385.75 % (7257/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.732574
Epoch 2.2: Loss = 0.749847
Epoch 2.3: Loss = 0.766846
Epoch 2.4: Loss = 0.717148
Epoch 2.5: Loss = 0.712936
Epoch 2.6: Loss = 0.691025
Epoch 2.7: Loss = 0.708191
Epoch 2.8: Loss = 0.708252
Epoch 2.9: Loss = 0.687347
Epoch 2.10: Loss = 0.689529
Epoch 2.11: Loss = 0.681808
Epoch 2.12: Loss = 0.740738
Epoch 2.13: Loss = 0.732056
Epoch 2.14: Loss = 0.723816
Epoch 2.15: Loss = 0.684708
Epoch 2.16: Loss = 0.74115
Epoch 2.17: Loss = 0.666962
Epoch 2.18: Loss = 0.6604
Epoch 2.19: Loss = 0.64856
Epoch 2.20: Loss = 0.721786
Epoch 2.21: Loss = 0.608795
Epoch 2.22: Loss = 0.687622
Epoch 2.23: Loss = 0.677322
Epoch 2.24: Loss = 0.71373
Epoch 2.25: Loss = 0.649399
Epoch 2.26: Loss = 0.657715
Epoch 2.27: Loss = 0.651199
Epoch 2.28: Loss = 0.697906
Epoch 2.29: Loss = 0.636261
Epoch 2.30: Loss = 0.721848
TRAIN LOSS = 0.695602
TRAIN ACC = 76.4679 % (45883/60000)
Loss = 0.63382
Loss = 0.703033
Loss = 0.664246
Loss = 0.664246
Loss = 0.653748
TEST LOSS = 0.663818
TEST ACC = 458.829 % (7732/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.628387
Epoch 3.2: Loss = 0.722321
Epoch 3.3: Loss = 0.653198
Epoch 3.4: Loss = 0.673843
Epoch 3.5: Loss = 0.622208
Epoch 3.6: Loss = 0.675507
Epoch 3.7: Loss = 0.623566
Epoch 3.8: Loss = 0.584442
Epoch 3.9: Loss = 0.642181
Epoch 3.10: Loss = 0.597961
Epoch 3.11: Loss = 0.642487
Epoch 3.12: Loss = 0.631149
Epoch 3.13: Loss = 0.682846
Epoch 3.14: Loss = 0.675583
Epoch 3.15: Loss = 0.635712
Epoch 3.16: Loss = 0.613159
Epoch 3.17: Loss = 0.630966
Epoch 3.18: Loss = 0.683029
Epoch 3.19: Loss = 0.679306
Epoch 3.20: Loss = 0.596176
Epoch 3.21: Loss = 0.702591
Epoch 3.22: Loss = 0.628113
Epoch 3.23: Loss = 0.63974
Epoch 3.24: Loss = 0.607559
Epoch 3.25: Loss = 0.617523
Epoch 3.26: Loss = 0.614822
Epoch 3.27: Loss = 0.626083
Epoch 3.28: Loss = 0.601486
Epoch 3.29: Loss = 0.679428
Epoch 3.30: Loss = 0.636169
TRAIN LOSS = 0.641602
TRAIN ACC = 79.0588 % (47438/60000)
Loss = 0.619324
Loss = 0.700882
Loss = 0.671982
Loss = 0.664764
Loss = 0.657349
TEST LOSS = 0.66286
TEST ACC = 474.379 % (7866/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.63562
Epoch 4.2: Loss = 0.603317
Epoch 4.3: Loss = 0.668015
Epoch 4.4: Loss = 0.569366
Epoch 4.5: Loss = 0.661591
Epoch 4.6: Loss = 0.662369
Epoch 4.7: Loss = 0.630966
Epoch 4.8: Loss = 0.652863
Epoch 4.9: Loss = 0.683395
Epoch 4.10: Loss = 0.660278
Epoch 4.11: Loss = 0.639114
Epoch 4.12: Loss = 0.667542
Epoch 4.13: Loss = 0.674362
Epoch 4.14: Loss = 0.630325
Epoch 4.15: Loss = 0.654877
Epoch 4.16: Loss = 0.611588
Epoch 4.17: Loss = 0.570282
Epoch 4.18: Loss = 0.640747
Epoch 4.19: Loss = 0.574417
Epoch 4.20: Loss = 0.614548
Epoch 4.21: Loss = 0.626663
Epoch 4.22: Loss = 0.585419
Epoch 4.23: Loss = 0.573715
Epoch 4.24: Loss = 0.629395
Epoch 4.25: Loss = 0.642776
Epoch 4.26: Loss = 0.611038
Epoch 4.27: Loss = 0.608627
Epoch 4.28: Loss = 0.651947
Epoch 4.29: Loss = 0.64122
Epoch 4.30: Loss = 0.604233
TRAIN LOSS = 0.629364
TRAIN ACC = 79.7806 % (47870/60000)
Loss = 0.606903
Loss = 0.704224
Loss = 0.672928
Loss = 0.663422
Loss = 0.659821
TEST LOSS = 0.661459
TEST ACC = 478.699 % (7953/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.643768
Epoch 5.2: Loss = 0.632858
Epoch 5.3: Loss = 0.5914
Epoch 5.4: Loss = 0.607895
Epoch 5.5: Loss = 0.598892
Epoch 5.6: Loss = 0.574829
Epoch 5.7: Loss = 0.730255
Epoch 5.8: Loss = 0.583496
Epoch 5.9: Loss = 0.64415
Epoch 5.10: Loss = 0.576385
Epoch 5.11: Loss = 0.685333
Epoch 5.12: Loss = 0.65271
Epoch 5.13: Loss = 0.684372
Epoch 5.14: Loss = 0.626755
Epoch 5.15: Loss = 0.705688
Epoch 5.16: Loss = 0.626755
Epoch 5.17: Loss = 0.664978
Epoch 5.18: Loss = 0.613892
Epoch 5.19: Loss = 0.584091
Epoch 5.20: Loss = 0.612488
Epoch 5.21: Loss = 0.603897
Epoch 5.22: Loss = 0.587616
Epoch 5.23: Loss = 0.623489
Epoch 5.24: Loss = 0.613174
Epoch 5.25: Loss = 0.618607
Epoch 5.26: Loss = 0.608765
Epoch 5.27: Loss = 0.60672
Epoch 5.28: Loss = 0.612549
Epoch 5.29: Loss = 0.612213
Epoch 5.30: Loss = 0.595703
TRAIN LOSS = 0.624146
TRAIN ACC = 80.4169 % (48252/60000)
Loss = 0.579819
Loss = 0.68335
Loss = 0.652847
Loss = 0.639801
Loss = 0.643188
TEST LOSS = 0.639801
TEST ACC = 482.52 % (8011/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.574799
Epoch 6.2: Loss = 0.63559
Epoch 6.3: Loss = 0.564804
Epoch 6.4: Loss = 0.617767
Epoch 6.5: Loss = 0.636002
Epoch 6.6: Loss = 0.639038
Epoch 6.7: Loss = 0.613464
Epoch 6.8: Loss = 0.636734
Epoch 6.9: Loss = 0.671371
Epoch 6.10: Loss = 0.605316
Epoch 6.11: Loss = 0.600113
Epoch 6.12: Loss = 0.591949
Epoch 6.13: Loss = 0.645157
Epoch 6.14: Loss = 0.569839
Epoch 6.15: Loss = 0.621872
Epoch 6.16: Loss = 0.544815
Epoch 6.17: Loss = 0.628464
Epoch 6.18: Loss = 0.572159
Epoch 6.19: Loss = 0.658783
Epoch 6.20: Loss = 0.59877
Epoch 6.21: Loss = 0.618759
Epoch 6.22: Loss = 0.595123
Epoch 6.23: Loss = 0.580521
Epoch 6.24: Loss = 0.627106
Epoch 6.25: Loss = 0.611496
Epoch 6.26: Loss = 0.571228
Epoch 6.27: Loss = 0.618896
Epoch 6.28: Loss = 0.609863
Epoch 6.29: Loss = 0.656555
Epoch 6.30: Loss = 0.555801
TRAIN LOSS = 0.609085
TRAIN ACC = 81.0699 % (48644/60000)
Loss = 0.560486
Loss = 0.662323
Loss = 0.632599
Loss = 0.615829
Loss = 0.621109
TEST LOSS = 0.618469
TEST ACC = 486.44 % (8077/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.625565
Epoch 7.2: Loss = 0.596817
Epoch 7.3: Loss = 0.567078
Epoch 7.4: Loss = 0.56723
Epoch 7.5: Loss = 0.601974
Epoch 7.6: Loss = 0.59935
Epoch 7.7: Loss = 0.555344
Epoch 7.8: Loss = 0.570969
Epoch 7.9: Loss = 0.610764
Epoch 7.10: Loss = 0.576294
Epoch 7.11: Loss = 0.62738
Epoch 7.12: Loss = 0.591461
Epoch 7.13: Loss = 0.570068
Epoch 7.14: Loss = 0.598587
Epoch 7.15: Loss = 0.612976
Epoch 7.16: Loss = 0.571396
Epoch 7.17: Loss = 0.579178
Epoch 7.18: Loss = 0.609192
Epoch 7.19: Loss = 0.655975
Epoch 7.20: Loss = 0.591248
Epoch 7.21: Loss = 0.647125
Epoch 7.22: Loss = 0.596451
Epoch 7.23: Loss = 0.65242
Epoch 7.24: Loss = 0.593216
Epoch 7.25: Loss = 0.591675
Epoch 7.26: Loss = 0.596313
Epoch 7.27: Loss = 0.563095
Epoch 7.28: Loss = 0.640076
Epoch 7.29: Loss = 0.629807
Epoch 7.30: Loss = 0.623627
TRAIN LOSS = 0.600449
TRAIN ACC = 81.6772 % (49008/60000)
Loss = 0.580383
Loss = 0.685303
Loss = 0.654175
Loss = 0.638596
Loss = 0.636887
TEST LOSS = 0.639068
TEST ACC = 490.079 % (8072/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.573166
Epoch 8.2: Loss = 0.688705
Epoch 8.3: Loss = 0.662811
Epoch 8.4: Loss = 0.653564
Epoch 8.5: Loss = 0.588791
Epoch 8.6: Loss = 0.599808
Epoch 8.7: Loss = 0.62645
Epoch 8.8: Loss = 0.618195
Epoch 8.9: Loss = 0.651749
Epoch 8.10: Loss = 0.587982
Epoch 8.11: Loss = 0.586716
Epoch 8.12: Loss = 0.618958
Epoch 8.13: Loss = 0.640488
Epoch 8.14: Loss = 0.545013
Epoch 8.15: Loss = 0.592972
Epoch 8.16: Loss = 0.593735
Epoch 8.17: Loss = 0.617081
Epoch 8.18: Loss = 0.634705
Epoch 8.19: Loss = 0.602859
Epoch 8.20: Loss = 0.553909
Epoch 8.21: Loss = 0.602829
Epoch 8.22: Loss = 0.597717
Epoch 8.23: Loss = 0.567566
Epoch 8.24: Loss = 0.596527
Epoch 8.25: Loss = 0.617172
Epoch 8.26: Loss = 0.556534
Epoch 8.27: Loss = 0.609818
Epoch 8.28: Loss = 0.612167
Epoch 8.29: Loss = 0.599686
Epoch 8.30: Loss = 0.662933
TRAIN LOSS = 0.608704
TRAIN ACC = 81.5567 % (48936/60000)
Loss = 0.579041
Loss = 0.685532
Loss = 0.659607
Loss = 0.646561
Loss = 0.637634
TEST LOSS = 0.641675
TEST ACC = 489.359 % (8126/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.547577
Epoch 9.2: Loss = 0.614532
Epoch 9.3: Loss = 0.688004
Epoch 9.4: Loss = 0.575348
Epoch 9.5: Loss = 0.590317
Epoch 9.6: Loss = 0.560715
Epoch 9.7: Loss = 0.645477
Epoch 9.8: Loss = 0.55217
Epoch 9.9: Loss = 0.603027
Epoch 9.10: Loss = 0.561249
Epoch 9.11: Loss = 0.629349
Epoch 9.12: Loss = 0.62709
Epoch 9.13: Loss = 0.730545
Epoch 9.14: Loss = 0.667297
Epoch 9.15: Loss = 0.610062
Epoch 9.16: Loss = 0.603607
Epoch 9.17: Loss = 0.600769
Epoch 9.18: Loss = 0.658295
Epoch 9.19: Loss = 0.655106
Epoch 9.20: Loss = 0.624588
Epoch 9.21: Loss = 0.634827
Epoch 9.22: Loss = 0.643417
Epoch 9.23: Loss = 0.604843
Epoch 9.24: Loss = 0.603287
Epoch 9.25: Loss = 0.541718
Epoch 9.26: Loss = 0.61351
Epoch 9.27: Loss = 0.584259
Epoch 9.28: Loss = 0.529907
Epoch 9.29: Loss = 0.585388
Epoch 9.30: Loss = 0.61261
TRAIN LOSS = 0.609985
TRAIN ACC = 81.8497 % (49112/60000)
Loss = 0.624359
Loss = 0.727203
Loss = 0.696167
Loss = 0.69339
Loss = 0.670532
TEST LOSS = 0.68233
TEST ACC = 491.119 % (8001/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.634766
Epoch 10.2: Loss = 0.564499
Epoch 10.3: Loss = 0.621124
Epoch 10.4: Loss = 0.616074
Epoch 10.5: Loss = 0.598572
Epoch 10.6: Loss = 0.530563
Epoch 10.7: Loss = 0.605576
Epoch 10.8: Loss = 0.544937
Epoch 10.9: Loss = 0.617462
Epoch 10.10: Loss = 0.582001
Epoch 10.11: Loss = 0.575104
Epoch 10.12: Loss = 0.626755
Epoch 10.13: Loss = 0.615631
Epoch 10.14: Loss = 0.642426
Epoch 10.15: Loss = 0.671219
Epoch 10.16: Loss = 0.561829
Epoch 10.17: Loss = 0.636322
Epoch 10.18: Loss = 0.574249
Epoch 10.19: Loss = 0.634491
Epoch 10.20: Loss = 0.575256
Epoch 10.21: Loss = 0.60527
Epoch 10.22: Loss = 0.600357
Epoch 10.23: Loss = 0.613434
Epoch 10.24: Loss = 0.630966
Epoch 10.25: Loss = 0.523956
Epoch 10.26: Loss = 0.570724
Epoch 10.27: Loss = 0.628906
Epoch 10.28: Loss = 0.537766
Epoch 10.29: Loss = 0.59462
Epoch 10.30: Loss = 0.617188
TRAIN LOSS = 0.598419
TRAIN ACC = 82.2128 % (49330/60000)
Loss = 0.560745
Loss = 0.671295
Loss = 0.647995
Loss = 0.615463
Loss = 0.618881
TEST LOSS = 0.622876
TEST ACC = 493.3 % (8126/10000)
