Setting up connection 0
***********************************************************
Training FMNIST
Model: Dense([60000, 1, 256]) => Dense([60000, 1, 256]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 500
Num Epochs: 10
Learning Rate: 0.1 to 0.1 over 10 epochs
Clipping Factor: 4
Sigma: 2
***********************************************************
Epoch 1.1: Loss = 2.39778
Epoch 1.2: Loss = 2.32948
Epoch 1.3: Loss = 2.24036
Epoch 1.4: Loss = 2.19063
Epoch 1.5: Loss = 2.1329
Epoch 1.6: Loss = 2.10782
Epoch 1.7: Loss = 2.01476
Epoch 1.8: Loss = 1.99443
Epoch 1.9: Loss = 1.92859
Epoch 1.10: Loss = 1.8884
Epoch 1.11: Loss = 1.86084
Epoch 1.12: Loss = 1.83968
Epoch 1.13: Loss = 1.72133
Epoch 1.14: Loss = 1.72041
Epoch 1.15: Loss = 1.67561
Epoch 1.16: Loss = 1.60179
Epoch 1.17: Loss = 1.58627
Epoch 1.18: Loss = 1.56784
Epoch 1.19: Loss = 1.54427
Epoch 1.20: Loss = 1.45633
Epoch 1.21: Loss = 1.45807
Epoch 1.22: Loss = 1.41249
Epoch 1.23: Loss = 1.40596
Epoch 1.24: Loss = 1.36484
Epoch 1.25: Loss = 1.35094
Epoch 1.26: Loss = 1.33173
Epoch 1.27: Loss = 1.28661
Epoch 1.28: Loss = 1.2469
Epoch 1.29: Loss = 1.21893
Epoch 1.30: Loss = 1.22284
Epoch 1.31: Loss = 1.20625
Epoch 1.32: Loss = 1.173
Epoch 1.33: Loss = 1.19589
Epoch 1.34: Loss = 1.13168
Epoch 1.35: Loss = 1.13048
Epoch 1.36: Loss = 1.11047
Epoch 1.37: Loss = 1.09262
Epoch 1.38: Loss = 1.05725
Epoch 1.39: Loss = 1.07338
Epoch 1.40: Loss = 1.06023
Epoch 1.41: Loss = 1.02969
Epoch 1.42: Loss = 1.07797
Epoch 1.43: Loss = 0.996735
Epoch 1.44: Loss = 1.00745
Epoch 1.45: Loss = 1.05156
Epoch 1.46: Loss = 0.980743
Epoch 1.47: Loss = 0.904144
Epoch 1.48: Loss = 0.945969
Epoch 1.49: Loss = 0.984573
Epoch 1.50: Loss = 0.960144
Epoch 1.51: Loss = 0.971375
Epoch 1.52: Loss = 0.938095
Epoch 1.53: Loss = 0.97438
Epoch 1.54: Loss = 0.913895
Epoch 1.55: Loss = 0.975082
Epoch 1.56: Loss = 0.886185
Epoch 1.57: Loss = 0.869965
Epoch 1.58: Loss = 0.858276
Epoch 1.59: Loss = 0.912292
Epoch 1.60: Loss = 0.961731
Epoch 1.61: Loss = 0.965805
Epoch 1.62: Loss = 0.924301
Epoch 1.63: Loss = 0.930847
Epoch 1.64: Loss = 0.848434
Epoch 1.65: Loss = 0.823151
Epoch 1.66: Loss = 0.819565
Epoch 1.67: Loss = 0.922974
Epoch 1.68: Loss = 0.921097
Epoch 1.69: Loss = 0.838257
Epoch 1.70: Loss = 0.924026
Epoch 1.71: Loss = 0.904785
Epoch 1.72: Loss = 0.829346
Epoch 1.73: Loss = 0.859253
Epoch 1.74: Loss = 0.859299
Epoch 1.75: Loss = 0.799438
Epoch 1.76: Loss = 0.844009
Epoch 1.77: Loss = 0.8228
Epoch 1.78: Loss = 0.892883
Epoch 1.79: Loss = 0.955719
Epoch 1.80: Loss = 0.765686
Epoch 1.81: Loss = 0.829224
Epoch 1.82: Loss = 0.805679
Epoch 1.83: Loss = 0.85704
Epoch 1.84: Loss = 0.808807
Epoch 1.85: Loss = 0.848984
Epoch 1.86: Loss = 0.803009
Epoch 1.87: Loss = 0.804382
Epoch 1.88: Loss = 0.758774
Epoch 1.89: Loss = 0.778
Epoch 1.90: Loss = 0.834991
Epoch 1.91: Loss = 0.757751
Epoch 1.92: Loss = 0.752762
Epoch 1.93: Loss = 0.797638
Epoch 1.94: Loss = 0.817169
Epoch 1.95: Loss = 0.830597
Epoch 1.96: Loss = 0.793625
Epoch 1.97: Loss = 0.881271
Epoch 1.98: Loss = 0.821381
Epoch 1.99: Loss = 0.815903
Epoch 1.100: Loss = 0.829254
Epoch 1.101: Loss = 0.744522
Epoch 1.102: Loss = 0.735001
Epoch 1.103: Loss = 0.771439
Epoch 1.104: Loss = 0.82489
Epoch 1.105: Loss = 0.72728
Epoch 1.106: Loss = 0.788773
Epoch 1.107: Loss = 0.801788
Epoch 1.108: Loss = 0.664001
Epoch 1.109: Loss = 0.813919
Epoch 1.110: Loss = 0.784363
Epoch 1.111: Loss = 0.740189
Epoch 1.112: Loss = 0.789383
Epoch 1.113: Loss = 0.766525
Epoch 1.114: Loss = 0.795197
Epoch 1.115: Loss = 0.692307
Epoch 1.116: Loss = 0.772903
Epoch 1.117: Loss = 0.684631
Epoch 1.118: Loss = 0.791245
Epoch 1.119: Loss = 0.754517
Epoch 1.120: Loss = 0.689682
TRAIN LOSS = 1.08618
TRAIN ACC = 62.8326 % (37701/60000)
Loss = 0.707916
Loss = 0.831818
Loss = 0.806137
Loss = 0.701782
Loss = 0.722
Loss = 0.876633
Loss = 0.896133
Loss = 0.871445
Loss = 0.781906
Loss = 0.718719
Loss = 0.854279
Loss = 0.794067
Loss = 0.839813
Loss = 0.813873
Loss = 0.768616
Loss = 0.840332
Loss = 0.751587
Loss = 0.791763
Loss = 0.86499
Loss = 0.790924
TEST LOSS = 0.801236
TEST ACC = 377.01 % (7155/10000)
Reducing learning rate to 0.100006
Epoch 2.1: Loss = 0.820297
Epoch 2.2: Loss = 0.746063
Epoch 2.3: Loss = 0.798187
Epoch 2.4: Loss = 0.719528
Epoch 2.5: Loss = 0.782532
Epoch 2.6: Loss = 0.724457
Epoch 2.7: Loss = 0.73555
Epoch 2.8: Loss = 0.662216
Epoch 2.9: Loss = 0.729996
Epoch 2.10: Loss = 0.719345
Epoch 2.11: Loss = 0.756317
Epoch 2.12: Loss = 0.720413
Epoch 2.13: Loss = 0.68808
Epoch 2.14: Loss = 0.796463
Epoch 2.15: Loss = 0.752472
Epoch 2.16: Loss = 0.698135
Epoch 2.17: Loss = 0.757019
Epoch 2.18: Loss = 0.779968
Epoch 2.19: Loss = 0.65419
Epoch 2.20: Loss = 0.766418
Epoch 2.21: Loss = 0.704437
Epoch 2.22: Loss = 0.792313
Epoch 2.23: Loss = 0.726227
Epoch 2.24: Loss = 0.745224
Epoch 2.25: Loss = 0.772369
Epoch 2.26: Loss = 0.709076
Epoch 2.27: Loss = 0.72049
Epoch 2.28: Loss = 0.789032
Epoch 2.29: Loss = 0.733734
Epoch 2.30: Loss = 0.720673
Epoch 2.31: Loss = 0.741592
Epoch 2.32: Loss = 0.700653
Epoch 2.33: Loss = 0.734741
Epoch 2.34: Loss = 0.695053
Epoch 2.35: Loss = 0.65831
Epoch 2.36: Loss = 0.761948
Epoch 2.37: Loss = 0.73999
Epoch 2.38: Loss = 0.667557
Epoch 2.39: Loss = 0.767685
Epoch 2.40: Loss = 0.708893
Epoch 2.41: Loss = 0.66452
Epoch 2.42: Loss = 0.762985
Epoch 2.43: Loss = 0.678711
Epoch 2.44: Loss = 0.636749
Epoch 2.45: Loss = 0.81073
Epoch 2.46: Loss = 0.739197
Epoch 2.47: Loss = 0.70903
Epoch 2.48: Loss = 0.790054
Epoch 2.49: Loss = 0.707245
Epoch 2.50: Loss = 0.666428
Epoch 2.51: Loss = 0.770233
Epoch 2.52: Loss = 0.750519
Epoch 2.53: Loss = 0.809128
Epoch 2.54: Loss = 0.725037
Epoch 2.55: Loss = 0.664658
Epoch 2.56: Loss = 0.687866
Epoch 2.57: Loss = 0.736954
Epoch 2.58: Loss = 0.717056
Epoch 2.59: Loss = 0.744797
Epoch 2.60: Loss = 0.765457
Epoch 2.61: Loss = 0.669159
Epoch 2.62: Loss = 0.82283
Epoch 2.63: Loss = 0.871185
Epoch 2.64: Loss = 0.696075
Epoch 2.65: Loss = 0.745056
Epoch 2.66: Loss = 0.677887
Epoch 2.67: Loss = 0.687134
Epoch 2.68: Loss = 0.682312
Epoch 2.69: Loss = 0.798187
Epoch 2.70: Loss = 0.74379
Epoch 2.71: Loss = 0.724426
Epoch 2.72: Loss = 0.671844
Epoch 2.73: Loss = 0.670654
Epoch 2.74: Loss = 0.791473
Epoch 2.75: Loss = 0.755417
Epoch 2.76: Loss = 0.789764
Epoch 2.77: Loss = 0.711639
Epoch 2.78: Loss = 0.845627
Epoch 2.79: Loss = 0.737015
Epoch 2.80: Loss = 0.858002
Epoch 2.81: Loss = 0.66571
Epoch 2.82: Loss = 0.69017
Epoch 2.83: Loss = 0.766479
Epoch 2.84: Loss = 0.755783
Epoch 2.85: Loss = 0.810745
Epoch 2.86: Loss = 0.807526
Epoch 2.87: Loss = 0.662094
Epoch 2.88: Loss = 0.689255
Epoch 2.89: Loss = 0.695465
Epoch 2.90: Loss = 0.617523
Epoch 2.91: Loss = 0.803177
Epoch 2.92: Loss = 0.736252
Epoch 2.93: Loss = 0.816849
Epoch 2.94: Loss = 0.709167
Epoch 2.95: Loss = 0.674103
Epoch 2.96: Loss = 0.704224
Epoch 2.97: Loss = 0.891388
Epoch 2.98: Loss = 0.746826
Epoch 2.99: Loss = 0.672531
Epoch 2.100: Loss = 0.640747
Epoch 2.101: Loss = 0.708237
Epoch 2.102: Loss = 0.749985
Epoch 2.103: Loss = 0.658539
Epoch 2.104: Loss = 0.756271
Epoch 2.105: Loss = 0.75119
Epoch 2.106: Loss = 0.67717
Epoch 2.107: Loss = 0.724091
Epoch 2.108: Loss = 0.658478
Epoch 2.109: Loss = 0.620117
Epoch 2.110: Loss = 0.716934
Epoch 2.111: Loss = 0.788406
Epoch 2.112: Loss = 0.739853
Epoch 2.113: Loss = 0.663757
Epoch 2.114: Loss = 0.792694
Epoch 2.115: Loss = 0.575516
Epoch 2.116: Loss = 0.781067
Epoch 2.117: Loss = 0.677872
Epoch 2.118: Loss = 0.786789
Epoch 2.119: Loss = 0.714813
Epoch 2.120: Loss = 0.719345
TRAIN LOSS = 0.730865
TRAIN ACC = 75.8804 % (45530/60000)
Loss = 0.64772
Loss = 0.80043
Loss = 0.720184
Loss = 0.669998
Loss = 0.625214
Loss = 0.833908
Loss = 0.879807
Loss = 0.766006
Loss = 0.717682
Loss = 0.660065
Loss = 0.815369
Loss = 0.766479
Loss = 0.769333
Loss = 0.751038
Loss = 0.683655
Loss = 0.75296
Loss = 0.684753
Loss = 0.775421
Loss = 0.77063
Loss = 0.731888
TEST LOSS = 0.741127
TEST ACC = 455.299 % (7610/10000)
Reducing learning rate to 0.100006
Epoch 3.1: Loss = 0.669113
Epoch 3.2: Loss = 0.70192
Epoch 3.3: Loss = 0.764313
Epoch 3.4: Loss = 0.852737
Epoch 3.5: Loss = 0.706253
Epoch 3.6: Loss = 0.691971
Epoch 3.7: Loss = 0.655655
Epoch 3.8: Loss = 0.69191
Epoch 3.9: Loss = 0.787613
Epoch 3.10: Loss = 0.758209
Epoch 3.11: Loss = 0.733276
Epoch 3.12: Loss = 0.648102
Epoch 3.13: Loss = 0.657425
Epoch 3.14: Loss = 0.644836
Epoch 3.15: Loss = 0.73909
Epoch 3.16: Loss = 0.785294
Epoch 3.17: Loss = 0.677963
Epoch 3.18: Loss = 0.758652
Epoch 3.19: Loss = 0.728592
Epoch 3.20: Loss = 0.613663
Epoch 3.21: Loss = 0.745956
Epoch 3.22: Loss = 0.690643
Epoch 3.23: Loss = 0.651138
Epoch 3.24: Loss = 0.702652
Epoch 3.25: Loss = 0.579147
Epoch 3.26: Loss = 0.72525
Epoch 3.27: Loss = 0.757141
Epoch 3.28: Loss = 0.761353
Epoch 3.29: Loss = 0.789551
Epoch 3.30: Loss = 0.764679
Epoch 3.31: Loss = 0.774414
Epoch 3.32: Loss = 0.76152
Epoch 3.33: Loss = 0.609131
Epoch 3.34: Loss = 0.734604
Epoch 3.35: Loss = 0.760956
Epoch 3.36: Loss = 0.631531
Epoch 3.37: Loss = 0.882767
Epoch 3.38: Loss = 0.696228
Epoch 3.39: Loss = 0.716766
Epoch 3.40: Loss = 0.778152
Epoch 3.41: Loss = 0.681
Epoch 3.42: Loss = 0.747162
Epoch 3.43: Loss = 0.653259
Epoch 3.44: Loss = 0.732269
Epoch 3.45: Loss = 0.719666
Epoch 3.46: Loss = 0.703339
Epoch 3.47: Loss = 0.748856
Epoch 3.48: Loss = 0.730362
Epoch 3.49: Loss = 0.688828
Epoch 3.50: Loss = 0.779007
Epoch 3.51: Loss = 0.671768
Epoch 3.52: Loss = 0.760284
Epoch 3.53: Loss = 0.863251
Epoch 3.54: Loss = 0.714874
Epoch 3.55: Loss = 0.845886
Epoch 3.56: Loss = 0.783569
Epoch 3.57: Loss = 0.791901
Epoch 3.58: Loss = 0.757278
Epoch 3.59: Loss = 0.650986
Epoch 3.60: Loss = 0.747971
Epoch 3.61: Loss = 0.6698
Epoch 3.62: Loss = 0.713715
Epoch 3.63: Loss = 0.784485
Epoch 3.64: Loss = 0.806778
Epoch 3.65: Loss = 0.664902
Epoch 3.66: Loss = 0.754822
Epoch 3.67: Loss = 0.758911
Epoch 3.68: Loss = 0.939575
Epoch 3.69: Loss = 0.871857
Epoch 3.70: Loss = 0.72525
Epoch 3.71: Loss = 0.774811
Epoch 3.72: Loss = 0.703278
Epoch 3.73: Loss = 0.637497
Epoch 3.74: Loss = 0.870255
Epoch 3.75: Loss = 0.806915
Epoch 3.76: Loss = 0.897812
Epoch 3.77: Loss = 0.907745
Epoch 3.78: Loss = 0.948486
Epoch 3.79: Loss = 0.774857
Epoch 3.80: Loss = 0.795227
Epoch 3.81: Loss = 0.801697
Epoch 3.82: Loss = 0.579575
Epoch 3.83: Loss = 0.672699
Epoch 3.84: Loss = 0.826569
Epoch 3.85: Loss = 0.78125
Epoch 3.86: Loss = 0.77092
Epoch 3.87: Loss = 0.811386
Epoch 3.88: Loss = 0.727646
Epoch 3.89: Loss = 0.686218
Epoch 3.90: Loss = 0.735291
Epoch 3.91: Loss = 0.746201
Epoch 3.92: Loss = 0.723129
Epoch 3.93: Loss = 0.690704
Epoch 3.94: Loss = 0.695251
Epoch 3.95: Loss = 0.718521
Epoch 3.96: Loss = 0.757538
Epoch 3.97: Loss = 0.77179
Epoch 3.98: Loss = 0.743622
Epoch 3.99: Loss = 0.738739
Epoch 3.100: Loss = 0.777313
Epoch 3.101: Loss = 0.738342
Epoch 3.102: Loss = 0.787384
Epoch 3.103: Loss = 0.645523
Epoch 3.104: Loss = 0.649719
Epoch 3.105: Loss = 0.876617
Epoch 3.106: Loss = 0.790741
Epoch 3.107: Loss = 0.65802
Epoch 3.108: Loss = 0.785904
Epoch 3.109: Loss = 0.74324
Epoch 3.110: Loss = 0.709702
Epoch 3.111: Loss = 0.699036
Epoch 3.112: Loss = 0.748138
Epoch 3.113: Loss = 0.695526
Epoch 3.114: Loss = 0.749191
Epoch 3.115: Loss = 0.674423
Epoch 3.116: Loss = 0.89743
Epoch 3.117: Loss = 0.816025
Epoch 3.118: Loss = 0.745331
Epoch 3.119: Loss = 0.699661
Epoch 3.120: Loss = 0.968384
TRAIN LOSS = 0.743286
TRAIN ACC = 77.4414 % (46467/60000)
Loss = 0.655472
Loss = 0.792862
Loss = 0.731735
Loss = 0.642471
Loss = 0.619125
Loss = 0.885483
Loss = 0.927261
Loss = 0.840637
Loss = 0.733475
Loss = 0.650864
Loss = 0.872604
Loss = 0.8078
Loss = 0.753433
Loss = 0.772415
Loss = 0.706436
Loss = 0.750504
Loss = 0.699493
Loss = 0.753357
Loss = 0.790421
Loss = 0.765671
TEST LOSS = 0.757576
TEST ACC = 464.67 % (7716/10000)
Reducing learning rate to 0.100006
Epoch 4.1: Loss = 0.908295
Epoch 4.2: Loss = 0.746933
Epoch 4.3: Loss = 0.658875
Epoch 4.4: Loss = 0.775085
Epoch 4.5: Loss = 0.687546
Epoch 4.6: Loss = 0.646423
Epoch 4.7: Loss = 0.627075
Epoch 4.8: Loss = 0.750427
Epoch 4.9: Loss = 0.615097
Epoch 4.10: Loss = 0.63562
Epoch 4.11: Loss = 0.750473
Epoch 4.12: Loss = 0.667847
Epoch 4.13: Loss = 0.88002
Epoch 4.14: Loss = 0.702744
Epoch 4.15: Loss = 0.790482
Epoch 4.16: Loss = 0.710617
Epoch 4.17: Loss = 0.811142
Epoch 4.18: Loss = 0.81842
Epoch 4.19: Loss = 0.586334
Epoch 4.20: Loss = 0.915619
Epoch 4.21: Loss = 0.781921
Epoch 4.22: Loss = 0.592361
Epoch 4.23: Loss = 0.896652
Epoch 4.24: Loss = 0.710175
Epoch 4.25: Loss = 0.730148
Epoch 4.26: Loss = 0.735077
Epoch 4.27: Loss = 0.710724
Epoch 4.28: Loss = 0.617661
Epoch 4.29: Loss = 0.77951
Epoch 4.30: Loss = 0.823547
Epoch 4.31: Loss = 0.928772
Epoch 4.32: Loss = 0.700409
Epoch 4.33: Loss = 0.652084
Epoch 4.34: Loss = 0.73613
Epoch 4.35: Loss = 0.776489
Epoch 4.36: Loss = 0.795898
Epoch 4.37: Loss = 0.833694
Epoch 4.38: Loss = 0.923904
Epoch 4.39: Loss = 0.782211
Epoch 4.40: Loss = 0.680771
Epoch 4.41: Loss = 0.748444
Epoch 4.42: Loss = 0.659714
Epoch 4.43: Loss = 0.946457
Epoch 4.44: Loss = 0.76033
Epoch 4.45: Loss = 0.682083
Epoch 4.46: Loss = 0.718704
Epoch 4.47: Loss = 0.838303
Epoch 4.48: Loss = 0.756653
Epoch 4.49: Loss = 0.622665
Epoch 4.50: Loss = 0.729279
Epoch 4.51: Loss = 0.763641
Epoch 4.52: Loss = 0.59552
Epoch 4.53: Loss = 0.780899
Epoch 4.54: Loss = 0.719971
Epoch 4.55: Loss = 0.745468
Epoch 4.56: Loss = 0.778412
Epoch 4.57: Loss = 0.91008
Epoch 4.58: Loss = 0.605103
Epoch 4.59: Loss = 0.884003
Epoch 4.60: Loss = 0.666
Epoch 4.61: Loss = 0.743271
Epoch 4.62: Loss = 0.785873
Epoch 4.63: Loss = 0.919617
Epoch 4.64: Loss = 0.7276
Epoch 4.65: Loss = 0.747589
Epoch 4.66: Loss = 0.74678
Epoch 4.67: Loss = 0.733932
Epoch 4.68: Loss = 0.907883
Epoch 4.69: Loss = 0.667969
Epoch 4.70: Loss = 0.671722
Epoch 4.71: Loss = 0.667755
Epoch 4.72: Loss = 0.818649
Epoch 4.73: Loss = 0.721191
Epoch 4.74: Loss = 0.821777
Epoch 4.75: Loss = 0.757141
Epoch 4.76: Loss = 0.772171
Epoch 4.77: Loss = 0.789017
Epoch 4.78: Loss = 0.65683
Epoch 4.79: Loss = 0.853241
Epoch 4.80: Loss = 0.788086
Epoch 4.81: Loss = 0.907654
Epoch 4.82: Loss = 0.636475
Epoch 4.83: Loss = 0.730316
Epoch 4.84: Loss = 0.771057
Epoch 4.85: Loss = 0.838257
Epoch 4.86: Loss = 0.701294
Epoch 4.87: Loss = 0.724396
Epoch 4.88: Loss = 0.773682
Epoch 4.89: Loss = 0.822357
Epoch 4.90: Loss = 0.699219
Epoch 4.91: Loss = 0.769714
Epoch 4.92: Loss = 0.92012
Epoch 4.93: Loss = 0.71875
Epoch 4.94: Loss = 0.753036
Epoch 4.95: Loss = 0.708664
Epoch 4.96: Loss = 0.60939
Epoch 4.97: Loss = 0.762863
Epoch 4.98: Loss = 0.789459
Epoch 4.99: Loss = 0.772125
Epoch 4.100: Loss = 0.845306
Epoch 4.101: Loss = 0.842453
Epoch 4.102: Loss = 0.802155
Epoch 4.103: Loss = 0.660751
Epoch 4.104: Loss = 0.899734
Epoch 4.105: Loss = 0.928864
Epoch 4.106: Loss = 0.827576
Epoch 4.107: Loss = 0.723038
Epoch 4.108: Loss = 0.875427
Epoch 4.109: Loss = 0.6492
Epoch 4.110: Loss = 0.741699
Epoch 4.111: Loss = 0.718338
Epoch 4.112: Loss = 0.74472
Epoch 4.113: Loss = 0.912186
Epoch 4.114: Loss = 0.858643
Epoch 4.115: Loss = 0.859268
Epoch 4.116: Loss = 0.745956
Epoch 4.117: Loss = 0.765793
Epoch 4.118: Loss = 0.784424
Epoch 4.119: Loss = 0.822189
Epoch 4.120: Loss = 0.774155
TRAIN LOSS = 0.76062
TRAIN ACC = 78.1403 % (46886/60000)
Loss = 0.72348
Loss = 0.888855
Loss = 0.800156
Loss = 0.715454
Loss = 0.687057
Loss = 0.958191
Loss = 0.934799
Loss = 0.805481
Loss = 0.801834
Loss = 0.725311
Loss = 0.926071
Loss = 0.894669
Loss = 0.849579
Loss = 0.800552
Loss = 0.780426
Loss = 0.861298
Loss = 0.770187
Loss = 0.832489
Loss = 0.893875
Loss = 0.814423
TEST LOSS = 0.823209
TEST ACC = 468.86 % (7733/10000)
Reducing learning rate to 0.100006
Epoch 5.1: Loss = 0.830536
Epoch 5.2: Loss = 0.744537
Epoch 5.3: Loss = 0.922836
Epoch 5.4: Loss = 0.661987
Epoch 5.5: Loss = 0.790741
Epoch 5.6: Loss = 0.873352
Epoch 5.7: Loss = 0.825211
Epoch 5.8: Loss = 0.775925
Epoch 5.9: Loss = 0.830826
Epoch 5.10: Loss = 0.921188
Epoch 5.11: Loss = 0.825302
Epoch 5.12: Loss = 0.836365
Epoch 5.13: Loss = 0.730835
Epoch 5.14: Loss = 0.572021
Epoch 5.15: Loss = 0.804398
Epoch 5.16: Loss = 0.790497
Epoch 5.17: Loss = 0.739273
Epoch 5.18: Loss = 0.687424
Epoch 5.19: Loss = 0.881851
Epoch 5.20: Loss = 0.721832
Epoch 5.21: Loss = 0.803726
Epoch 5.22: Loss = 0.735352
Epoch 5.23: Loss = 0.882523
Epoch 5.24: Loss = 0.699615
Epoch 5.25: Loss = 0.805466
Epoch 5.26: Loss = 0.799179
Epoch 5.27: Loss = 0.866959
Epoch 5.28: Loss = 0.830719
Epoch 5.29: Loss = 0.893188
Epoch 5.30: Loss = 0.862228
Epoch 5.31: Loss = 0.782272
Epoch 5.32: Loss = 0.832855
Epoch 5.33: Loss = 0.904541
Epoch 5.34: Loss = 0.719543
Epoch 5.35: Loss = 0.848022
Epoch 5.36: Loss = 0.824142
Epoch 5.37: Loss = 0.665817
Epoch 5.38: Loss = 0.904068
Epoch 5.39: Loss = 0.739273
Epoch 5.40: Loss = 0.817566
Epoch 5.41: Loss = 0.809982
Epoch 5.42: Loss = 0.669067
Epoch 5.43: Loss = 0.75798
Epoch 5.44: Loss = 0.807007
Epoch 5.45: Loss = 0.762589
Epoch 5.46: Loss = 0.793503
Epoch 5.47: Loss = 0.804749
Epoch 5.48: Loss = 0.841629
Epoch 5.49: Loss = 0.694489
Epoch 5.50: Loss = 0.75441
Epoch 5.51: Loss = 0.671783
Epoch 5.52: Loss = 0.734207
Epoch 5.53: Loss = 0.819626
Epoch 5.54: Loss = 0.812256
Epoch 5.55: Loss = 0.707291
Epoch 5.56: Loss = 0.786179
Epoch 5.57: Loss = 0.708328
Epoch 5.58: Loss = 0.821167
Epoch 5.59: Loss = 0.81572
Epoch 5.60: Loss = 0.700119
Epoch 5.61: Loss = 0.786484
Epoch 5.62: Loss = 0.811356
Epoch 5.63: Loss = 0.691574
Epoch 5.64: Loss = 0.860367
Epoch 5.65: Loss = 0.703918
Epoch 5.66: Loss = 0.795746
Epoch 5.67: Loss = 0.818222
Epoch 5.68: Loss = 0.915909
Epoch 5.69: Loss = 0.835983
Epoch 5.70: Loss = 0.770096
Epoch 5.71: Loss = 0.966431
Epoch 5.72: Loss = 0.744461
Epoch 5.73: Loss = 0.850311
Epoch 5.74: Loss = 0.629135
Epoch 5.75: Loss = 0.724762
Epoch 5.76: Loss = 0.7957
Epoch 5.77: Loss = 0.711487
Epoch 5.78: Loss = 0.703186
Epoch 5.79: Loss = 0.720108
Epoch 5.80: Loss = 0.863983
Epoch 5.81: Loss = 0.774643
Epoch 5.82: Loss = 0.807129
Epoch 5.83: Loss = 0.806549
Epoch 5.84: Loss = 0.832184
Epoch 5.85: Loss = 0.813965
Epoch 5.86: Loss = 0.758713
Epoch 5.87: Loss = 0.863632
Epoch 5.88: Loss = 0.641052
Epoch 5.89: Loss = 0.802658
Epoch 5.90: Loss = 0.847443
Epoch 5.91: Loss = 0.777267
Epoch 5.92: Loss = 0.902145
Epoch 5.93: Loss = 0.81604
Epoch 5.94: Loss = 0.756454
Epoch 5.95: Loss = 0.810593
Epoch 5.96: Loss = 0.926987
Epoch 5.97: Loss = 0.814087
Epoch 5.98: Loss = 0.840622
Epoch 5.99: Loss = 0.841812
Epoch 5.100: Loss = 0.858521
Epoch 5.101: Loss = 0.815399
Epoch 5.102: Loss = 0.656174
Epoch 5.103: Loss = 0.622635
Epoch 5.104: Loss = 0.913849
Epoch 5.105: Loss = 0.809662
Epoch 5.106: Loss = 0.9664
Epoch 5.107: Loss = 0.806091
Epoch 5.108: Loss = 0.88588
Epoch 5.109: Loss = 0.778931
Epoch 5.110: Loss = 0.932114
Epoch 5.111: Loss = 0.891846
Epoch 5.112: Loss = 0.683197
Epoch 5.113: Loss = 0.784607
Epoch 5.114: Loss = 0.821304
Epoch 5.115: Loss = 0.734161
Epoch 5.116: Loss = 0.817505
Epoch 5.117: Loss = 0.713455
Epoch 5.118: Loss = 0.780014
Epoch 5.119: Loss = 0.725571
Epoch 5.120: Loss = 0.619583
TRAIN LOSS = 0.791733
TRAIN ACC = 78.0258 % (46817/60000)
Loss = 0.712341
Loss = 0.885345
Loss = 0.722763
Loss = 0.698486
Loss = 0.724854
Loss = 0.993134
Loss = 0.977432
Loss = 0.840454
Loss = 0.779099
Loss = 0.751907
Loss = 0.911972
Loss = 0.873795
Loss = 0.858475
Loss = 0.813492
Loss = 0.814209
Loss = 0.824295
Loss = 0.753662
Loss = 0.829025
Loss = 0.877701
Loss = 0.747345
TEST LOSS = 0.819489
TEST ACC = 468.169 % (7772/10000)
Reducing learning rate to 0.100006
Epoch 6.1: Loss = 0.788834
Epoch 6.2: Loss = 0.821503
Epoch 6.3: Loss = 0.946335
Epoch 6.4: Loss = 0.773499
Epoch 6.5: Loss = 0.861771
Epoch 6.6: Loss = 0.807251
Epoch 6.7: Loss = 0.890778
Epoch 6.8: Loss = 0.824051
Epoch 6.9: Loss = 0.960403
Epoch 6.10: Loss = 0.766388
Epoch 6.11: Loss = 0.826797
Epoch 6.12: Loss = 0.892029
Epoch 6.13: Loss = 0.761932
Epoch 6.14: Loss = 0.770416
Epoch 6.15: Loss = 0.668564
Epoch 6.16: Loss = 0.695114
Epoch 6.17: Loss = 0.823349
Epoch 6.18: Loss = 0.836746
Epoch 6.19: Loss = 0.782181
Epoch 6.20: Loss = 0.898956
Epoch 6.21: Loss = 0.742981
Epoch 6.22: Loss = 0.935989
Epoch 6.23: Loss = 0.688858
Epoch 6.24: Loss = 0.721771
Epoch 6.25: Loss = 0.986572
Epoch 6.26: Loss = 0.820877
Epoch 6.27: Loss = 0.933182
Epoch 6.28: Loss = 0.915573
Epoch 6.29: Loss = 0.744583
Epoch 6.30: Loss = 0.960739
Epoch 6.31: Loss = 1.06462
Epoch 6.32: Loss = 0.820587
Epoch 6.33: Loss = 0.688095
Epoch 6.34: Loss = 0.810867
Epoch 6.35: Loss = 0.766876
Epoch 6.36: Loss = 0.792374
Epoch 6.37: Loss = 0.846054
Epoch 6.38: Loss = 0.853195
Epoch 6.39: Loss = 0.937286
Epoch 6.40: Loss = 0.857224
Epoch 6.41: Loss = 0.816238
Epoch 6.42: Loss = 0.781708
Epoch 6.43: Loss = 0.827148
Epoch 6.44: Loss = 1.03758
Epoch 6.45: Loss = 0.879211
Epoch 6.46: Loss = 0.725342
Epoch 6.47: Loss = 0.638519
Epoch 6.48: Loss = 0.703751
Epoch 6.49: Loss = 0.852478
Epoch 6.50: Loss = 0.756653
Epoch 6.51: Loss = 0.762512
Epoch 6.52: Loss = 0.774673
Epoch 6.53: Loss = 0.818802
Epoch 6.54: Loss = 0.940826
Epoch 6.55: Loss = 0.801498
Epoch 6.56: Loss = 0.839249
Epoch 6.57: Loss = 0.865646
Epoch 6.58: Loss = 0.781036
Epoch 6.59: Loss = 0.944626
Epoch 6.60: Loss = 0.773849
Epoch 6.61: Loss = 0.803772
Epoch 6.62: Loss = 0.934708
Epoch 6.63: Loss = 0.717697
Epoch 6.64: Loss = 0.83696
Epoch 6.65: Loss = 0.732422
Epoch 6.66: Loss = 0.694916
Epoch 6.67: Loss = 0.790222
Epoch 6.68: Loss = 0.924164
Epoch 6.69: Loss = 0.799805
Epoch 6.70: Loss = 0.853134
Epoch 6.71: Loss = 0.866531
Epoch 6.72: Loss = 1.01859
Epoch 6.73: Loss = 0.66095
Epoch 6.74: Loss = 0.845856
Epoch 6.75: Loss = 0.826385
Epoch 6.76: Loss = 0.78717
Epoch 6.77: Loss = 0.890335
Epoch 6.78: Loss = 0.878799
Epoch 6.79: Loss = 0.900391
Epoch 6.80: Loss = 0.853806
Epoch 6.81: Loss = 0.766998
Epoch 6.82: Loss = 0.698135
Epoch 6.83: Loss = 0.737656
Epoch 6.84: Loss = 0.788483
Epoch 6.85: Loss = 0.777206
Epoch 6.86: Loss = 0.831345
Epoch 6.87: Loss = 0.958282
Epoch 6.88: Loss = 0.821991
Epoch 6.89: Loss = 0.856766
Epoch 6.90: Loss = 0.79805
Epoch 6.91: Loss = 0.877625
Epoch 6.92: Loss = 0.69722
Epoch 6.93: Loss = 0.83493
Epoch 6.94: Loss = 0.884689
Epoch 6.95: Loss = 1.00365
Epoch 6.96: Loss = 0.713165
Epoch 6.97: Loss = 0.751251
Epoch 6.98: Loss = 0.781357
Epoch 6.99: Loss = 0.93161
Epoch 6.100: Loss = 0.811127
Epoch 6.101: Loss = 0.603592
Epoch 6.102: Loss = 0.985519
Epoch 6.103: Loss = 0.81778
Epoch 6.104: Loss = 0.764679
Epoch 6.105: Loss = 0.7603
Epoch 6.106: Loss = 0.854675
Epoch 6.107: Loss = 0.718155
Epoch 6.108: Loss = 0.770615
Epoch 6.109: Loss = 0.935257
Epoch 6.110: Loss = 0.735916
Epoch 6.111: Loss = 0.831299
Epoch 6.112: Loss = 0.924866
Epoch 6.113: Loss = 0.877289
Epoch 6.114: Loss = 0.708252
Epoch 6.115: Loss = 0.921371
Epoch 6.116: Loss = 0.584717
Epoch 6.117: Loss = 0.93158
Epoch 6.118: Loss = 0.959335
Epoch 6.119: Loss = 0.908142
Epoch 6.120: Loss = 0.77475
TRAIN LOSS = 0.82428
TRAIN ACC = 78.389 % (47036/60000)
Loss = 0.738983
Loss = 0.901672
Loss = 0.812805
Loss = 0.778015
Loss = 0.774307
Loss = 1.0246
Loss = 1.06807
Loss = 0.950775
Loss = 0.830032
Loss = 0.773682
Loss = 0.97229
Loss = 0.948624
Loss = 0.918518
Loss = 0.856934
Loss = 0.837967
Loss = 0.878159
Loss = 0.798645
Loss = 0.855057
Loss = 0.933456
Loss = 0.814713
TEST LOSS = 0.873365
TEST ACC = 470.36 % (7838/10000)
Reducing learning rate to 0.100006
Epoch 7.1: Loss = 0.971146
Epoch 7.2: Loss = 0.755402
Epoch 7.3: Loss = 0.773941
Epoch 7.4: Loss = 0.849808
Epoch 7.5: Loss = 0.735107
Epoch 7.6: Loss = 0.920868
Epoch 7.7: Loss = 0.952621
Epoch 7.8: Loss = 0.941208
Epoch 7.9: Loss = 0.726196
Epoch 7.10: Loss = 0.817963
Epoch 7.11: Loss = 0.684143
Epoch 7.12: Loss = 0.927582
Epoch 7.13: Loss = 0.819473
Epoch 7.14: Loss = 1.12375
Epoch 7.15: Loss = 0.929642
Epoch 7.16: Loss = 0.821487
Epoch 7.17: Loss = 1.03665
Epoch 7.18: Loss = 1.02567
Epoch 7.19: Loss = 0.812927
Epoch 7.20: Loss = 0.980591
Epoch 7.21: Loss = 0.696136
Epoch 7.22: Loss = 0.925797
Epoch 7.23: Loss = 0.736893
Epoch 7.24: Loss = 0.866074
Epoch 7.25: Loss = 1.13448
Epoch 7.26: Loss = 36.4466
Epoch 7.27: Loss = 5656.38
Epoch 7.28: Loss = -172.987
Epoch 7.29: Loss = -25.8563
Epoch 7.30: Loss = -946.851
Epoch 7.31: Loss = 3058.51
Epoch 7.32: Loss = -1983.38
Epoch 7.33: Loss = -1532.12
Epoch 7.34: Loss = 723.877
Epoch 7.35: Loss = 1161.57
Epoch 7.36: Loss = 2719.99
Epoch 7.37: Loss = -1489.68
Epoch 7.38: Loss = -1209.66
Epoch 7.39: Loss = 120.612
Epoch 7.40: Loss = -213.798
Epoch 7.41: Loss = -1008.22
Epoch 7.42: Loss = 2033.65
Epoch 7.43: Loss = 800.103
Epoch 7.44: Loss = -1748.21
Epoch 7.45: Loss = -434.666
Epoch 7.46: Loss = 1864.79
Epoch 7.47: Loss = -520.217
Epoch 7.48: Loss = 2917.63
Epoch 7.49: Loss = -1281.92
Epoch 7.50: Loss = -1205.22
Epoch 7.51: Loss = 1046.48
Epoch 7.52: Loss = 1449.35
Epoch 7.53: Loss = -37.5819
Epoch 7.54: Loss = -4277.28
Epoch 7.55: Loss = 32.3757
Epoch 7.56: Loss = -749.124
Epoch 7.57: Loss = -419.003
Epoch 7.58: Loss = 792.01
Epoch 7.59: Loss = 197.545
Epoch 7.60: Loss = 2061.17
Epoch 7.61: Loss = 730.738
Epoch 7.62: Loss = 769.599
Epoch 7.63: Loss = 583.057
Epoch 7.64: Loss = 36.5708
Epoch 7.65: Loss = 844.548
Epoch 7.66: Loss = -730.258
Epoch 7.67: Loss = -907.229
Epoch 7.68: Loss = 681.432
Epoch 7.69: Loss = -441.544
Epoch 7.70: Loss = -33.821
Epoch 7.71: Loss = 925.777
Epoch 7.72: Loss = -2549.85
Epoch 7.73: Loss = -119.764
Epoch 7.74: Loss = 1009.53
Epoch 7.75: Loss = -555.101
Epoch 7.76: Loss = 456.409
Epoch 7.77: Loss = 2949.66
Epoch 7.78: Loss = -163.398
Epoch 7.79: Loss = -919.945
Epoch 7.80: Loss = -1394.83
Epoch 7.81: Loss = 226.088
Epoch 7.82: Loss = 3103.05
Epoch 7.83: Loss = 1168.17
Epoch 7.84: Loss = -932.375
Epoch 7.85: Loss = -1471.73
Epoch 7.86: Loss = 679.937
Epoch 7.87: Loss = -2467.49
Epoch 7.88: Loss = 1259.92
Epoch 7.89: Loss = -2123.72
Epoch 7.90: Loss = -839.584
Epoch 7.91: Loss = 944.011
Epoch 7.92: Loss = 295.81
Epoch 7.93: Loss = -335.76
Epoch 7.94: Loss = -310.023
Epoch 7.95: Loss = 573.048
Epoch 7.96: Loss = 23.5938
Epoch 7.97: Loss = 1784.53
Epoch 7.98: Loss = -447.824
Epoch 7.99: Loss = 866.475
Epoch 7.100: Loss = 1635.87
Epoch 7.101: Loss = -164.189
Epoch 7.102: Loss = -1122.83
Epoch 7.103: Loss = -988.94
Epoch 7.104: Loss = 629.474
Epoch 7.105: Loss = -273.359
Epoch 7.106: Loss = 453.99
Epoch 7.107: Loss = -1492.55
Epoch 7.108: Loss = -510.725
Epoch 7.109: Loss = -355.377
Epoch 7.110: Loss = 2216.83
Epoch 7.111: Loss = 501.789
Epoch 7.112: Loss = 1534.4
Epoch 7.113: Loss = 2840.25
Epoch 7.114: Loss = -98.9159
Epoch 7.115: Loss = 535.553
Epoch 7.116: Loss = 1226.29
Epoch 7.117: Loss = 1005.5
Epoch 7.118: Loss = -791.595
Epoch 7.119: Loss = -226.154
Epoch 7.120: Loss = 1174.8
TRAIN LOSS = 152.807
TRAIN ACC = 24.0723 % (14444/60000)
Loss = -1825.34
Loss = 792.485
Loss = -110.589
Loss = -2220.77
Loss = 645.474
Loss = -2833.77
Loss = -486.556
Loss = 263.295
Loss = -322.743
Loss = 1642
Loss = -793.166
Loss = 74.1069
Loss = -2046.64
Loss = 2845.46
Loss = 1530.71
Loss = -1136.97
Loss = 746.22
Loss = 1223.2
Loss = -635.282
Loss = -439.264
TEST LOSS = -3.67437
TEST ACC = 144.44 % (972/10000)
Reducing learning rate to 0.100006
Epoch 8.1: Loss = 951.692
Epoch 8.2: Loss = 1558.73
Epoch 8.3: Loss = 80.2133
Epoch 8.4: Loss = -962.868
Epoch 8.5: Loss = 24.5336
Epoch 8.6: Loss = 768.076
Epoch 8.7: Loss = 1675.51
Epoch 8.8: Loss = -1459.34
Epoch 8.9: Loss = 844.863
Epoch 8.10: Loss = 1072.98
Epoch 8.11: Loss = -903.205
Epoch 8.12: Loss = 794.457
Epoch 8.13: Loss = 573.137
Epoch 8.14: Loss = -297.336
Epoch 8.15: Loss = 1120.51
Epoch 8.16: Loss = -1299.42
Epoch 8.17: Loss = -717.437
Epoch 8.18: Loss = -95.385
Epoch 8.19: Loss = 992.634
Epoch 8.20: Loss = 1083.61
Epoch 8.21: Loss = -1054.33
Epoch 8.22: Loss = 2747.93
Epoch 8.23: Loss = -685.059
Epoch 8.24: Loss = -37.1085
Epoch 8.25: Loss = 915.425
Epoch 8.26: Loss = 446.002
Epoch 8.27: Loss = 1924.3
Epoch 8.28: Loss = -1771.26
Epoch 8.29: Loss = -61.9145
Epoch 8.30: Loss = -68.2199
Epoch 8.31: Loss = 1250.44
Epoch 8.32: Loss = -2270.54
Epoch 8.33: Loss = 1319.2
Epoch 8.34: Loss = -576.079
Epoch 8.35: Loss = -1619.02
Epoch 8.36: Loss = -1979.13
Epoch 8.37: Loss = 2584.32
Epoch 8.38: Loss = -784.216
Epoch 8.39: Loss = -984.432
Epoch 8.40: Loss = -622.113
Epoch 8.41: Loss = -74.6333
Epoch 8.42: Loss = 139.593
Epoch 8.43: Loss = -1233.61
Epoch 8.44: Loss = 531.999
Epoch 8.45: Loss = -45.4872
Epoch 8.46: Loss = -697.546
Epoch 8.47: Loss = 2288.27
Epoch 8.48: Loss = -660.494
Epoch 8.49: Loss = -166.327
Epoch 8.50: Loss = -1488.72
Epoch 8.51: Loss = 454.44
Epoch 8.52: Loss = -1237.86
Epoch 8.53: Loss = 676.629
Epoch 8.54: Loss = 251.767
Epoch 8.55: Loss = 1084.31
Epoch 8.56: Loss = 904.322
Epoch 8.57: Loss = 345.571
Epoch 8.58: Loss = -174.69
Epoch 8.59: Loss = -1494.13
Epoch 8.60: Loss = 663.155
Epoch 8.61: Loss = 1494.54
Epoch 8.62: Loss = -1447.26
Epoch 8.63: Loss = -2687.51
Epoch 8.64: Loss = 285.483
Epoch 8.65: Loss = 1217.88
Epoch 8.66: Loss = -1596.11
Epoch 8.67: Loss = -776.092
Epoch 8.68: Loss = 2223.76
Epoch 8.69: Loss = -921.528
Epoch 8.70: Loss = -271.724
Epoch 8.71: Loss = 346.199
Epoch 8.72: Loss = 199.261
Epoch 8.73: Loss = 458.561
Epoch 8.74: Loss = -561.345
Epoch 8.75: Loss = 1800.36
Epoch 8.76: Loss = -277.78
Epoch 8.77: Loss = 269.082
Epoch 8.78: Loss = 1372.27
Epoch 8.79: Loss = -1144.1
Epoch 8.80: Loss = -173.017
Epoch 8.81: Loss = 128.812
Epoch 8.82: Loss = -200.436
Epoch 8.83: Loss = -742.27
Epoch 8.84: Loss = -941.819
Epoch 8.85: Loss = -1837.41
Epoch 8.86: Loss = -836.522
Epoch 8.87: Loss = -958.675
Epoch 8.88: Loss = 349.08
Epoch 8.89: Loss = -1214.67
Epoch 8.90: Loss = 1259.54
Epoch 8.91: Loss = 2722.94
Epoch 8.92: Loss = -171.936
Epoch 8.93: Loss = -66.6256
Epoch 8.94: Loss = -855.904
Epoch 8.95: Loss = -191.786
Epoch 8.96: Loss = -95.1643
Epoch 8.97: Loss = -114.428
Epoch 8.98: Loss = 413.883
Epoch 8.99: Loss = 556.559
Epoch 8.100: Loss = 68.8296
Epoch 8.101: Loss = 1535.68
Epoch 8.102: Loss = 190.988
Epoch 8.103: Loss = -61.9559
Epoch 8.104: Loss = 1662.08
Epoch 8.105: Loss = 2182.35
Epoch 8.106: Loss = -14.2987
Epoch 8.107: Loss = 222.551
Epoch 8.108: Loss = 1739.59
Epoch 8.109: Loss = -74.545
Epoch 8.110: Loss = -134.498
Epoch 8.111: Loss = 1066.14
Epoch 8.112: Loss = 1980.1
Epoch 8.113: Loss = -106.327
Epoch 8.114: Loss = -2241.92
Epoch 8.115: Loss = -2013.85
Epoch 8.116: Loss = -625.056
Epoch 8.117: Loss = -702.175
Epoch 8.118: Loss = -1956.19
Epoch 8.119: Loss = 1197.15
Epoch 8.120: Loss = 337.508
TRAIN LOSS = 48.4421
TRAIN ACC = 9.92737 % (5957/60000)
Loss = -501.447
Loss = 111.975
Loss = 950.239
Loss = -2328.6
Loss = -772.501
Loss = 1188.9
Loss = 1126.04
Loss = 634.329
Loss = -1136.07
Loss = -1692.84
Loss = -271.461
Loss = -714.974
Loss = 409.392
Loss = 1372.04
Loss = 1284.1
Loss = -918.425
Loss = 2411.26
Loss = 1085.95
Loss = 1534.19
Loss = -737.099
TEST LOSS = 1.01719
TEST ACC = 59.5703 % (984/10000)
Reducing learning rate to 0.100006
Epoch 9.1: Loss = 3508.58
Epoch 9.2: Loss = -585.999
Epoch 9.3: Loss = 1852.85
Epoch 9.4: Loss = 1774.89
Epoch 9.5: Loss = 3248.81
Epoch 9.6: Loss = -1829.32
Epoch 9.7: Loss = -339.295
Epoch 9.8: Loss = -208.754
Epoch 9.9: Loss = -902.176
Epoch 9.10: Loss = -2246.03
Epoch 9.11: Loss = -91.8292
Epoch 9.12: Loss = -88.1881
Epoch 9.13: Loss = -231.028
Epoch 9.14: Loss = 1.08569
Epoch 9.15: Loss = -155.425
Epoch 9.16: Loss = -905.494
Epoch 9.17: Loss = 173.714
Epoch 9.18: Loss = 172.395
Epoch 9.19: Loss = 1149.71
Epoch 9.20: Loss = -157.109
Epoch 9.21: Loss = 576.412
Epoch 9.22: Loss = -667.738
Epoch 9.23: Loss = -2570.3
Epoch 9.24: Loss = -255.337
Epoch 9.25: Loss = -1352.31
Epoch 9.26: Loss = 1179.26
Epoch 9.27: Loss = -210.407
Epoch 9.28: Loss = 1584.76
Epoch 9.29: Loss = 1500.31
Epoch 9.30: Loss = 898.653
Epoch 9.31: Loss = 390.097
Epoch 9.32: Loss = 846.4
Epoch 9.33: Loss = -1028.07
Epoch 9.34: Loss = -1573.28
Epoch 9.35: Loss = -494.369
Epoch 9.36: Loss = -1093.61
Epoch 9.37: Loss = 285.025
Epoch 9.38: Loss = -730.767
Epoch 9.39: Loss = -771.838
Epoch 9.40: Loss = 1042.15
Epoch 9.41: Loss = 1126.63
Epoch 9.42: Loss = 2109.6
Epoch 9.43: Loss = 945.745
Epoch 9.44: Loss = 2431.14
Epoch 9.45: Loss = 882.434
Epoch 9.46: Loss = -139.162
Epoch 9.47: Loss = 730.302
Epoch 9.48: Loss = -838.512
Epoch 9.49: Loss = 1422.64
Epoch 9.50: Loss = -1866.45
Epoch 9.51: Loss = -80.3355
Epoch 9.52: Loss = 195.02
Epoch 9.53: Loss = -836.211
Epoch 9.54: Loss = 2002.6
Epoch 9.55: Loss = -555.281
Epoch 9.56: Loss = 1154.69
Epoch 9.57: Loss = 458.15
Epoch 9.58: Loss = -1568.84
Epoch 9.59: Loss = 1240.57
Epoch 9.60: Loss = -1682.1
Epoch 9.61: Loss = -1234.25
Epoch 9.62: Loss = 1032.6
Epoch 9.63: Loss = 1053.01
Epoch 9.64: Loss = -847.829
Epoch 9.65: Loss = -1993.59
Epoch 9.66: Loss = -545.088
Epoch 9.67: Loss = -591.296
Epoch 9.68: Loss = -1267.1
Epoch 9.69: Loss = 1905.67
Epoch 9.70: Loss = -79.8116
Epoch 9.71: Loss = 794.706
Epoch 9.72: Loss = 1314.93
Epoch 9.73: Loss = 1451.55
Epoch 9.74: Loss = 279.132
Epoch 9.75: Loss = -529.802
Epoch 9.76: Loss = -308.273
Epoch 9.77: Loss = -205.866
Epoch 9.78: Loss = 2113.93
Epoch 9.79: Loss = -81.1301
Epoch 9.80: Loss = -97.9397
Epoch 9.81: Loss = -335.717
Epoch 9.82: Loss = 327.354
Epoch 9.83: Loss = 1763.76
Epoch 9.84: Loss = -689.553
Epoch 9.85: Loss = -743.009
Epoch 9.86: Loss = 2229.52
Epoch 9.87: Loss = -584.786
Epoch 9.88: Loss = 1058.57
Epoch 9.89: Loss = 553.84
Epoch 9.90: Loss = 813.648
Epoch 9.91: Loss = -318.356
Epoch 9.92: Loss = -664.944
Epoch 9.93: Loss = -2028.28
Epoch 9.94: Loss = -419.593
Epoch 9.95: Loss = -2431.79
Epoch 9.96: Loss = -1390.98
Epoch 9.97: Loss = -326.484
Epoch 9.98: Loss = -1165.23
Epoch 9.99: Loss = -776.957
Epoch 9.100: Loss = 682.762
Epoch 9.101: Loss = -462.698
Epoch 9.102: Loss = -380.296
Epoch 9.103: Loss = 756.605
Epoch 9.104: Loss = 3339.4
Epoch 9.105: Loss = -632.84
Epoch 9.106: Loss = 1757.22
Epoch 9.107: Loss = 853.818
Epoch 9.108: Loss = -945.519
Epoch 9.109: Loss = 1047.89
Epoch 9.110: Loss = 132.519
Epoch 9.111: Loss = 765.592
Epoch 9.112: Loss = -1536.91
Epoch 9.113: Loss = 434.55
Epoch 9.114: Loss = 78.2099
Epoch 9.115: Loss = 444.565
Epoch 9.116: Loss = 193.381
Epoch 9.117: Loss = -123.371
Epoch 9.118: Loss = 828.249
Epoch 9.119: Loss = -1326.47
Epoch 9.120: Loss = 1042.91
TRAIN LOSS = 106.778
TRAIN ACC = 9.86176 % (5917/60000)
Loss = -602.103
Loss = -1172.3
Loss = 882.84
Loss = 1734.95
Loss = -1552.39
Loss = -887.993
Loss = 1961.91
Loss = 1154.55
Loss = 1504.49
Loss = -629.325
Loss = -391.993
Loss = -1116.22
Loss = -1556.73
Loss = 277.982
Loss = -420.751
Loss = 1577.64
Loss = -2440.22
Loss = 1331.65
Loss = -377.131
Loss = -1224.24
TEST LOSS = -0.803152
TEST ACC = 59.1705 % (1067/10000)
Reducing learning rate to 0.100006
Epoch 10.1: Loss = -1133.55
Epoch 10.2: Loss = -1551.62
Epoch 10.3: Loss = 45.4597
Epoch 10.4: Loss = -97.0061
Epoch 10.5: Loss = -1369.02
Epoch 10.6: Loss = 494.021
Epoch 10.7: Loss = 1333.46
Epoch 10.8: Loss = -958.708
Epoch 10.9: Loss = -514.787
Epoch 10.10: Loss = -1036.16
Epoch 10.11: Loss = -201.362
Epoch 10.12: Loss = 1338.85
Epoch 10.13: Loss = -1372.02
Epoch 10.14: Loss = 398.026
Epoch 10.15: Loss = 807.25
Epoch 10.16: Loss = 1393.39
Epoch 10.17: Loss = 914.809
Epoch 10.18: Loss = -1051.52
Epoch 10.19: Loss = 1163.39
Epoch 10.20: Loss = 599.865
Epoch 10.21: Loss = -140.537
Epoch 10.22: Loss = -159.179
Epoch 10.23: Loss = -737.3
Epoch 10.24: Loss = -310.852
Epoch 10.25: Loss = -448.455
Epoch 10.26: Loss = 2413
Epoch 10.27: Loss = 1587.62
Epoch 10.28: Loss = 1225.44
Epoch 10.29: Loss = -307.535
Epoch 10.30: Loss = 998.389
Epoch 10.31: Loss = -940.834
Epoch 10.32: Loss = 1636.92
Epoch 10.33: Loss = 2368.16
Epoch 10.34: Loss = -134.813
Epoch 10.35: Loss = 1622.67
Epoch 10.36: Loss = 562.674
Epoch 10.37: Loss = -668.894
Epoch 10.38: Loss = -784.211
Epoch 10.39: Loss = -1636.46
Epoch 10.40: Loss = -1166.53
Epoch 10.41: Loss = -477.406
Epoch 10.42: Loss = -760.769
Epoch 10.43: Loss = -497.432
Epoch 10.44: Loss = 1045.53
Epoch 10.45: Loss = -14.3556
Epoch 10.46: Loss = -2113.23
Epoch 10.47: Loss = 1190.87
Epoch 10.48: Loss = 2185.91
Epoch 10.49: Loss = -391.825
Epoch 10.50: Loss = -1826.55
Epoch 10.51: Loss = -1410.15
Epoch 10.52: Loss = -381.875
Epoch 10.53: Loss = -607.81
Epoch 10.54: Loss = 1325.75
Epoch 10.55: Loss = 1008.67
Epoch 10.56: Loss = -455.777
Epoch 10.57: Loss = 533.926
Epoch 10.58: Loss = 1482.4
Epoch 10.59: Loss = 1480.89
Epoch 10.60: Loss = -143.998
Epoch 10.61: Loss = -1195.83
Epoch 10.62: Loss = -281.66
Epoch 10.63: Loss = 1153.96
Epoch 10.64: Loss = 697.546
Epoch 10.65: Loss = 2332.17
Epoch 10.66: Loss = -379.525
Epoch 10.67: Loss = 172.086
Epoch 10.68: Loss = 2402.41
Epoch 10.69: Loss = -96.5172
Epoch 10.70: Loss = -390.914
Epoch 10.71: Loss = 496.202
Epoch 10.72: Loss = 96.8378
Epoch 10.73: Loss = -1537.7
Epoch 10.74: Loss = 50.3758
Epoch 10.75: Loss = -2628.21
Epoch 10.76: Loss = 1284.23
Epoch 10.77: Loss = 1943.9
Epoch 10.78: Loss = 840.383
Epoch 10.79: Loss = 1006.39
Epoch 10.80: Loss = 2173.83
Epoch 10.81: Loss = 1063.85
Epoch 10.82: Loss = 813.089
Epoch 10.83: Loss = 1635.32
Epoch 10.84: Loss = 1512.6
Epoch 10.85: Loss = 647.123
Epoch 10.86: Loss = 29.623
Epoch 10.87: Loss = 46.4435
Epoch 10.88: Loss = 1091.64
Epoch 10.89: Loss = 156.584
Epoch 10.90: Loss = -1380.74
Epoch 10.91: Loss = -561.658
Epoch 10.92: Loss = -768.226
Epoch 10.93: Loss = 878.198
Epoch 10.94: Loss = 1219.26
Epoch 10.95: Loss = 940.648
Epoch 10.96: Loss = -1132.06
Epoch 10.97: Loss = 1474.67
Epoch 10.98: Loss = 606.545
Epoch 10.99: Loss = -1120.3
Epoch 10.100: Loss = 67.6903
Epoch 10.101: Loss = -871.091
Epoch 10.102: Loss = -287.237
Epoch 10.103: Loss = 464.071
Epoch 10.104: Loss = 1105.89
Epoch 10.105: Loss = 611.539
Epoch 10.106: Loss = 276.801
Epoch 10.107: Loss = 440.867
Epoch 10.108: Loss = 2068.69
Epoch 10.109: Loss = 832.102
Epoch 10.110: Loss = -500.947
Epoch 10.111: Loss = -159.066
Epoch 10.112: Loss = -22.644
Epoch 10.113: Loss = -1827.24
Epoch 10.114: Loss = 1641.02
Epoch 10.115: Loss = 270.564
Epoch 10.116: Loss = 1011.77
Epoch 10.117: Loss = -235.381
Epoch 10.118: Loss = 304.886
Epoch 10.119: Loss = -416.487
Epoch 10.120: Loss = -4015.12
TRAIN LOSS = 178.403
TRAIN ACC = 10.0388 % (6023/60000)
Loss = 1043.85
Loss = -42.1472
Loss = 40.7509
Loss = 884.134
Loss = 382.057
Loss = -785.943
Loss = -2385.45
Loss = -46.712
Loss = 1414.35
Loss = -1462.12
Loss = -971.665
Loss = 805.564
Loss = -1370.15
Loss = -3645.32
Loss = 3084.76
Loss = 1323.56
Loss = 1076.73
Loss = -2232.01
Loss = 1.75594
Loss = -118.619
TEST LOSS = -1.23588
TEST ACC = 60.2295 % (1007/10000)
