Setting up connection 0
***********************************************************
Training FMNIST
Model: Dense([60000, 1, 256]) => Dense([60000, 1, 256]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 500
Num Epochs: 10
Learning Rate: 0.1 to 0.1 over 10 epochs
Clipping Factor: 4
Sigma: 2
***********************************************************
Epoch 1.1: Loss = 2.32825
Epoch 1.2: Loss = 2.29704
Epoch 1.3: Loss = 2.25041
Epoch 1.4: Loss = 2.18666
Epoch 1.5: Loss = 2.14357
Epoch 1.6: Loss = 2.07411
Epoch 1.7: Loss = 2.02025
Epoch 1.8: Loss = 2.00671
Epoch 1.9: Loss = 1.94473
Epoch 1.10: Loss = 1.92075
Epoch 1.11: Loss = 1.88181
Epoch 1.12: Loss = 1.82144
Epoch 1.13: Loss = 1.76224
Epoch 1.14: Loss = 1.72726
Epoch 1.15: Loss = 1.69916
Epoch 1.16: Loss = 1.66768
Epoch 1.17: Loss = 1.65704
Epoch 1.18: Loss = 1.61955
Epoch 1.19: Loss = 1.58231
Epoch 1.20: Loss = 1.51936
Epoch 1.21: Loss = 1.55737
Epoch 1.22: Loss = 1.51312
Epoch 1.23: Loss = 1.51274
Epoch 1.24: Loss = 1.4437
Epoch 1.25: Loss = 1.38054
Epoch 1.26: Loss = 1.33633
Epoch 1.27: Loss = 1.34724
Epoch 1.28: Loss = 1.3671
Epoch 1.29: Loss = 1.28477
Epoch 1.30: Loss = 1.24509
Epoch 1.31: Loss = 1.25365
Epoch 1.32: Loss = 1.18948
Epoch 1.33: Loss = 1.20721
Epoch 1.34: Loss = 1.18578
Epoch 1.35: Loss = 1.20532
Epoch 1.36: Loss = 1.14735
Epoch 1.37: Loss = 1.15213
Epoch 1.38: Loss = 1.23631
Epoch 1.39: Loss = 1.14371
Epoch 1.40: Loss = 1.09274
Epoch 1.41: Loss = 1.11632
Epoch 1.42: Loss = 1.07471
Epoch 1.43: Loss = 1.06877
Epoch 1.44: Loss = 1.0883
Epoch 1.45: Loss = 1.13016
Epoch 1.46: Loss = 1.01109
Epoch 1.47: Loss = 1.0318
Epoch 1.48: Loss = 1.0513
Epoch 1.49: Loss = 1.00468
Epoch 1.50: Loss = 1.00798
Epoch 1.51: Loss = 1.01898
Epoch 1.52: Loss = 0.973785
Epoch 1.53: Loss = 0.963989
Epoch 1.54: Loss = 0.963669
Epoch 1.55: Loss = 0.960983
Epoch 1.56: Loss = 0.939697
Epoch 1.57: Loss = 1.03514
Epoch 1.58: Loss = 0.975616
Epoch 1.59: Loss = 0.929016
Epoch 1.60: Loss = 0.919174
Epoch 1.61: Loss = 0.917648
Epoch 1.62: Loss = 0.886169
Epoch 1.63: Loss = 0.891876
Epoch 1.64: Loss = 0.889542
Epoch 1.65: Loss = 0.878815
Epoch 1.66: Loss = 0.919846
Epoch 1.67: Loss = 0.798828
Epoch 1.68: Loss = 0.923569
Epoch 1.69: Loss = 0.921875
Epoch 1.70: Loss = 0.831955
Epoch 1.71: Loss = 0.815872
Epoch 1.72: Loss = 0.89328
Epoch 1.73: Loss = 0.86467
Epoch 1.74: Loss = 0.86647
Epoch 1.75: Loss = 0.870178
Epoch 1.76: Loss = 0.829208
Epoch 1.77: Loss = 0.92366
Epoch 1.78: Loss = 0.895874
Epoch 1.79: Loss = 0.836914
Epoch 1.80: Loss = 0.797882
Epoch 1.81: Loss = 0.877686
Epoch 1.82: Loss = 0.826874
Epoch 1.83: Loss = 0.810074
Epoch 1.84: Loss = 0.881989
Epoch 1.85: Loss = 0.756149
Epoch 1.86: Loss = 0.881042
Epoch 1.87: Loss = 0.846237
Epoch 1.88: Loss = 0.789001
Epoch 1.89: Loss = 0.834015
Epoch 1.90: Loss = 0.840714
Epoch 1.91: Loss = 0.819473
Epoch 1.92: Loss = 0.75296
Epoch 1.93: Loss = 0.853134
Epoch 1.94: Loss = 0.846939
Epoch 1.95: Loss = 0.752502
Epoch 1.96: Loss = 0.869293
Epoch 1.97: Loss = 0.764847
Epoch 1.98: Loss = 0.833527
Epoch 1.99: Loss = 0.801468
Epoch 1.100: Loss = 0.792953
Epoch 1.101: Loss = 0.856995
Epoch 1.102: Loss = 0.851074
Epoch 1.103: Loss = 0.71933
Epoch 1.104: Loss = 0.750565
Epoch 1.105: Loss = 0.75473
Epoch 1.106: Loss = 0.726761
Epoch 1.107: Loss = 0.820328
Epoch 1.108: Loss = 0.764267
Epoch 1.109: Loss = 0.743164
Epoch 1.110: Loss = 0.780411
Epoch 1.111: Loss = 0.788834
Epoch 1.112: Loss = 0.797089
Epoch 1.113: Loss = 0.787216
Epoch 1.114: Loss = 0.780228
Epoch 1.115: Loss = 0.759842
Epoch 1.116: Loss = 0.80162
Epoch 1.117: Loss = 0.778061
Epoch 1.118: Loss = 0.766632
Epoch 1.119: Loss = 0.820175
Epoch 1.120: Loss = 0.720612
TRAIN LOSS = 1.1136
TRAIN ACC = 63.9694 % (38384/60000)
Loss = 0.685455
Loss = 0.798004
Loss = 0.786423
Loss = 0.683487
Loss = 0.672134
Loss = 0.853058
Loss = 0.868347
Loss = 0.838516
Loss = 0.759933
Loss = 0.681946
Loss = 0.794449
Loss = 0.771118
Loss = 0.771042
Loss = 0.791031
Loss = 0.733551
Loss = 0.827393
Loss = 0.680832
Loss = 0.776688
Loss = 0.819427
Loss = 0.765701
TEST LOSS = 0.767927
TEST ACC = 383.839 % (7273/10000)
Reducing learning rate to 0.100006
Epoch 2.1: Loss = 0.672226
Epoch 2.2: Loss = 0.805557
Epoch 2.3: Loss = 0.746613
Epoch 2.4: Loss = 0.761841
Epoch 2.5: Loss = 0.780273
Epoch 2.6: Loss = 0.798935
Epoch 2.7: Loss = 0.766525
Epoch 2.8: Loss = 0.678192
Epoch 2.9: Loss = 0.662994
Epoch 2.10: Loss = 0.759888
Epoch 2.11: Loss = 0.699448
Epoch 2.12: Loss = 0.758408
Epoch 2.13: Loss = 0.724869
Epoch 2.14: Loss = 0.797546
Epoch 2.15: Loss = 0.711197
Epoch 2.16: Loss = 0.720642
Epoch 2.17: Loss = 0.792526
Epoch 2.18: Loss = 0.810654
Epoch 2.19: Loss = 0.694717
Epoch 2.20: Loss = 0.734879
Epoch 2.21: Loss = 0.802307
Epoch 2.22: Loss = 0.665833
Epoch 2.23: Loss = 0.735397
Epoch 2.24: Loss = 0.725128
Epoch 2.25: Loss = 0.934998
Epoch 2.26: Loss = 0.646072
Epoch 2.27: Loss = 0.7798
Epoch 2.28: Loss = 0.727921
Epoch 2.29: Loss = 0.801758
Epoch 2.30: Loss = 0.879517
Epoch 2.31: Loss = 0.737656
Epoch 2.32: Loss = 0.769913
Epoch 2.33: Loss = 0.858963
Epoch 2.34: Loss = 0.731491
Epoch 2.35: Loss = 0.671295
Epoch 2.36: Loss = 0.790833
Epoch 2.37: Loss = 0.732498
Epoch 2.38: Loss = 0.810745
Epoch 2.39: Loss = 0.705399
Epoch 2.40: Loss = 0.770538
Epoch 2.41: Loss = 0.695908
Epoch 2.42: Loss = 0.822189
Epoch 2.43: Loss = 0.770172
Epoch 2.44: Loss = 0.676315
Epoch 2.45: Loss = 0.713333
Epoch 2.46: Loss = 0.738327
Epoch 2.47: Loss = 0.71286
Epoch 2.48: Loss = 0.719193
Epoch 2.49: Loss = 0.858109
Epoch 2.50: Loss = 0.773407
Epoch 2.51: Loss = 0.790619
Epoch 2.52: Loss = 0.783051
Epoch 2.53: Loss = 0.80687
Epoch 2.54: Loss = 0.721527
Epoch 2.55: Loss = 0.731003
Epoch 2.56: Loss = 0.705017
Epoch 2.57: Loss = 0.633377
Epoch 2.58: Loss = 0.668854
Epoch 2.59: Loss = 0.828659
Epoch 2.60: Loss = 0.773636
Epoch 2.61: Loss = 0.770294
Epoch 2.62: Loss = 0.680603
Epoch 2.63: Loss = 0.692535
Epoch 2.64: Loss = 0.80014
Epoch 2.65: Loss = 0.865936
Epoch 2.66: Loss = 0.846893
Epoch 2.67: Loss = 0.700058
Epoch 2.68: Loss = 0.737183
Epoch 2.69: Loss = 0.75206
Epoch 2.70: Loss = 0.729889
Epoch 2.71: Loss = 0.809021
Epoch 2.72: Loss = 0.745728
Epoch 2.73: Loss = 0.770447
Epoch 2.74: Loss = 0.630569
Epoch 2.75: Loss = 0.745316
Epoch 2.76: Loss = 0.74231
Epoch 2.77: Loss = 0.74733
Epoch 2.78: Loss = 0.792847
Epoch 2.79: Loss = 0.648239
Epoch 2.80: Loss = 0.691315
Epoch 2.81: Loss = 0.594086
Epoch 2.82: Loss = 0.797562
Epoch 2.83: Loss = 0.933517
Epoch 2.84: Loss = 0.640167
Epoch 2.85: Loss = 0.758118
Epoch 2.86: Loss = 0.739899
Epoch 2.87: Loss = 0.734329
Epoch 2.88: Loss = 0.698441
Epoch 2.89: Loss = 0.767227
Epoch 2.90: Loss = 0.75531
Epoch 2.91: Loss = 0.651337
Epoch 2.92: Loss = 0.713898
Epoch 2.93: Loss = 0.785416
Epoch 2.94: Loss = 0.794113
Epoch 2.95: Loss = 0.732651
Epoch 2.96: Loss = 0.647751
Epoch 2.97: Loss = 0.727661
Epoch 2.98: Loss = 0.740631
Epoch 2.99: Loss = 0.666107
Epoch 2.100: Loss = 0.739273
Epoch 2.101: Loss = 0.808762
Epoch 2.102: Loss = 0.754807
Epoch 2.103: Loss = 0.742249
Epoch 2.104: Loss = 0.689102
Epoch 2.105: Loss = 0.718399
Epoch 2.106: Loss = 0.849747
Epoch 2.107: Loss = 0.762222
Epoch 2.108: Loss = 0.75296
Epoch 2.109: Loss = 0.751633
Epoch 2.110: Loss = 0.821518
Epoch 2.111: Loss = 0.653976
Epoch 2.112: Loss = 0.741211
Epoch 2.113: Loss = 0.726013
Epoch 2.114: Loss = 0.652374
Epoch 2.115: Loss = 0.754623
Epoch 2.116: Loss = 0.595428
Epoch 2.117: Loss = 0.652054
Epoch 2.118: Loss = 0.868179
Epoch 2.119: Loss = 0.742325
Epoch 2.120: Loss = 0.715286
TRAIN LOSS = 0.744583
TRAIN ACC = 75.3113 % (45189/60000)
Loss = 0.653412
Loss = 0.75592
Loss = 0.733795
Loss = 0.631683
Loss = 0.635483
Loss = 0.857681
Loss = 0.848007
Loss = 0.820053
Loss = 0.720718
Loss = 0.627243
Loss = 0.793381
Loss = 0.77951
Loss = 0.732147
Loss = 0.746658
Loss = 0.695023
Loss = 0.789795
Loss = 0.669159
Loss = 0.776611
Loss = 0.798492
Loss = 0.748596
TEST LOSS = 0.740668
TEST ACC = 451.889 % (7560/10000)
Reducing learning rate to 0.100006
Epoch 3.1: Loss = 0.764481
Epoch 3.2: Loss = 0.730423
Epoch 3.3: Loss = 0.83226
Epoch 3.4: Loss = 0.680161
Epoch 3.5: Loss = 0.684616
Epoch 3.6: Loss = 0.751236
Epoch 3.7: Loss = 0.807755
Epoch 3.8: Loss = 0.710754
Epoch 3.9: Loss = 0.700684
Epoch 3.10: Loss = 0.725067
Epoch 3.11: Loss = 0.700363
Epoch 3.12: Loss = 0.634186
Epoch 3.13: Loss = 0.734512
Epoch 3.14: Loss = 0.719055
Epoch 3.15: Loss = 0.693481
Epoch 3.16: Loss = 0.906998
Epoch 3.17: Loss = 0.776611
Epoch 3.18: Loss = 0.701462
Epoch 3.19: Loss = 0.759598
Epoch 3.20: Loss = 0.722382
Epoch 3.21: Loss = 0.73439
Epoch 3.22: Loss = 0.663849
Epoch 3.23: Loss = 0.80545
Epoch 3.24: Loss = 0.797775
Epoch 3.25: Loss = 0.786789
Epoch 3.26: Loss = 0.729019
Epoch 3.27: Loss = 0.652878
Epoch 3.28: Loss = 0.641586
Epoch 3.29: Loss = 0.721329
Epoch 3.30: Loss = 0.678162
Epoch 3.31: Loss = 0.87117
Epoch 3.32: Loss = 0.836487
Epoch 3.33: Loss = 0.71109
Epoch 3.34: Loss = 0.758835
Epoch 3.35: Loss = 0.663925
Epoch 3.36: Loss = 0.721603
Epoch 3.37: Loss = 0.626999
Epoch 3.38: Loss = 0.712814
Epoch 3.39: Loss = 0.791855
Epoch 3.40: Loss = 0.757187
Epoch 3.41: Loss = 0.771362
Epoch 3.42: Loss = 0.755386
Epoch 3.43: Loss = 0.708588
Epoch 3.44: Loss = 0.730576
Epoch 3.45: Loss = 0.71524
Epoch 3.46: Loss = 0.754074
Epoch 3.47: Loss = 0.620102
Epoch 3.48: Loss = 0.752884
Epoch 3.49: Loss = 0.763306
Epoch 3.50: Loss = 0.717316
Epoch 3.51: Loss = 0.676529
Epoch 3.52: Loss = 0.75058
Epoch 3.53: Loss = 0.632889
Epoch 3.54: Loss = 0.709717
Epoch 3.55: Loss = 0.766724
Epoch 3.56: Loss = 0.685547
Epoch 3.57: Loss = 0.794281
Epoch 3.58: Loss = 0.630264
Epoch 3.59: Loss = 0.727203
Epoch 3.60: Loss = 0.7061
Epoch 3.61: Loss = 0.76622
Epoch 3.62: Loss = 0.739853
Epoch 3.63: Loss = 0.722809
Epoch 3.64: Loss = 0.745956
Epoch 3.65: Loss = 0.752106
Epoch 3.66: Loss = 0.790207
Epoch 3.67: Loss = 0.739594
Epoch 3.68: Loss = 0.715576
Epoch 3.69: Loss = 0.784332
Epoch 3.70: Loss = 0.808884
Epoch 3.71: Loss = 0.658203
Epoch 3.72: Loss = 0.77597
Epoch 3.73: Loss = 0.655167
Epoch 3.74: Loss = 0.718536
Epoch 3.75: Loss = 0.799698
Epoch 3.76: Loss = 0.596268
Epoch 3.77: Loss = 0.827194
Epoch 3.78: Loss = 0.82608
Epoch 3.79: Loss = 0.730011
Epoch 3.80: Loss = 0.798538
Epoch 3.81: Loss = 0.784393
Epoch 3.82: Loss = 0.782867
Epoch 3.83: Loss = 0.88002
Epoch 3.84: Loss = 0.754639
Epoch 3.85: Loss = 0.71347
Epoch 3.86: Loss = 0.862396
Epoch 3.87: Loss = 0.783951
Epoch 3.88: Loss = 0.788971
Epoch 3.89: Loss = 0.618393
Epoch 3.90: Loss = 0.780548
Epoch 3.91: Loss = 0.640121
Epoch 3.92: Loss = 0.628128
Epoch 3.93: Loss = 0.670578
Epoch 3.94: Loss = 0.788483
Epoch 3.95: Loss = 0.625183
Epoch 3.96: Loss = 0.73703
Epoch 3.97: Loss = 0.667953
Epoch 3.98: Loss = 0.662537
Epoch 3.99: Loss = 0.666824
Epoch 3.100: Loss = 0.74379
Epoch 3.101: Loss = 0.773987
Epoch 3.102: Loss = 0.727798
Epoch 3.103: Loss = 0.851959
Epoch 3.104: Loss = 0.669174
Epoch 3.105: Loss = 0.78273
Epoch 3.106: Loss = 0.751007
Epoch 3.107: Loss = 0.70282
Epoch 3.108: Loss = 0.774628
Epoch 3.109: Loss = 0.705994
Epoch 3.110: Loss = 0.662979
Epoch 3.111: Loss = 0.725449
Epoch 3.112: Loss = 0.758087
Epoch 3.113: Loss = 0.609756
Epoch 3.114: Loss = 0.758972
Epoch 3.115: Loss = 0.844101
Epoch 3.116: Loss = 0.748962
Epoch 3.117: Loss = 0.779877
Epoch 3.118: Loss = 0.706909
Epoch 3.119: Loss = 0.868469
Epoch 3.120: Loss = 0.757736
TRAIN LOSS = 0.735519
TRAIN ACC = 77.3911 % (46436/60000)
Loss = 0.621964
Loss = 0.741882
Loss = 0.692001
Loss = 0.626694
Loss = 0.654022
Loss = 0.811691
Loss = 0.874786
Loss = 0.792801
Loss = 0.745621
Loss = 0.653915
Loss = 0.825211
Loss = 0.786438
Loss = 0.73465
Loss = 0.774384
Loss = 0.688477
Loss = 0.785797
Loss = 0.669357
Loss = 0.783447
Loss = 0.764297
Loss = 0.738983
TEST LOSS = 0.738321
TEST ACC = 464.359 % (7719/10000)
Reducing learning rate to 0.100006
Epoch 4.1: Loss = 0.703308
Epoch 4.2: Loss = 0.739166
Epoch 4.3: Loss = 0.916519
Epoch 4.4: Loss = 0.84407
Epoch 4.5: Loss = 0.778976
Epoch 4.6: Loss = 0.728561
Epoch 4.7: Loss = 0.849274
Epoch 4.8: Loss = 0.76532
Epoch 4.9: Loss = 0.723923
Epoch 4.10: Loss = 0.778412
Epoch 4.11: Loss = 0.724106
Epoch 4.12: Loss = 0.677536
Epoch 4.13: Loss = 0.701385
Epoch 4.14: Loss = 0.721008
Epoch 4.15: Loss = 0.684052
Epoch 4.16: Loss = 0.7267
Epoch 4.17: Loss = 0.681305
Epoch 4.18: Loss = 0.64241
Epoch 4.19: Loss = 0.77562
Epoch 4.20: Loss = 0.792633
Epoch 4.21: Loss = 0.698135
Epoch 4.22: Loss = 0.662079
Epoch 4.23: Loss = 0.729507
Epoch 4.24: Loss = 0.723434
Epoch 4.25: Loss = 0.690262
Epoch 4.26: Loss = 0.600677
Epoch 4.27: Loss = 0.605453
Epoch 4.28: Loss = 0.888809
Epoch 4.29: Loss = 0.725296
Epoch 4.30: Loss = 0.759781
Epoch 4.31: Loss = 0.70195
Epoch 4.32: Loss = 0.721878
Epoch 4.33: Loss = 0.629272
Epoch 4.34: Loss = 0.774261
Epoch 4.35: Loss = 0.637589
Epoch 4.36: Loss = 0.845261
Epoch 4.37: Loss = 0.624191
Epoch 4.38: Loss = 0.78186
Epoch 4.39: Loss = 0.785843
Epoch 4.40: Loss = 0.757217
Epoch 4.41: Loss = 0.738831
Epoch 4.42: Loss = 0.672516
Epoch 4.43: Loss = 0.674393
Epoch 4.44: Loss = 0.685043
Epoch 4.45: Loss = 0.752991
Epoch 4.46: Loss = 0.697021
Epoch 4.47: Loss = 0.979813
Epoch 4.48: Loss = 0.780365
Epoch 4.49: Loss = 0.661865
Epoch 4.50: Loss = 0.701141
Epoch 4.51: Loss = 0.890305
Epoch 4.52: Loss = 0.740982
Epoch 4.53: Loss = 0.804428
Epoch 4.54: Loss = 0.755051
Epoch 4.55: Loss = 0.801346
Epoch 4.56: Loss = 0.698349
Epoch 4.57: Loss = 0.796494
Epoch 4.58: Loss = 0.755707
Epoch 4.59: Loss = 0.680557
Epoch 4.60: Loss = 0.747192
Epoch 4.61: Loss = 0.883041
Epoch 4.62: Loss = 0.719742
Epoch 4.63: Loss = 0.692032
Epoch 4.64: Loss = 0.720245
Epoch 4.65: Loss = 0.756866
Epoch 4.66: Loss = 0.737915
Epoch 4.67: Loss = 0.779282
Epoch 4.68: Loss = 0.721039
Epoch 4.69: Loss = 0.831085
Epoch 4.70: Loss = 0.701385
Epoch 4.71: Loss = 0.689713
Epoch 4.72: Loss = 0.759293
Epoch 4.73: Loss = 0.764618
Epoch 4.74: Loss = 0.748581
Epoch 4.75: Loss = 0.66069
Epoch 4.76: Loss = 0.849503
Epoch 4.77: Loss = 0.686798
Epoch 4.78: Loss = 0.760132
Epoch 4.79: Loss = 0.74794
Epoch 4.80: Loss = 0.739105
Epoch 4.81: Loss = 0.856186
Epoch 4.82: Loss = 0.631989
Epoch 4.83: Loss = 0.69725
Epoch 4.84: Loss = 0.897491
Epoch 4.85: Loss = 0.724396
Epoch 4.86: Loss = 0.617966
Epoch 4.87: Loss = 0.759415
Epoch 4.88: Loss = 0.948441
Epoch 4.89: Loss = 0.649155
Epoch 4.90: Loss = 0.821243
Epoch 4.91: Loss = 0.82785
Epoch 4.92: Loss = 0.819107
Epoch 4.93: Loss = 0.7854
Epoch 4.94: Loss = 0.670593
Epoch 4.95: Loss = 0.678268
Epoch 4.96: Loss = 0.768097
Epoch 4.97: Loss = 0.705917
Epoch 4.98: Loss = 0.691467
Epoch 4.99: Loss = 0.745865
Epoch 4.100: Loss = 0.943863
Epoch 4.101: Loss = 0.80748
Epoch 4.102: Loss = 0.698074
Epoch 4.103: Loss = 0.697601
Epoch 4.104: Loss = 0.974762
Epoch 4.105: Loss = 0.729233
Epoch 4.106: Loss = 0.734436
Epoch 4.107: Loss = 0.941528
Epoch 4.108: Loss = 0.751923
Epoch 4.109: Loss = 0.844147
Epoch 4.110: Loss = 0.808151
Epoch 4.111: Loss = 0.581482
Epoch 4.112: Loss = 0.624268
Epoch 4.113: Loss = 0.825455
Epoch 4.114: Loss = 0.753723
Epoch 4.115: Loss = 0.820404
Epoch 4.116: Loss = 0.797974
Epoch 4.117: Loss = 0.664841
Epoch 4.118: Loss = 0.747604
Epoch 4.119: Loss = 0.840988
Epoch 4.120: Loss = 0.684113
TRAIN LOSS = 0.748581
TRAIN ACC = 78.363 % (47020/60000)
Loss = 0.703644
Loss = 0.819778
Loss = 0.752167
Loss = 0.705185
Loss = 0.729477
Loss = 0.909119
Loss = 0.941742
Loss = 0.918564
Loss = 0.783966
Loss = 0.671173
Loss = 0.912094
Loss = 0.845551
Loss = 0.813232
Loss = 0.782791
Loss = 0.780289
Loss = 0.834625
Loss = 0.753891
Loss = 0.851288
Loss = 0.839432
Loss = 0.840149
TEST LOSS = 0.809408
TEST ACC = 470.2 % (7729/10000)
Reducing learning rate to 0.100006
Epoch 5.1: Loss = 0.803772
Epoch 5.2: Loss = 0.815414
Epoch 5.3: Loss = 0.883194
Epoch 5.4: Loss = 0.702316
Epoch 5.5: Loss = 0.947876
Epoch 5.6: Loss = 0.910294
Epoch 5.7: Loss = 0.885834
Epoch 5.8: Loss = 0.879929
Epoch 5.9: Loss = 0.722565
Epoch 5.10: Loss = 0.715515
Epoch 5.11: Loss = 0.717209
Epoch 5.12: Loss = 0.925858
Epoch 5.13: Loss = 0.750641
Epoch 5.14: Loss = 0.837234
Epoch 5.15: Loss = 0.682953
Epoch 5.16: Loss = 0.794571
Epoch 5.17: Loss = 0.831543
Epoch 5.18: Loss = 0.799911
Epoch 5.19: Loss = 0.753082
Epoch 5.20: Loss = 0.74382
Epoch 5.21: Loss = 0.851013
Epoch 5.22: Loss = 0.597595
Epoch 5.23: Loss = 0.676743
Epoch 5.24: Loss = 0.87117
Epoch 5.25: Loss = 0.814728
Epoch 5.26: Loss = 0.779648
Epoch 5.27: Loss = 0.915558
Epoch 5.28: Loss = 0.76265
Epoch 5.29: Loss = 0.67392
Epoch 5.30: Loss = 0.756989
Epoch 5.31: Loss = 0.801804
Epoch 5.32: Loss = 0.75676
Epoch 5.33: Loss = 0.819412
Epoch 5.34: Loss = 0.922241
Epoch 5.35: Loss = 0.921509
Epoch 5.36: Loss = 0.820679
Epoch 5.37: Loss = 0.740326
Epoch 5.38: Loss = 0.786621
Epoch 5.39: Loss = 0.850006
Epoch 5.40: Loss = 0.608139
Epoch 5.41: Loss = 0.70166
Epoch 5.42: Loss = 0.676819
Epoch 5.43: Loss = 0.798737
Epoch 5.44: Loss = 0.776276
Epoch 5.45: Loss = 0.929214
Epoch 5.46: Loss = 0.72702
Epoch 5.47: Loss = 0.876175
Epoch 5.48: Loss = 0.800064
Epoch 5.49: Loss = 0.77092
Epoch 5.50: Loss = 0.863968
Epoch 5.51: Loss = 1.07503
Epoch 5.52: Loss = 0.720322
Epoch 5.53: Loss = 0.856888
Epoch 5.54: Loss = 0.807922
Epoch 5.55: Loss = 0.837021
Epoch 5.56: Loss = 0.837967
Epoch 5.57: Loss = 0.835403
Epoch 5.58: Loss = 0.864822
Epoch 5.59: Loss = 0.724564
Epoch 5.60: Loss = 0.732803
Epoch 5.61: Loss = 0.894455
Epoch 5.62: Loss = 0.853821
Epoch 5.63: Loss = 0.995407
Epoch 5.64: Loss = 0.876907
Epoch 5.65: Loss = 0.849213
Epoch 5.66: Loss = 0.584335
Epoch 5.67: Loss = 0.935059
Epoch 5.68: Loss = 0.815704
Epoch 5.69: Loss = 0.798187
Epoch 5.70: Loss = 0.85025
Epoch 5.71: Loss = 0.795288
Epoch 5.72: Loss = 0.823654
Epoch 5.73: Loss = 0.717178
Epoch 5.74: Loss = 0.840408
Epoch 5.75: Loss = 0.864868
Epoch 5.76: Loss = 0.820801
Epoch 5.77: Loss = 0.778183
Epoch 5.78: Loss = 0.762665
Epoch 5.79: Loss = 0.841217
Epoch 5.80: Loss = 0.807938
Epoch 5.81: Loss = 0.831055
Epoch 5.82: Loss = 0.848557
Epoch 5.83: Loss = 0.728271
Epoch 5.84: Loss = 0.929871
Epoch 5.85: Loss = 0.827316
Epoch 5.86: Loss = 0.689682
Epoch 5.87: Loss = 0.762756
Epoch 5.88: Loss = 0.891266
Epoch 5.89: Loss = 0.831284
Epoch 5.90: Loss = 0.777176
Epoch 5.91: Loss = 0.622055
Epoch 5.92: Loss = 0.716949
Epoch 5.93: Loss = 0.774887
Epoch 5.94: Loss = 0.689072
Epoch 5.95: Loss = 0.782547
Epoch 5.96: Loss = 0.865707
Epoch 5.97: Loss = 0.827576
Epoch 5.98: Loss = 0.89209
Epoch 5.99: Loss = 0.847214
Epoch 5.100: Loss = 0.790237
Epoch 5.101: Loss = 0.593872
Epoch 5.102: Loss = 0.675949
Epoch 5.103: Loss = 0.902512
Epoch 5.104: Loss = 0.829285
Epoch 5.105: Loss = 0.763397
Epoch 5.106: Loss = 0.704498
Epoch 5.107: Loss = 0.719894
Epoch 5.108: Loss = 0.886002
Epoch 5.109: Loss = 0.722717
Epoch 5.110: Loss = 0.894135
Epoch 5.111: Loss = 0.812164
Epoch 5.112: Loss = 0.870605
Epoch 5.113: Loss = 0.702576
Epoch 5.114: Loss = 0.859436
Epoch 5.115: Loss = 0.860779
Epoch 5.116: Loss = 0.888321
Epoch 5.117: Loss = 0.799576
Epoch 5.118: Loss = 0.945511
Epoch 5.119: Loss = 0.834198
Epoch 5.120: Loss = 0.989761
TRAIN LOSS = 0.806107
TRAIN ACC = 78.6484 % (47192/60000)
Loss = 0.737854
Loss = 0.841064
Loss = 0.842041
Loss = 0.735397
Loss = 0.773148
Loss = 0.910049
Loss = 1.03572
Loss = 0.909409
Loss = 0.877487
Loss = 0.718323
Loss = 0.98201
Loss = 0.910751
Loss = 0.893356
Loss = 0.837311
Loss = 0.866226
Loss = 0.883408
Loss = 0.732117
Loss = 0.922775
Loss = 0.916626
Loss = 0.879471
TEST LOSS = 0.860227
TEST ACC = 471.919 % (7702/10000)
Reducing learning rate to 0.100006
Epoch 6.1: Loss = 0.811371
Epoch 6.2: Loss = 0.735855
Epoch 6.3: Loss = 1.01585
Epoch 6.4: Loss = 0.741425
Epoch 6.5: Loss = 0.828812
Epoch 6.6: Loss = 0.903793
Epoch 6.7: Loss = 0.704254
Epoch 6.8: Loss = 0.945541
Epoch 6.9: Loss = 0.875763
Epoch 6.10: Loss = 0.797302
Epoch 6.11: Loss = 0.795532
Epoch 6.12: Loss = 1.11812
Epoch 6.13: Loss = 0.952957
Epoch 6.14: Loss = 0.826401
Epoch 6.15: Loss = 0.747971
Epoch 6.16: Loss = 0.994492
Epoch 6.17: Loss = 0.832916
Epoch 6.18: Loss = 0.833237
Epoch 6.19: Loss = 0.963531
Epoch 6.20: Loss = 0.729599
Epoch 6.21: Loss = 0.90654
Epoch 6.22: Loss = 0.911499
Epoch 6.23: Loss = 0.85141
Epoch 6.24: Loss = 0.940002
Epoch 6.25: Loss = 0.868088
Epoch 6.26: Loss = 0.87645
Epoch 6.27: Loss = 0.822723
Epoch 6.28: Loss = 0.729065
Epoch 6.29: Loss = 0.752533
Epoch 6.30: Loss = 0.74527
Epoch 6.31: Loss = 0.967438
Epoch 6.32: Loss = 0.731735
Epoch 6.33: Loss = 0.749847
Epoch 6.34: Loss = 0.77652
Epoch 6.35: Loss = 0.879532
Epoch 6.36: Loss = 0.775742
Epoch 6.37: Loss = 0.852966
Epoch 6.38: Loss = 0.91658
Epoch 6.39: Loss = 0.885391
Epoch 6.40: Loss = 0.989487
Epoch 6.41: Loss = 0.893433
Epoch 6.42: Loss = 0.76236
Epoch 6.43: Loss = 0.859299
Epoch 6.44: Loss = 0.873032
Epoch 6.45: Loss = 0.966751
Epoch 6.46: Loss = 0.849976
Epoch 6.47: Loss = 0.793884
Epoch 6.48: Loss = 0.79512
Epoch 6.49: Loss = 0.889664
Epoch 6.50: Loss = 0.718109
Epoch 6.51: Loss = 0.927933
Epoch 6.52: Loss = 0.869125
Epoch 6.53: Loss = 0.860397
Epoch 6.54: Loss = 1.05937
Epoch 6.55: Loss = 1.25294
Epoch 6.56: Loss = 0.876022
Epoch 6.57: Loss = 1.1481
Epoch 6.58: Loss = 0.744034
Epoch 6.59: Loss = 0.86174
Epoch 6.60: Loss = 0.879562
Epoch 6.61: Loss = 1.12894
Epoch 6.62: Loss = 0.836136
Epoch 6.63: Loss = 0.855164
Epoch 6.64: Loss = 0.793793
Epoch 6.65: Loss = 0.662674
Epoch 6.66: Loss = 0.854034
Epoch 6.67: Loss = 0.713593
Epoch 6.68: Loss = 0.843643
Epoch 6.69: Loss = 0.999344
Epoch 6.70: Loss = 0.87561
Epoch 6.71: Loss = 0.672318
Epoch 6.72: Loss = 0.958298
Epoch 6.73: Loss = 0.944855
Epoch 6.74: Loss = 0.94603
Epoch 6.75: Loss = 0.885818
Epoch 6.76: Loss = 0.952682
Epoch 6.77: Loss = 2.30753
Epoch 6.78: Loss = 1.19669
Epoch 6.79: Loss = 1.02133
Epoch 6.80: Loss = 0.849014
Epoch 6.81: Loss = 0.985718
Epoch 6.82: Loss = 0.960205
Epoch 6.83: Loss = 0.793747
Epoch 6.84: Loss = 0.862366
Epoch 6.85: Loss = 0.75235
Epoch 6.86: Loss = 0.87381
Epoch 6.87: Loss = 1.04544
Epoch 6.88: Loss = 0.802811
Epoch 6.89: Loss = 0.858078
Epoch 6.90: Loss = 0.697464
Epoch 6.91: Loss = 31.8311
Epoch 6.92: Loss = 60.0894
Epoch 6.93: Loss = 13089.7
Epoch 6.94: Loss = -2915.82
Epoch 6.95: Loss = -97.8307
Epoch 6.96: Loss = 933.937
Epoch 6.97: Loss = 236.157
Epoch 6.98: Loss = -669.305
Epoch 6.99: Loss = 497.704
Epoch 6.100: Loss = 724.333
Epoch 6.101: Loss = -215.573
Epoch 6.102: Loss = -1109.65
Epoch 6.103: Loss = -214.477
Epoch 6.104: Loss = 7.93535
Epoch 6.105: Loss = -376.447
Epoch 6.106: Loss = 1140.28
Epoch 6.107: Loss = -1087.52
Epoch 6.108: Loss = -637.076
Epoch 6.109: Loss = -368.084
Epoch 6.110: Loss = -679.094
Epoch 6.111: Loss = 284.582
Epoch 6.112: Loss = -568.426
Epoch 6.113: Loss = -2580.88
Epoch 6.114: Loss = 354.143
Epoch 6.115: Loss = 689.247
Epoch 6.116: Loss = -1392.86
Epoch 6.117: Loss = 1278.91
Epoch 6.118: Loss = -293.703
Epoch 6.119: Loss = -1596.29
Epoch 6.120: Loss = -484.322
TRAIN LOSS = 34.3458
TRAIN ACC = 60.7605 % (36458/60000)
Loss = 250.393
Loss = -419.996
Loss = -766.958
Loss = 761.694
Loss = -282.184
Loss = -959.231
Loss = -954.925
Loss = 91.3173
Loss = -74.6629
Loss = -741.455
Loss = -261.815
Loss = -2024.59
Loss = 1764.63
Loss = 1021.24
Loss = -1492.82
Loss = -1757.28
Loss = -1495.13
Loss = -2282.63
Loss = -1623.82
Loss = -609.175
TEST LOSS = -3.04672
TEST ACC = 364.58 % (1027/10000)
Reducing learning rate to 0.100006
Epoch 7.1: Loss = -462.629
Epoch 7.2: Loss = 2295.92
Epoch 7.3: Loss = 967.011
Epoch 7.4: Loss = 736.229
Epoch 7.5: Loss = -939.029
Epoch 7.6: Loss = 1065.91
Epoch 7.7: Loss = 686.02
Epoch 7.8: Loss = -2504.85
Epoch 7.9: Loss = -155.67
Epoch 7.10: Loss = 1263.09
Epoch 7.11: Loss = -313.558
Epoch 7.12: Loss = 763.652
Epoch 7.13: Loss = -432.434
Epoch 7.14: Loss = 717.528
Epoch 7.15: Loss = 381.638
Epoch 7.16: Loss = -1139.06
Epoch 7.17: Loss = 1135.67
Epoch 7.18: Loss = 321.169
Epoch 7.19: Loss = 494.201
Epoch 7.20: Loss = -2683.26
Epoch 7.21: Loss = 563.648
Epoch 7.22: Loss = 322.072
Epoch 7.23: Loss = 489.192
Epoch 7.24: Loss = 1145.01
Epoch 7.25: Loss = 287.039
Epoch 7.26: Loss = -561.691
Epoch 7.27: Loss = 1083.42
Epoch 7.28: Loss = -159.725
Epoch 7.29: Loss = -2355.13
Epoch 7.30: Loss = 1357.29
Epoch 7.31: Loss = -434.189
Epoch 7.32: Loss = 604.979
Epoch 7.33: Loss = 2535.23
Epoch 7.34: Loss = -1031
Epoch 7.35: Loss = -956.164
Epoch 7.36: Loss = -1652.31
Epoch 7.37: Loss = 2064.8
Epoch 7.38: Loss = -361.158
Epoch 7.39: Loss = -244.841
Epoch 7.40: Loss = 806.196
Epoch 7.41: Loss = -1299.74
Epoch 7.42: Loss = -1656.16
Epoch 7.43: Loss = -193.381
Epoch 7.44: Loss = -30.2503
Epoch 7.45: Loss = 841.46
Epoch 7.46: Loss = 249.302
Epoch 7.47: Loss = 1419.79
Epoch 7.48: Loss = 535.797
Epoch 7.49: Loss = -101.731
Epoch 7.50: Loss = -1159.38
Epoch 7.51: Loss = 53.4801
Epoch 7.52: Loss = 459.211
Epoch 7.53: Loss = 1174.42
Epoch 7.54: Loss = 858.065
Epoch 7.55: Loss = 2785.31
Epoch 7.56: Loss = -376.937
Epoch 7.57: Loss = 975.004
Epoch 7.58: Loss = 1343.29
Epoch 7.59: Loss = -705.874
Epoch 7.60: Loss = 936.36
Epoch 7.61: Loss = -274.742
Epoch 7.62: Loss = 1479.93
Epoch 7.63: Loss = -768.732
Epoch 7.64: Loss = 681.812
Epoch 7.65: Loss = 946.553
Epoch 7.66: Loss = 392.614
Epoch 7.67: Loss = -461.344
Epoch 7.68: Loss = -1216.96
Epoch 7.69: Loss = 1617.55
Epoch 7.70: Loss = 646.749
Epoch 7.71: Loss = 1375.09
Epoch 7.72: Loss = 935.651
Epoch 7.73: Loss = 1971.07
Epoch 7.74: Loss = -1139.03
Epoch 7.75: Loss = 637.948
Epoch 7.76: Loss = 379.692
Epoch 7.77: Loss = 429.8
Epoch 7.78: Loss = 800.417
Epoch 7.79: Loss = 898.649
Epoch 7.80: Loss = -440.982
Epoch 7.81: Loss = 979.739
Epoch 7.82: Loss = 1055.97
Epoch 7.83: Loss = -112.298
Epoch 7.84: Loss = 1332.41
Epoch 7.85: Loss = -428.812
Epoch 7.86: Loss = 1927.47
Epoch 7.87: Loss = -137.217
Epoch 7.88: Loss = 1950.3
Epoch 7.89: Loss = 161.846
Epoch 7.90: Loss = -388.365
Epoch 7.91: Loss = 351.613
Epoch 7.92: Loss = 550.675
Epoch 7.93: Loss = 434.15
Epoch 7.94: Loss = 1949.15
Epoch 7.95: Loss = 1410.82
Epoch 7.96: Loss = 939.379
Epoch 7.97: Loss = -3130.32
Epoch 7.98: Loss = 750.216
Epoch 7.99: Loss = 979.234
Epoch 7.100: Loss = 297.983
Epoch 7.101: Loss = 997.415
Epoch 7.102: Loss = 1059.83
Epoch 7.103: Loss = 502.605
Epoch 7.104: Loss = 3494.15
Epoch 7.105: Loss = -604.33
Epoch 7.106: Loss = 224.525
Epoch 7.107: Loss = -402.77
Epoch 7.108: Loss = 1303.97
Epoch 7.109: Loss = 1001.69
Epoch 7.110: Loss = -363.843
Epoch 7.111: Loss = 82.7278
Epoch 7.112: Loss = 1277.1
Epoch 7.113: Loss = 266.993
Epoch 7.114: Loss = -772.287
Epoch 7.115: Loss = 806.392
Epoch 7.116: Loss = -253.634
Epoch 7.117: Loss = 242.478
Epoch 7.118: Loss = 1318.55
Epoch 7.119: Loss = 134.112
Epoch 7.120: Loss = 1179.49
TRAIN LOSS = 358.915
TRAIN ACC = 9.69086 % (5815/60000)
Loss = -1798.71
Loss = 2386.77
Loss = 276.641
Loss = 1023.42
Loss = -1932.71
Loss = -915.971
Loss = 760.962
Loss = 2863.34
Loss = 1442.47
Loss = 519.358
Loss = -1672.71
Loss = 1438.42
Loss = -1621.97
Loss = 1291.35
Loss = -672.633
Loss = 2365.21
Loss = 1476.48
Loss = 333.157
Loss = 1758.19
Loss = -306.583
TEST LOSS = 0.362337
TEST ACC = 58.1497 % (942/10000)
Reducing learning rate to 0.100006
Epoch 8.1: Loss = -146.259
Epoch 8.2: Loss = 1429.83
Epoch 8.3: Loss = -1647.01
Epoch 8.4: Loss = 1436.45
Epoch 8.5: Loss = -1614.56
Epoch 8.6: Loss = 914.07
Epoch 8.7: Loss = -1107.56
Epoch 8.8: Loss = -718.372
Epoch 8.9: Loss = -445.591
Epoch 8.10: Loss = 633.489
Epoch 8.11: Loss = -53.7533
Epoch 8.12: Loss = -1116.02
Epoch 8.13: Loss = -1279.44
Epoch 8.14: Loss = 1870.92
Epoch 8.15: Loss = 159.911
Epoch 8.16: Loss = 2261.41
Epoch 8.17: Loss = -1940.73
Epoch 8.18: Loss = -924.327
Epoch 8.19: Loss = 1192.07
Epoch 8.20: Loss = 1403.47
Epoch 8.21: Loss = -611.463
Epoch 8.22: Loss = 433.692
Epoch 8.23: Loss = 2311.63
Epoch 8.24: Loss = 2283.59
Epoch 8.25: Loss = 1500.11
Epoch 8.26: Loss = -103.38
Epoch 8.27: Loss = 528.802
Epoch 8.28: Loss = -112.046
Epoch 8.29: Loss = 192.805
Epoch 8.30: Loss = -2003.49
Epoch 8.31: Loss = 296.752
Epoch 8.32: Loss = -1204.4
Epoch 8.33: Loss = -1902.12
Epoch 8.34: Loss = 2711.4
Epoch 8.35: Loss = -1571.76
Epoch 8.36: Loss = -2997.68
Epoch 8.37: Loss = 1971.82
Epoch 8.38: Loss = 286.406
Epoch 8.39: Loss = 1501.11
Epoch 8.40: Loss = -746.553
Epoch 8.41: Loss = 917.116
Epoch 8.42: Loss = 1890.81
Epoch 8.43: Loss = 1101.58
Epoch 8.44: Loss = -246.681
Epoch 8.45: Loss = -1630.45
Epoch 8.46: Loss = -2369.92
Epoch 8.47: Loss = 1929.76
Epoch 8.48: Loss = -238.845
Epoch 8.49: Loss = -1014.68
Epoch 8.50: Loss = -656.084
Epoch 8.51: Loss = -1516.15
Epoch 8.52: Loss = -469.04
Epoch 8.53: Loss = -509.253
Epoch 8.54: Loss = 395.677
Epoch 8.55: Loss = -385.065
Epoch 8.56: Loss = 1175.24
Epoch 8.57: Loss = 1384.6
Epoch 8.58: Loss = 1443.78
Epoch 8.59: Loss = -728.56
Epoch 8.60: Loss = -1663.87
Epoch 8.61: Loss = 189.499
Epoch 8.62: Loss = 1590.98
Epoch 8.63: Loss = 405.197
Epoch 8.64: Loss = -161.82
Epoch 8.65: Loss = 1180.32
Epoch 8.66: Loss = -1853.39
Epoch 8.67: Loss = 420.157
Epoch 8.68: Loss = -3621.59
Epoch 8.69: Loss = -3015.23
Epoch 8.70: Loss = 1033.52
Epoch 8.71: Loss = -729.659
Epoch 8.72: Loss = -2097.16
Epoch 8.73: Loss = -1865.18
Epoch 8.74: Loss = -1328.36
Epoch 8.75: Loss = 1116.48
Epoch 8.76: Loss = 232.888
Epoch 8.77: Loss = -44.7053
Epoch 8.78: Loss = 480.967
Epoch 8.79: Loss = -960.702
Epoch 8.80: Loss = 496.249
Epoch 8.81: Loss = -557.917
Epoch 8.82: Loss = 1349.34
Epoch 8.83: Loss = 1400.73
Epoch 8.84: Loss = -1678.92
Epoch 8.85: Loss = 701.274
Epoch 8.86: Loss = -344.664
Epoch 8.87: Loss = 3233.2
Epoch 8.88: Loss = 2177.8
Epoch 8.89: Loss = 947.708
Epoch 8.90: Loss = -2296.15
Epoch 8.91: Loss = -1469.23
Epoch 8.92: Loss = -531.912
Epoch 8.93: Loss = -693.339
Epoch 8.94: Loss = -468.744
Epoch 8.95: Loss = -431.571
Epoch 8.96: Loss = 79.31
Epoch 8.97: Loss = -331.878
Epoch 8.98: Loss = 709.691
Epoch 8.99: Loss = 162.737
Epoch 8.100: Loss = -1125.13
Epoch 8.101: Loss = 836.612
Epoch 8.102: Loss = -2813.7
Epoch 8.103: Loss = 1455.37
Epoch 8.104: Loss = -1756.73
Epoch 8.105: Loss = -1261
Epoch 8.106: Loss = -2073.39
Epoch 8.107: Loss = -642.065
Epoch 8.108: Loss = -1235.49
Epoch 8.109: Loss = 1570.54
Epoch 8.110: Loss = -550.253
Epoch 8.111: Loss = -535.042
Epoch 8.112: Loss = 941.318
Epoch 8.113: Loss = -2510.88
Epoch 8.114: Loss = -892.901
Epoch 8.115: Loss = 345.224
Epoch 8.116: Loss = 725.297
Epoch 8.117: Loss = -204.168
Epoch 8.118: Loss = -1486.72
Epoch 8.119: Loss = 984.115
Epoch 8.120: Loss = -132.126
TRAIN LOSS = -125.435
TRAIN ACC = 10.0861 % (6052/60000)
Loss = 1029.32
Loss = 650.094
Loss = -559.397
Loss = 545.992
Loss = -1563.18
Loss = 1156.51
Loss = 603.486
Loss = -594.354
Loss = -399.316
Loss = -2170.29
Loss = -2114.93
Loss = -1655.84
Loss = -2965.27
Loss = -840.378
Loss = 1146.71
Loss = -428.012
Loss = 1849.34
Loss = -1751.22
Loss = 1927.88
Loss = -497.388
TEST LOSS = -3.83267
TEST ACC = 60.5194 % (1018/10000)
Reducing learning rate to 0.100006
Epoch 9.1: Loss = 1297.12
Epoch 9.2: Loss = 1071.35
Epoch 9.3: Loss = -201.749
Epoch 9.4: Loss = 2350.2
Epoch 9.5: Loss = -1927.6
Epoch 9.6: Loss = -2247.9
Epoch 9.7: Loss = 689.79
Epoch 9.8: Loss = -51.9854
Epoch 9.9: Loss = 322.119
Epoch 9.10: Loss = -708.477
Epoch 9.11: Loss = 1711.69
Epoch 9.12: Loss = -51.7661
Epoch 9.13: Loss = 565.804
Epoch 9.14: Loss = 1226.07
Epoch 9.15: Loss = -2389.04
Epoch 9.16: Loss = -50.8694
Epoch 9.17: Loss = -1782.1
Epoch 9.18: Loss = 1391.53
Epoch 9.19: Loss = 1306.09
Epoch 9.20: Loss = -947.284
Epoch 9.21: Loss = 867.401
Epoch 9.22: Loss = -258.714
Epoch 9.23: Loss = -162.499
Epoch 9.24: Loss = 129.357
Epoch 9.25: Loss = -166.693
Epoch 9.26: Loss = -1206.42
Epoch 9.27: Loss = -1943.55
Epoch 9.28: Loss = 733.198
Epoch 9.29: Loss = -688.966
Epoch 9.30: Loss = 205.193
Epoch 9.31: Loss = -1077.59
Epoch 9.32: Loss = -1320.8
Epoch 9.33: Loss = 79.767
Epoch 9.34: Loss = 1190.04
Epoch 9.35: Loss = -118.348
Epoch 9.36: Loss = -184.825
Epoch 9.37: Loss = 1468.31
Epoch 9.38: Loss = -1731.81
Epoch 9.39: Loss = -1097.99
Epoch 9.40: Loss = -644.908
Epoch 9.41: Loss = -1650.38
Epoch 9.42: Loss = -483.77
Epoch 9.43: Loss = 2387.01
Epoch 9.44: Loss = 2.25317
Epoch 9.45: Loss = -459.193
Epoch 9.46: Loss = 585.142
Epoch 9.47: Loss = -459.635
Epoch 9.48: Loss = 59.027
Epoch 9.49: Loss = 508.204
Epoch 9.50: Loss = -1321.62
Epoch 9.51: Loss = 346.368
Epoch 9.52: Loss = -644.584
Epoch 9.53: Loss = -973.403
Epoch 9.54: Loss = 2471.94
Epoch 9.55: Loss = -1352.51
Epoch 9.56: Loss = 1594.68
Epoch 9.57: Loss = 590.123
Epoch 9.58: Loss = 2631.81
Epoch 9.59: Loss = 2213.74
Epoch 9.60: Loss = -944.522
Epoch 9.61: Loss = 1052.26
Epoch 9.62: Loss = -484.57
Epoch 9.63: Loss = -1353.4
Epoch 9.64: Loss = -1805.26
Epoch 9.65: Loss = 1151.3
Epoch 9.66: Loss = 323.849
Epoch 9.67: Loss = -142.005
Epoch 9.68: Loss = -103.465
Epoch 9.69: Loss = 1764.27
Epoch 9.70: Loss = -108.658
Epoch 9.71: Loss = -487.274
Epoch 9.72: Loss = 508.705
Epoch 9.73: Loss = -737.718
Epoch 9.74: Loss = -4088.66
Epoch 9.75: Loss = 644.133
Epoch 9.76: Loss = -115.181
Epoch 9.77: Loss = -43.4184
Epoch 9.78: Loss = 357.178
Epoch 9.79: Loss = -1355.1
Epoch 9.80: Loss = 1866.1
Epoch 9.81: Loss = -443.626
Epoch 9.82: Loss = 1031.89
Epoch 9.83: Loss = 1225.37
Epoch 9.84: Loss = 808.725
Epoch 9.85: Loss = 277.801
Epoch 9.86: Loss = 1964.82
Epoch 9.87: Loss = -1151.64
Epoch 9.88: Loss = -959.513
Epoch 9.89: Loss = 233.52
Epoch 9.90: Loss = 444.398
Epoch 9.91: Loss = -572.381
Epoch 9.92: Loss = -161.129
Epoch 9.93: Loss = 862.696
Epoch 9.94: Loss = 2893.34
Epoch 9.95: Loss = 756.216
Epoch 9.96: Loss = 2007.98
Epoch 9.97: Loss = 483.28
Epoch 9.98: Loss = -1136.43
Epoch 9.99: Loss = 2.79555
Epoch 9.100: Loss = -146.125
Epoch 9.101: Loss = 839.276
Epoch 9.102: Loss = 1303.64
Epoch 9.103: Loss = 2052.96
Epoch 9.104: Loss = -2271.93
Epoch 9.105: Loss = -945.157
Epoch 9.106: Loss = 2288.82
Epoch 9.107: Loss = -1882.58
Epoch 9.108: Loss = -459.258
Epoch 9.109: Loss = 78.7556
Epoch 9.110: Loss = 660.481
Epoch 9.111: Loss = 231.411
Epoch 9.112: Loss = -614.849
Epoch 9.113: Loss = 1051.33
Epoch 9.114: Loss = 7.65967
Epoch 9.115: Loss = 457.605
Epoch 9.116: Loss = -528.997
Epoch 9.117: Loss = 691.794
Epoch 9.118: Loss = -2228.97
Epoch 9.119: Loss = 428.531
Epoch 9.120: Loss = -803.66
TRAIN LOSS = 53.0491
TRAIN ACC = 9.74731 % (5849/60000)
Loss = -1152.31
Loss = -1574.29
Loss = 1692.79
Loss = -197.622
Loss = 650.059
Loss = -1771.17
Loss = 1352.63
Loss = 1994.69
Loss = 412.902
Loss = 18.1687
Loss = 290.928
Loss = -1354.7
Loss = 1075.2
Loss = 1938.41
Loss = -1501.23
Loss = -775.563
Loss = 655.593
Loss = 651.713
Loss = 1787.89
Loss = -673.509
TEST LOSS = 0.918885
TEST ACC = 58.49 % (979/10000)
Reducing learning rate to 0.100006
Epoch 10.1: Loss = 1452.56
Epoch 10.2: Loss = 1694.98
Epoch 10.3: Loss = 1325.83
Epoch 10.4: Loss = 247.32
Epoch 10.5: Loss = 1389.71
Epoch 10.6: Loss = 361.839
Epoch 10.7: Loss = 2463.4
Epoch 10.8: Loss = -894.71
Epoch 10.9: Loss = -1181.85
Epoch 10.10: Loss = 38.9954
Epoch 10.11: Loss = -232.188
Epoch 10.12: Loss = -531.231
Epoch 10.13: Loss = -545.616
Epoch 10.14: Loss = -1714.39
Epoch 10.15: Loss = -2565.25
Epoch 10.16: Loss = -351.436
Epoch 10.17: Loss = -301.2
Epoch 10.18: Loss = -1366.81
Epoch 10.19: Loss = 556.484
Epoch 10.20: Loss = 95.0385
Epoch 10.21: Loss = -677.712
Epoch 10.22: Loss = -2293.07
Epoch 10.23: Loss = -2644.98
Epoch 10.24: Loss = -999.248
Epoch 10.25: Loss = -575.375
Epoch 10.26: Loss = -958.722
Epoch 10.27: Loss = 1002
Epoch 10.28: Loss = 1577.09
Epoch 10.29: Loss = -1319.21
Epoch 10.30: Loss = -891.699
Epoch 10.31: Loss = -1400.42
Epoch 10.32: Loss = -580.109
Epoch 10.33: Loss = -1701.25
Epoch 10.34: Loss = -820.604
Epoch 10.35: Loss = -358.201
Epoch 10.36: Loss = 107.771
Epoch 10.37: Loss = 392.12
Epoch 10.38: Loss = 1338.59
Epoch 10.39: Loss = -379.072
Epoch 10.40: Loss = -1624.04
Epoch 10.41: Loss = -45.1007
Epoch 10.42: Loss = -610.906
Epoch 10.43: Loss = 669.54
Epoch 10.44: Loss = -210.07
Epoch 10.45: Loss = -843.5
Epoch 10.46: Loss = 200.81
Epoch 10.47: Loss = -39.1729
Epoch 10.48: Loss = -72.7157
Epoch 10.49: Loss = 2100.74
Epoch 10.50: Loss = -231.22
Epoch 10.51: Loss = -1546.91
Epoch 10.52: Loss = 1096.57
Epoch 10.53: Loss = 227.028
Epoch 10.54: Loss = 1381.18
Epoch 10.55: Loss = -1180.88
Epoch 10.56: Loss = -1159.17
Epoch 10.57: Loss = -202.577
Epoch 10.58: Loss = 896.374
Epoch 10.59: Loss = -290.418
Epoch 10.60: Loss = -615.253
Epoch 10.61: Loss = -709.533
Epoch 10.62: Loss = -1356.48
Epoch 10.63: Loss = -1420.86
Epoch 10.64: Loss = 785.54
Epoch 10.65: Loss = -542.129
Epoch 10.66: Loss = -92.0199
Epoch 10.67: Loss = -743.45
Epoch 10.68: Loss = 1357.92
Epoch 10.69: Loss = 1559.51
Epoch 10.70: Loss = 1226.97
Epoch 10.71: Loss = -1923.99
Epoch 10.72: Loss = -1546.9
Epoch 10.73: Loss = 1192.97
Epoch 10.74: Loss = 257.418
Epoch 10.75: Loss = -599.172
Epoch 10.76: Loss = 920.799
Epoch 10.77: Loss = 879.381
Epoch 10.78: Loss = -1957.56
Epoch 10.79: Loss = 94.2321
Epoch 10.80: Loss = 2311.95
Epoch 10.81: Loss = 1698.98
Epoch 10.82: Loss = 949.54
Epoch 10.83: Loss = -300.96
Epoch 10.84: Loss = 2237.59
Epoch 10.85: Loss = -946.379
Epoch 10.86: Loss = 618.117
Epoch 10.87: Loss = -747.984
Epoch 10.88: Loss = 1277.58
Epoch 10.89: Loss = 754.183
Epoch 10.90: Loss = 219.218
Epoch 10.91: Loss = -119.983
Epoch 10.92: Loss = -2715.49
Epoch 10.93: Loss = -987.985
Epoch 10.94: Loss = 530.727
Epoch 10.95: Loss = -56.7551
Epoch 10.96: Loss = -1680.97
Epoch 10.97: Loss = -1604.66
Epoch 10.98: Loss = 502.993
Epoch 10.99: Loss = 2073.14
Epoch 10.100: Loss = -2016.57
Epoch 10.101: Loss = 2730.04
Epoch 10.102: Loss = 367.752
Epoch 10.103: Loss = -1300.8
Epoch 10.104: Loss = -1590.05
Epoch 10.105: Loss = -190.468
Epoch 10.106: Loss = -659.548
Epoch 10.107: Loss = 120.604
Epoch 10.108: Loss = 1746.67
Epoch 10.109: Loss = 135.553
Epoch 10.110: Loss = 101.09
Epoch 10.111: Loss = 1979.47
Epoch 10.112: Loss = -1332.92
Epoch 10.113: Loss = -778.26
Epoch 10.114: Loss = -364.675
Epoch 10.115: Loss = 1639.89
Epoch 10.116: Loss = 345.558
Epoch 10.117: Loss = 72.0798
Epoch 10.118: Loss = 99.9883
Epoch 10.119: Loss = 1229.71
Epoch 10.120: Loss = 887.041
TRAIN LOSS = -72.6901
TRAIN ACC = 10.0143 % (6008/60000)
Loss = 557.426
Loss = 1473.75
Loss = 784.122
Loss = 476.749
Loss = -1219.02
Loss = -1296.07
Loss = -78.4948
Loss = -653.241
Loss = 514.053
Loss = 1329.54
Loss = -497.263
Loss = 1576.4
Loss = 1937.73
Loss = 1739.89
Loss = -1181.35
Loss = 1939.05
Loss = 1460.26
Loss = 27.1068
Loss = 866.078
Loss = 780.209
TEST LOSS = 2.55856
TEST ACC = 60.08 % (992/10000)
