Setting up connection 0
***********************************************************
Training MNIST
Model: Dense([60000, 1, 500]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 500
Num Epochs: 10
Learning Rate: 0.1 to 0.1 over 10 epochs
Clipping Factor: 4
Sigma: 1
***********************************************************
Epoch 1.1: Loss = 2.41943
Epoch 1.2: Loss = 2.26027
Epoch 1.3: Loss = 2.21181
Epoch 1.4: Loss = 2.11299
Epoch 1.5: Loss = 2.02951
Epoch 1.6: Loss = 1.98549
Epoch 1.7: Loss = 1.90874
Epoch 1.8: Loss = 1.84288
Epoch 1.9: Loss = 1.81776
Epoch 1.10: Loss = 1.78349
Epoch 1.11: Loss = 1.68636
Epoch 1.12: Loss = 1.65633
Epoch 1.13: Loss = 1.66083
Epoch 1.14: Loss = 1.54192
Epoch 1.15: Loss = 1.54489
Epoch 1.16: Loss = 1.51117
Epoch 1.17: Loss = 1.54604
Epoch 1.18: Loss = 1.47823
Epoch 1.19: Loss = 1.4843
Epoch 1.20: Loss = 1.47519
Epoch 1.21: Loss = 1.42157
Epoch 1.22: Loss = 1.34193
Epoch 1.23: Loss = 1.33083
Epoch 1.24: Loss = 1.33989
Epoch 1.25: Loss = 1.30193
Epoch 1.26: Loss = 1.26791
Epoch 1.27: Loss = 1.23561
Epoch 1.28: Loss = 1.20651
Epoch 1.29: Loss = 1.16739
Epoch 1.30: Loss = 1.19797
Epoch 1.31: Loss = 1.23357
Epoch 1.32: Loss = 1.12895
Epoch 1.33: Loss = 1.15625
Epoch 1.34: Loss = 1.19073
Epoch 1.35: Loss = 1.13583
Epoch 1.36: Loss = 1.10263
Epoch 1.37: Loss = 1.17673
Epoch 1.38: Loss = 1.04016
Epoch 1.39: Loss = 1.10406
Epoch 1.40: Loss = 0.975128
Epoch 1.41: Loss = 1.11308
Epoch 1.42: Loss = 1.03516
Epoch 1.43: Loss = 0.961304
Epoch 1.44: Loss = 1.0629
Epoch 1.45: Loss = 0.998123
Epoch 1.46: Loss = 0.98172
Epoch 1.47: Loss = 0.940353
Epoch 1.48: Loss = 1.03889
Epoch 1.49: Loss = 0.951157
Epoch 1.50: Loss = 0.969376
Epoch 1.51: Loss = 1.06993
Epoch 1.52: Loss = 0.923309
Epoch 1.53: Loss = 0.956955
Epoch 1.54: Loss = 0.956467
Epoch 1.55: Loss = 0.957458
Epoch 1.56: Loss = 0.937363
Epoch 1.57: Loss = 0.94986
Epoch 1.58: Loss = 0.932831
Epoch 1.59: Loss = 0.869308
Epoch 1.60: Loss = 0.884109
Epoch 1.61: Loss = 0.872452
Epoch 1.62: Loss = 0.870728
Epoch 1.63: Loss = 0.859055
Epoch 1.64: Loss = 0.890045
Epoch 1.65: Loss = 0.850586
Epoch 1.66: Loss = 0.839325
Epoch 1.67: Loss = 0.853607
Epoch 1.68: Loss = 0.895294
Epoch 1.69: Loss = 0.946243
Epoch 1.70: Loss = 0.875992
Epoch 1.71: Loss = 0.786636
Epoch 1.72: Loss = 0.899536
Epoch 1.73: Loss = 0.749603
Epoch 1.74: Loss = 0.918716
Epoch 1.75: Loss = 0.827332
Epoch 1.76: Loss = 0.895523
Epoch 1.77: Loss = 0.930756
Epoch 1.78: Loss = 0.901337
Epoch 1.79: Loss = 0.834839
Epoch 1.80: Loss = 0.933731
Epoch 1.81: Loss = 0.828445
Epoch 1.82: Loss = 0.817429
Epoch 1.83: Loss = 0.836182
Epoch 1.84: Loss = 0.848358
Epoch 1.85: Loss = 0.843246
Epoch 1.86: Loss = 0.82756
Epoch 1.87: Loss = 0.781372
Epoch 1.88: Loss = 0.87973
Epoch 1.89: Loss = 0.806641
Epoch 1.90: Loss = 0.820618
Epoch 1.91: Loss = 0.702423
Epoch 1.92: Loss = 0.811752
Epoch 1.93: Loss = 0.765594
Epoch 1.94: Loss = 0.866196
Epoch 1.95: Loss = 0.725769
Epoch 1.96: Loss = 0.822144
Epoch 1.97: Loss = 0.748901
Epoch 1.98: Loss = 0.826294
Epoch 1.99: Loss = 0.838364
Epoch 1.100: Loss = 0.746338
Epoch 1.101: Loss = 0.837143
Epoch 1.102: Loss = 0.833405
Epoch 1.103: Loss = 0.807571
Epoch 1.104: Loss = 0.740906
Epoch 1.105: Loss = 0.811798
Epoch 1.106: Loss = 0.834457
Epoch 1.107: Loss = 0.836899
Epoch 1.108: Loss = 0.789795
Epoch 1.109: Loss = 0.750778
Epoch 1.110: Loss = 0.802185
Epoch 1.111: Loss = 0.803482
Epoch 1.112: Loss = 0.759613
Epoch 1.113: Loss = 0.720551
Epoch 1.114: Loss = 0.717438
Epoch 1.115: Loss = 0.743423
Epoch 1.116: Loss = 0.799011
Epoch 1.117: Loss = 0.793991
Epoch 1.118: Loss = 0.729843
Epoch 1.119: Loss = 0.704041
Epoch 1.120: Loss = 0.746841
TRAIN LOSS = 1.07202
TRAIN ACC = 63.1287 % (37879/60000)
Loss = 0.716599
Loss = 0.838654
Loss = 0.809723
Loss = 0.709915
Loss = 0.696716
Loss = 0.861084
Loss = 0.909073
Loss = 0.839355
Loss = 0.795166
Loss = 0.723511
Loss = 0.84079
Loss = 0.815491
Loss = 0.810623
Loss = 0.804871
Loss = 0.743622
Loss = 0.83609
Loss = 0.73027
Loss = 0.784668
Loss = 0.849091
Loss = 0.772629
TEST LOSS = 0.794397
TEST ACC = 378.789 % (7295/10000)
Reducing learning rate to 0.100006
Epoch 2.1: Loss = 0.788956
Epoch 2.2: Loss = 0.748962
Epoch 2.3: Loss = 0.700073
Epoch 2.4: Loss = 0.735031
Epoch 2.5: Loss = 0.831085
Epoch 2.6: Loss = 0.728806
Epoch 2.7: Loss = 0.729996
Epoch 2.8: Loss = 0.73436
Epoch 2.9: Loss = 0.74733
Epoch 2.10: Loss = 0.786972
Epoch 2.11: Loss = 0.720276
Epoch 2.12: Loss = 0.75351
Epoch 2.13: Loss = 0.756287
Epoch 2.14: Loss = 0.75824
Epoch 2.15: Loss = 0.703552
Epoch 2.16: Loss = 0.768524
Epoch 2.17: Loss = 0.662201
Epoch 2.18: Loss = 0.701813
Epoch 2.19: Loss = 0.841446
Epoch 2.20: Loss = 0.741104
Epoch 2.21: Loss = 0.787949
Epoch 2.22: Loss = 0.74205
Epoch 2.23: Loss = 0.657013
Epoch 2.24: Loss = 0.79129
Epoch 2.25: Loss = 0.734253
Epoch 2.26: Loss = 0.837097
Epoch 2.27: Loss = 0.691101
Epoch 2.28: Loss = 0.70314
Epoch 2.29: Loss = 0.754913
Epoch 2.30: Loss = 0.746872
Epoch 2.31: Loss = 0.778214
Epoch 2.32: Loss = 0.740723
Epoch 2.33: Loss = 0.77359
Epoch 2.34: Loss = 0.782394
Epoch 2.35: Loss = 0.784912
Epoch 2.36: Loss = 0.634842
Epoch 2.37: Loss = 0.732269
Epoch 2.38: Loss = 0.773621
Epoch 2.39: Loss = 0.67424
Epoch 2.40: Loss = 0.732864
Epoch 2.41: Loss = 0.644287
Epoch 2.42: Loss = 0.668579
Epoch 2.43: Loss = 0.824921
Epoch 2.44: Loss = 0.731461
Epoch 2.45: Loss = 0.659729
Epoch 2.46: Loss = 0.749573
Epoch 2.47: Loss = 0.765717
Epoch 2.48: Loss = 0.754364
Epoch 2.49: Loss = 0.707748
Epoch 2.50: Loss = 0.660019
Epoch 2.51: Loss = 0.684067
Epoch 2.52: Loss = 0.717102
Epoch 2.53: Loss = 0.805374
Epoch 2.54: Loss = 0.799042
Epoch 2.55: Loss = 0.753296
Epoch 2.56: Loss = 0.809525
Epoch 2.57: Loss = 0.702759
Epoch 2.58: Loss = 0.654251
Epoch 2.59: Loss = 0.78479
Epoch 2.60: Loss = 0.840851
Epoch 2.61: Loss = 0.681519
Epoch 2.62: Loss = 0.714066
Epoch 2.63: Loss = 0.698212
Epoch 2.64: Loss = 0.76001
Epoch 2.65: Loss = 0.680588
Epoch 2.66: Loss = 0.648056
Epoch 2.67: Loss = 0.819183
Epoch 2.68: Loss = 0.730911
Epoch 2.69: Loss = 0.754303
Epoch 2.70: Loss = 0.707413
Epoch 2.71: Loss = 0.71965
Epoch 2.72: Loss = 0.788193
Epoch 2.73: Loss = 0.702026
Epoch 2.74: Loss = 0.717041
Epoch 2.75: Loss = 0.731476
Epoch 2.76: Loss = 0.639847
Epoch 2.77: Loss = 0.758621
Epoch 2.78: Loss = 0.715515
Epoch 2.79: Loss = 0.694153
Epoch 2.80: Loss = 0.677444
Epoch 2.81: Loss = 0.769608
Epoch 2.82: Loss = 0.753784
Epoch 2.83: Loss = 0.763809
Epoch 2.84: Loss = 0.758514
Epoch 2.85: Loss = 0.677994
Epoch 2.86: Loss = 0.766769
Epoch 2.87: Loss = 0.692734
Epoch 2.88: Loss = 0.683975
Epoch 2.89: Loss = 0.680405
Epoch 2.90: Loss = 0.816345
Epoch 2.91: Loss = 0.613892
Epoch 2.92: Loss = 0.731567
Epoch 2.93: Loss = 0.689819
Epoch 2.94: Loss = 0.770538
Epoch 2.95: Loss = 0.657776
Epoch 2.96: Loss = 0.684418
Epoch 2.97: Loss = 0.733536
Epoch 2.98: Loss = 0.713486
Epoch 2.99: Loss = 0.685699
Epoch 2.100: Loss = 0.732758
Epoch 2.101: Loss = 0.708374
Epoch 2.102: Loss = 0.927414
Epoch 2.103: Loss = 0.676102
Epoch 2.104: Loss = 0.727036
Epoch 2.105: Loss = 0.777939
Epoch 2.106: Loss = 0.76326
Epoch 2.107: Loss = 0.745392
Epoch 2.108: Loss = 0.743652
Epoch 2.109: Loss = 0.669785
Epoch 2.110: Loss = 0.71347
Epoch 2.111: Loss = 0.747437
Epoch 2.112: Loss = 0.821182
Epoch 2.113: Loss = 0.760605
Epoch 2.114: Loss = 0.761841
Epoch 2.115: Loss = 0.693359
Epoch 2.116: Loss = 0.88707
Epoch 2.117: Loss = 0.718719
Epoch 2.118: Loss = 0.710907
Epoch 2.119: Loss = 0.671173
Epoch 2.120: Loss = 0.738937
TRAIN LOSS = 0.734924
TRAIN ACC = 75.5981 % (45361/60000)
Loss = 0.65184
Loss = 0.782059
Loss = 0.709778
Loss = 0.643433
Loss = 0.619949
Loss = 0.806931
Loss = 0.892365
Loss = 0.808243
Loss = 0.739929
Loss = 0.697617
Loss = 0.81662
Loss = 0.790863
Loss = 0.770691
Loss = 0.729034
Loss = 0.676468
Loss = 0.806198
Loss = 0.682388
Loss = 0.728256
Loss = 0.810242
Loss = 0.713837
TEST LOSS = 0.743837
TEST ACC = 453.609 % (7625/10000)
Reducing learning rate to 0.100006
Epoch 3.1: Loss = 0.732849
Epoch 3.2: Loss = 0.817947
Epoch 3.3: Loss = 0.84848
Epoch 3.4: Loss = 0.676544
Epoch 3.5: Loss = 0.726028
Epoch 3.6: Loss = 0.702911
Epoch 3.7: Loss = 0.740234
Epoch 3.8: Loss = 0.713409
Epoch 3.9: Loss = 0.650223
Epoch 3.10: Loss = 0.660553
Epoch 3.11: Loss = 0.767059
Epoch 3.12: Loss = 0.767609
Epoch 3.13: Loss = 0.824417
Epoch 3.14: Loss = 0.776535
Epoch 3.15: Loss = 0.710266
Epoch 3.16: Loss = 0.691833
Epoch 3.17: Loss = 0.733994
Epoch 3.18: Loss = 0.720428
Epoch 3.19: Loss = 0.727036
Epoch 3.20: Loss = 0.769409
Epoch 3.21: Loss = 0.789658
Epoch 3.22: Loss = 0.735428
Epoch 3.23: Loss = 0.695358
Epoch 3.24: Loss = 0.704712
Epoch 3.25: Loss = 0.753494
Epoch 3.26: Loss = 0.759552
Epoch 3.27: Loss = 0.708542
Epoch 3.28: Loss = 0.725845
Epoch 3.29: Loss = 0.764084
Epoch 3.30: Loss = 0.710388
Epoch 3.31: Loss = 0.705231
Epoch 3.32: Loss = 0.778351
Epoch 3.33: Loss = 0.793243
Epoch 3.34: Loss = 0.634232
Epoch 3.35: Loss = 0.69101
Epoch 3.36: Loss = 0.792511
Epoch 3.37: Loss = 0.644623
Epoch 3.38: Loss = 0.712921
Epoch 3.39: Loss = 0.660919
Epoch 3.40: Loss = 0.687881
Epoch 3.41: Loss = 0.693649
Epoch 3.42: Loss = 0.663605
Epoch 3.43: Loss = 0.728287
Epoch 3.44: Loss = 0.881042
Epoch 3.45: Loss = 0.701904
Epoch 3.46: Loss = 0.751877
Epoch 3.47: Loss = 0.826065
Epoch 3.48: Loss = 0.780029
Epoch 3.49: Loss = 0.703659
Epoch 3.50: Loss = 0.844971
Epoch 3.51: Loss = 0.745041
Epoch 3.52: Loss = 0.850174
Epoch 3.53: Loss = 0.718506
Epoch 3.54: Loss = 0.77475
Epoch 3.55: Loss = 0.662277
Epoch 3.56: Loss = 0.727829
Epoch 3.57: Loss = 0.736252
Epoch 3.58: Loss = 0.759476
Epoch 3.59: Loss = 0.745255
Epoch 3.60: Loss = 0.633118
Epoch 3.61: Loss = 0.690292
Epoch 3.62: Loss = 0.73616
Epoch 3.63: Loss = 0.628128
Epoch 3.64: Loss = 0.746613
Epoch 3.65: Loss = 0.724579
Epoch 3.66: Loss = 0.702988
Epoch 3.67: Loss = 0.789932
Epoch 3.68: Loss = 0.802673
Epoch 3.69: Loss = 0.746567
Epoch 3.70: Loss = 0.811829
Epoch 3.71: Loss = 0.622757
Epoch 3.72: Loss = 0.740219
Epoch 3.73: Loss = 0.801163
Epoch 3.74: Loss = 0.673294
Epoch 3.75: Loss = 0.816376
Epoch 3.76: Loss = 0.85405
Epoch 3.77: Loss = 0.761566
Epoch 3.78: Loss = 0.64415
Epoch 3.79: Loss = 0.751816
Epoch 3.80: Loss = 0.756256
Epoch 3.81: Loss = 0.820755
Epoch 3.82: Loss = 0.717255
Epoch 3.83: Loss = 0.71579
Epoch 3.84: Loss = 0.686295
Epoch 3.85: Loss = 0.736862
Epoch 3.86: Loss = 0.691101
Epoch 3.87: Loss = 0.83226
Epoch 3.88: Loss = 0.746109
Epoch 3.89: Loss = 0.813217
Epoch 3.90: Loss = 0.792953
Epoch 3.91: Loss = 0.692596
Epoch 3.92: Loss = 0.759354
Epoch 3.93: Loss = 0.690826
Epoch 3.94: Loss = 0.631897
Epoch 3.95: Loss = 0.799591
Epoch 3.96: Loss = 0.798325
Epoch 3.97: Loss = 0.724899
Epoch 3.98: Loss = 0.729889
Epoch 3.99: Loss = 0.717972
Epoch 3.100: Loss = 0.731308
Epoch 3.101: Loss = 0.728134
Epoch 3.102: Loss = 0.883606
Epoch 3.103: Loss = 0.701233
Epoch 3.104: Loss = 0.729736
Epoch 3.105: Loss = 0.732712
Epoch 3.106: Loss = 0.675583
Epoch 3.107: Loss = 0.834152
Epoch 3.108: Loss = 0.866028
Epoch 3.109: Loss = 0.770096
Epoch 3.110: Loss = 0.69017
Epoch 3.111: Loss = 0.906967
Epoch 3.112: Loss = 0.665237
Epoch 3.113: Loss = 0.734634
Epoch 3.114: Loss = 0.775803
Epoch 3.115: Loss = 0.705261
Epoch 3.116: Loss = 0.778732
Epoch 3.117: Loss = 0.676178
Epoch 3.118: Loss = 0.854843
Epoch 3.119: Loss = 0.756775
Epoch 3.120: Loss = 0.616318
TRAIN LOSS = 0.740402
TRAIN ACC = 77.475 % (46487/60000)
Loss = 0.668625
Loss = 0.79953
Loss = 0.692322
Loss = 0.68689
Loss = 0.646027
Loss = 0.834518
Loss = 0.970383
Loss = 0.878021
Loss = 0.78688
Loss = 0.764847
Loss = 0.883377
Loss = 0.868546
Loss = 0.803024
Loss = 0.78421
Loss = 0.724854
Loss = 0.827377
Loss = 0.7099
Loss = 0.734665
Loss = 0.86203
Loss = 0.756149
TEST LOSS = 0.784109
TEST ACC = 464.87 % (7650/10000)
Reducing learning rate to 0.100006
Epoch 4.1: Loss = 0.81665
Epoch 4.2: Loss = 0.699066
Epoch 4.3: Loss = 0.815887
Epoch 4.4: Loss = 0.794968
Epoch 4.5: Loss = 0.838943
Epoch 4.6: Loss = 0.772141
Epoch 4.7: Loss = 0.776443
Epoch 4.8: Loss = 0.759018
Epoch 4.9: Loss = 0.809265
Epoch 4.10: Loss = 0.756012
Epoch 4.11: Loss = 0.790924
Epoch 4.12: Loss = 0.801941
Epoch 4.13: Loss = 0.824142
Epoch 4.14: Loss = 0.752167
Epoch 4.15: Loss = 0.802139
Epoch 4.16: Loss = 0.565506
Epoch 4.17: Loss = 0.758041
Epoch 4.18: Loss = 0.754684
Epoch 4.19: Loss = 0.800674
Epoch 4.20: Loss = 0.735977
Epoch 4.21: Loss = 0.593628
Epoch 4.22: Loss = 0.765503
Epoch 4.23: Loss = 0.780197
Epoch 4.24: Loss = 0.766708
Epoch 4.25: Loss = 0.77916
Epoch 4.26: Loss = 0.854568
Epoch 4.27: Loss = 0.736313
Epoch 4.28: Loss = 0.841476
Epoch 4.29: Loss = 0.824387
Epoch 4.30: Loss = 0.682388
Epoch 4.31: Loss = 0.763214
Epoch 4.32: Loss = 0.692184
Epoch 4.33: Loss = 0.730896
Epoch 4.34: Loss = 0.72052
Epoch 4.35: Loss = 0.754349
Epoch 4.36: Loss = 0.682404
Epoch 4.37: Loss = 0.785614
Epoch 4.38: Loss = 0.640961
Epoch 4.39: Loss = 0.774704
Epoch 4.40: Loss = 0.719284
Epoch 4.41: Loss = 0.869598
Epoch 4.42: Loss = 0.843094
Epoch 4.43: Loss = 0.750305
Epoch 4.44: Loss = 0.774765
Epoch 4.45: Loss = 0.802155
Epoch 4.46: Loss = 0.851181
Epoch 4.47: Loss = 0.720108
Epoch 4.48: Loss = 0.80246
Epoch 4.49: Loss = 0.798965
Epoch 4.50: Loss = 0.780853
Epoch 4.51: Loss = 0.656418
Epoch 4.52: Loss = 0.868607
Epoch 4.53: Loss = 0.769882
Epoch 4.54: Loss = 0.688324
Epoch 4.55: Loss = 0.696472
Epoch 4.56: Loss = 0.644119
Epoch 4.57: Loss = 0.759598
Epoch 4.58: Loss = 0.744965
Epoch 4.59: Loss = 0.813477
Epoch 4.60: Loss = 0.76326
Epoch 4.61: Loss = 0.709854
Epoch 4.62: Loss = 0.642365
Epoch 4.63: Loss = 0.761398
Epoch 4.64: Loss = 0.737183
Epoch 4.65: Loss = 0.791
Epoch 4.66: Loss = 0.828171
Epoch 4.67: Loss = 0.768784
Epoch 4.68: Loss = 0.836411
Epoch 4.69: Loss = 0.707245
Epoch 4.70: Loss = 0.650818
Epoch 4.71: Loss = 0.770966
Epoch 4.72: Loss = 0.787415
Epoch 4.73: Loss = 0.622345
Epoch 4.74: Loss = 0.791412
Epoch 4.75: Loss = 0.671295
Epoch 4.76: Loss = 0.807648
Epoch 4.77: Loss = 0.768478
Epoch 4.78: Loss = 0.742004
Epoch 4.79: Loss = 0.809387
Epoch 4.80: Loss = 0.774002
Epoch 4.81: Loss = 0.700577
Epoch 4.82: Loss = 0.7724
Epoch 4.83: Loss = 0.763535
Epoch 4.84: Loss = 0.911697
Epoch 4.85: Loss = 0.800934
Epoch 4.86: Loss = 0.747849
Epoch 4.87: Loss = 0.880493
Epoch 4.88: Loss = 0.696075
Epoch 4.89: Loss = 0.629791
Epoch 4.90: Loss = 0.804855
Epoch 4.91: Loss = 0.819412
Epoch 4.92: Loss = 0.757523
Epoch 4.93: Loss = 0.718597
Epoch 4.94: Loss = 0.814743
Epoch 4.95: Loss = 0.718781
Epoch 4.96: Loss = 0.693298
Epoch 4.97: Loss = 0.677689
Epoch 4.98: Loss = 0.811783
Epoch 4.99: Loss = 0.83519
Epoch 4.100: Loss = 0.74556
Epoch 4.101: Loss = 0.635269
Epoch 4.102: Loss = 0.769958
Epoch 4.103: Loss = 0.739944
Epoch 4.104: Loss = 0.744888
Epoch 4.105: Loss = 0.739456
Epoch 4.106: Loss = 0.676117
Epoch 4.107: Loss = 0.758072
Epoch 4.108: Loss = 0.82515
Epoch 4.109: Loss = 0.633255
Epoch 4.110: Loss = 0.857178
Epoch 4.111: Loss = 0.793335
Epoch 4.112: Loss = 0.705154
Epoch 4.113: Loss = 0.753174
Epoch 4.114: Loss = 0.775696
Epoch 4.115: Loss = 0.81955
Epoch 4.116: Loss = 0.824661
Epoch 4.117: Loss = 0.818985
Epoch 4.118: Loss = 0.662964
Epoch 4.119: Loss = 0.892075
Epoch 4.120: Loss = 0.738388
TRAIN LOSS = 0.759628
TRAIN ACC = 78.2288 % (46939/60000)
Loss = 0.667007
Loss = 0.83403
Loss = 0.687103
Loss = 0.690979
Loss = 0.662094
Loss = 0.837051
Loss = 0.959595
Loss = 0.839493
Loss = 0.780228
Loss = 0.740356
Loss = 0.913391
Loss = 0.867386
Loss = 0.817505
Loss = 0.804703
Loss = 0.719955
Loss = 0.861877
Loss = 0.70253
Loss = 0.776276
Loss = 0.865585
Loss = 0.693741
TEST LOSS = 0.786044
TEST ACC = 469.389 % (7691/10000)
Reducing learning rate to 0.100006
Epoch 5.1: Loss = 0.758347
Epoch 5.2: Loss = 0.624649
Epoch 5.3: Loss = 0.720139
Epoch 5.4: Loss = 0.793427
Epoch 5.5: Loss = 0.762253
Epoch 5.6: Loss = 0.600266
Epoch 5.7: Loss = 0.759613
Epoch 5.8: Loss = 0.740112
Epoch 5.9: Loss = 0.753754
Epoch 5.10: Loss = 0.707764
Epoch 5.11: Loss = 0.895065
Epoch 5.12: Loss = 0.696426
Epoch 5.13: Loss = 0.757431
Epoch 5.14: Loss = 0.886993
Epoch 5.15: Loss = 0.855011
Epoch 5.16: Loss = 0.708359
Epoch 5.17: Loss = 0.739304
Epoch 5.18: Loss = 0.818268
Epoch 5.19: Loss = 0.806107
Epoch 5.20: Loss = 0.769913
Epoch 5.21: Loss = 0.712219
Epoch 5.22: Loss = 0.841019
Epoch 5.23: Loss = 0.671936
Epoch 5.24: Loss = 0.889572
Epoch 5.25: Loss = 0.784241
Epoch 5.26: Loss = 0.652588
Epoch 5.27: Loss = 0.921448
Epoch 5.28: Loss = 0.725067
Epoch 5.29: Loss = 0.818954
Epoch 5.30: Loss = 0.89386
Epoch 5.31: Loss = 0.825897
Epoch 5.32: Loss = 0.786194
Epoch 5.33: Loss = 0.836182
Epoch 5.34: Loss = 0.786469
Epoch 5.35: Loss = 0.719254
Epoch 5.36: Loss = 0.701096
Epoch 5.37: Loss = 0.760208
Epoch 5.38: Loss = 0.793304
Epoch 5.39: Loss = 0.611069
Epoch 5.40: Loss = 0.727783
Epoch 5.41: Loss = 0.813431
Epoch 5.42: Loss = 0.780197
Epoch 5.43: Loss = 0.876907
Epoch 5.44: Loss = 0.723373
Epoch 5.45: Loss = 0.873062
Epoch 5.46: Loss = 0.790009
Epoch 5.47: Loss = 0.696762
Epoch 5.48: Loss = 0.829865
Epoch 5.49: Loss = 0.791855
Epoch 5.50: Loss = 0.842499
Epoch 5.51: Loss = 0.746857
Epoch 5.52: Loss = 0.822906
Epoch 5.53: Loss = 0.670868
Epoch 5.54: Loss = 0.789444
Epoch 5.55: Loss = 0.871292
Epoch 5.56: Loss = 0.70816
Epoch 5.57: Loss = 0.72995
Epoch 5.58: Loss = 0.795273
Epoch 5.59: Loss = 0.800262
Epoch 5.60: Loss = 0.680038
Epoch 5.61: Loss = 0.884903
Epoch 5.62: Loss = 0.802444
Epoch 5.63: Loss = 0.806976
Epoch 5.64: Loss = 0.676025
Epoch 5.65: Loss = 0.949921
Epoch 5.66: Loss = 0.745773
Epoch 5.67: Loss = 0.753128
Epoch 5.68: Loss = 0.716049
Epoch 5.69: Loss = 0.927185
Epoch 5.70: Loss = 0.847565
Epoch 5.71: Loss = 0.713684
Epoch 5.72: Loss = 0.690018
Epoch 5.73: Loss = 0.682968
Epoch 5.74: Loss = 0.675812
Epoch 5.75: Loss = 0.84314
Epoch 5.76: Loss = 0.832809
Epoch 5.77: Loss = 0.832794
Epoch 5.78: Loss = 0.762634
Epoch 5.79: Loss = 0.916962
Epoch 5.80: Loss = 0.759048
Epoch 5.81: Loss = 0.921371
Epoch 5.82: Loss = 0.863632
Epoch 5.83: Loss = 0.625427
Epoch 5.84: Loss = 0.685577
Epoch 5.85: Loss = 0.851135
Epoch 5.86: Loss = 0.84494
Epoch 5.87: Loss = 0.779205
Epoch 5.88: Loss = 0.762665
Epoch 5.89: Loss = 0.809097
Epoch 5.90: Loss = 0.930496
Epoch 5.91: Loss = 0.767227
Epoch 5.92: Loss = 0.761887
Epoch 5.93: Loss = 0.881088
Epoch 5.94: Loss = 0.817169
Epoch 5.95: Loss = 0.773148
Epoch 5.96: Loss = 0.754608
Epoch 5.97: Loss = 0.794998
Epoch 5.98: Loss = 0.810715
Epoch 5.99: Loss = 0.815491
Epoch 5.100: Loss = 0.77681
Epoch 5.101: Loss = 0.740097
Epoch 5.102: Loss = 0.81694
Epoch 5.103: Loss = 0.733643
Epoch 5.104: Loss = 0.739258
Epoch 5.105: Loss = 0.689575
Epoch 5.106: Loss = 0.776443
Epoch 5.107: Loss = 0.780487
Epoch 5.108: Loss = 0.712097
Epoch 5.109: Loss = 0.836624
Epoch 5.110: Loss = 0.927017
Epoch 5.111: Loss = 0.781021
Epoch 5.112: Loss = 0.700516
Epoch 5.113: Loss = 0.930344
Epoch 5.114: Loss = 0.688385
Epoch 5.115: Loss = 0.778168
Epoch 5.116: Loss = 0.855011
Epoch 5.117: Loss = 0.650925
Epoch 5.118: Loss = 0.886108
Epoch 5.119: Loss = 0.872955
Epoch 5.120: Loss = 0.705154
TRAIN LOSS = 0.780777
TRAIN ACC = 78.2043 % (46925/60000)
Loss = 0.707764
Loss = 0.880295
Loss = 0.741913
Loss = 0.738312
Loss = 0.674057
Loss = 0.877533
Loss = 1.10651
Loss = 0.857727
Loss = 0.821777
Loss = 0.737244
Loss = 0.989731
Loss = 0.898743
Loss = 0.887039
Loss = 0.880096
Loss = 0.75061
Loss = 0.908646
Loss = 0.801666
Loss = 0.785355
Loss = 0.92424
Loss = 0.723389
TEST LOSS = 0.834632
TEST ACC = 469.249 % (7694/10000)
Reducing learning rate to 0.100006
Epoch 6.1: Loss = 0.803192
Epoch 6.2: Loss = 0.855835
Epoch 6.3: Loss = 0.701202
Epoch 6.4: Loss = 0.777039
Epoch 6.5: Loss = 0.759476
Epoch 6.6: Loss = 0.852905
Epoch 6.7: Loss = 0.616104
Epoch 6.8: Loss = 0.919006
Epoch 6.9: Loss = 0.693329
Epoch 6.10: Loss = 0.690262
Epoch 6.11: Loss = 0.712357
Epoch 6.12: Loss = 0.631805
Epoch 6.13: Loss = 0.944199
Epoch 6.14: Loss = 0.784882
Epoch 6.15: Loss = 0.840714
Epoch 6.16: Loss = 0.759125
Epoch 6.17: Loss = 0.803238
Epoch 6.18: Loss = 0.84285
Epoch 6.19: Loss = 0.774033
Epoch 6.20: Loss = 0.91954
Epoch 6.21: Loss = 0.781342
Epoch 6.22: Loss = 0.885284
Epoch 6.23: Loss = 0.767349
Epoch 6.24: Loss = 0.849594
Epoch 6.25: Loss = 0.712097
Epoch 6.26: Loss = 0.893295
Epoch 6.27: Loss = 0.787476
Epoch 6.28: Loss = 0.860733
Epoch 6.29: Loss = 0.776703
Epoch 6.30: Loss = 0.857162
Epoch 6.31: Loss = 0.880127
Epoch 6.32: Loss = 0.864395
Epoch 6.33: Loss = 0.970993
Epoch 6.34: Loss = 0.814789
Epoch 6.35: Loss = 0.745529
Epoch 6.36: Loss = 0.721344
Epoch 6.37: Loss = 0.900742
Epoch 6.38: Loss = 0.849854
Epoch 6.39: Loss = 0.674118
Epoch 6.40: Loss = 0.792465
Epoch 6.41: Loss = 0.747681
Epoch 6.42: Loss = 0.84758
Epoch 6.43: Loss = 0.772354
Epoch 6.44: Loss = 0.691391
Epoch 6.45: Loss = 0.868546
Epoch 6.46: Loss = 0.922668
Epoch 6.47: Loss = 0.767151
Epoch 6.48: Loss = 0.981796
Epoch 6.49: Loss = 0.819733
Epoch 6.50: Loss = 0.927933
Epoch 6.51: Loss = 0.769211
Epoch 6.52: Loss = 0.574005
Epoch 6.53: Loss = 0.771027
Epoch 6.54: Loss = 0.801804
Epoch 6.55: Loss = 0.809189
Epoch 6.56: Loss = 0.723663
Epoch 6.57: Loss = 0.764389
Epoch 6.58: Loss = 0.781219
Epoch 6.59: Loss = 0.639252
Epoch 6.60: Loss = 0.820038
Epoch 6.61: Loss = 0.686356
Epoch 6.62: Loss = 0.98671
Epoch 6.63: Loss = 0.795425
Epoch 6.64: Loss = 0.796585
Epoch 6.65: Loss = 0.826035
Epoch 6.66: Loss = 0.806885
Epoch 6.67: Loss = 0.789703
Epoch 6.68: Loss = 0.709381
Epoch 6.69: Loss = 0.824371
Epoch 6.70: Loss = 0.752884
Epoch 6.71: Loss = 0.80513
Epoch 6.72: Loss = 0.709457
Epoch 6.73: Loss = 0.757782
Epoch 6.74: Loss = 0.815155
Epoch 6.75: Loss = 0.667526
Epoch 6.76: Loss = 0.974243
Epoch 6.77: Loss = 0.805176
Epoch 6.78: Loss = 0.781036
Epoch 6.79: Loss = 0.928085
Epoch 6.80: Loss = 0.7733
Epoch 6.81: Loss = 0.823471
Epoch 6.82: Loss = 0.697922
Epoch 6.83: Loss = 0.786392
Epoch 6.84: Loss = 0.85553
Epoch 6.85: Loss = 0.801361
Epoch 6.86: Loss = 0.964066
Epoch 6.87: Loss = 0.728699
Epoch 6.88: Loss = 0.917709
Epoch 6.89: Loss = 0.815155
Epoch 6.90: Loss = 0.863541
Epoch 6.91: Loss = 0.840103
Epoch 6.92: Loss = 0.846481
Epoch 6.93: Loss = 0.940033
Epoch 6.94: Loss = 0.958389
Epoch 6.95: Loss = 0.873306
Epoch 6.96: Loss = 0.967529
Epoch 6.97: Loss = 0.828323
Epoch 6.98: Loss = 0.852921
Epoch 6.99: Loss = 0.850571
Epoch 6.100: Loss = 0.825806
Epoch 6.101: Loss = 0.894577
Epoch 6.102: Loss = 0.832855
Epoch 6.103: Loss = 0.786453
Epoch 6.104: Loss = 0.835541
Epoch 6.105: Loss = 0.83284
Epoch 6.106: Loss = 0.791565
Epoch 6.107: Loss = 0.829971
Epoch 6.108: Loss = 0.760162
Epoch 6.109: Loss = 0.835678
Epoch 6.110: Loss = 0.886795
Epoch 6.111: Loss = 0.918915
Epoch 6.112: Loss = 0.884537
Epoch 6.113: Loss = 0.776596
Epoch 6.114: Loss = 0.817978
Epoch 6.115: Loss = 0.778854
Epoch 6.116: Loss = 0.739151
Epoch 6.117: Loss = 0.800262
Epoch 6.118: Loss = 0.711472
Epoch 6.119: Loss = 0.839493
Epoch 6.120: Loss = 0.837753
TRAIN LOSS = 0.810745
TRAIN ACC = 78.2394 % (46945/60000)
Loss = 0.794861
Loss = 0.977859
Loss = 0.797379
Loss = 0.806915
Loss = 0.791641
Loss = 0.99472
Loss = 1.16158
Loss = 0.953522
Loss = 0.89415
Loss = 0.803467
Loss = 1.08942
Loss = 0.993423
Loss = 1.05156
Loss = 0.95282
Loss = 0.813797
Loss = 0.999435
Loss = 0.838318
Loss = 0.882874
Loss = 1.03758
Loss = 0.775253
TEST LOSS = 0.920528
TEST ACC = 469.449 % (7721/10000)
Reducing learning rate to 0.100006
Epoch 7.1: Loss = 0.897003
Epoch 7.2: Loss = 0.731613
Epoch 7.3: Loss = 0.898331
Epoch 7.4: Loss = 0.787781
Epoch 7.5: Loss = 0.934235
Epoch 7.6: Loss = 0.757584
Epoch 7.7: Loss = 0.999115
Epoch 7.8: Loss = 0.785355
Epoch 7.9: Loss = 0.99556
Epoch 7.10: Loss = 0.882278
Epoch 7.11: Loss = 0.699371
Epoch 7.12: Loss = 0.769806
Epoch 7.13: Loss = 0.845535
Epoch 7.14: Loss = 0.863205
Epoch 7.15: Loss = 0.772186
Epoch 7.16: Loss = 0.979324
Epoch 7.17: Loss = 0.774002
Epoch 7.18: Loss = 0.922729
Epoch 7.19: Loss = 0.885437
Epoch 7.20: Loss = 0.850739
Epoch 7.21: Loss = 0.824524
Epoch 7.22: Loss = 0.862
Epoch 7.23: Loss = 0.789124
Epoch 7.24: Loss = 0.891953
Epoch 7.25: Loss = 1.15776
Epoch 7.26: Loss = 0.887924
Epoch 7.27: Loss = 0.822189
Epoch 7.28: Loss = 0.935974
Epoch 7.29: Loss = 0.93602
Epoch 7.30: Loss = 0.813095
Epoch 7.31: Loss = 0.784912
Epoch 7.32: Loss = 0.826599
Epoch 7.33: Loss = 0.960068
Epoch 7.34: Loss = 0.74733
Epoch 7.35: Loss = 0.968109
Epoch 7.36: Loss = 0.819305
Epoch 7.37: Loss = 0.833282
Epoch 7.38: Loss = 0.771362
Epoch 7.39: Loss = 0.894821
Epoch 7.40: Loss = 0.766495
Epoch 7.41: Loss = 0.957077
Epoch 7.42: Loss = 0.943726
Epoch 7.43: Loss = 0.7173
Epoch 7.44: Loss = 0.796158
Epoch 7.45: Loss = 0.692215
Epoch 7.46: Loss = 0.782883
Epoch 7.47: Loss = 0.748169
Epoch 7.48: Loss = 0.840271
Epoch 7.49: Loss = 0.995041
Epoch 7.50: Loss = 0.69545
Epoch 7.51: Loss = 0.811722
Epoch 7.52: Loss = 0.994064
Epoch 7.53: Loss = 0.849396
Epoch 7.54: Loss = 0.918381
Epoch 7.55: Loss = 0.832855
Epoch 7.56: Loss = 0.740997
Epoch 7.57: Loss = 0.884567
Epoch 7.58: Loss = 0.909302
Epoch 7.59: Loss = 1.00591
Epoch 7.60: Loss = 0.824509
Epoch 7.61: Loss = 1.04074
Epoch 7.62: Loss = 0.773834
Epoch 7.63: Loss = 0.841904
Epoch 7.64: Loss = 0.763168
Epoch 7.65: Loss = 0.908737
Epoch 7.66: Loss = 0.77243
Epoch 7.67: Loss = 0.834671
Epoch 7.68: Loss = 0.895294
Epoch 7.69: Loss = 0.979355
Epoch 7.70: Loss = 0.846222
Epoch 7.71: Loss = 0.846725
Epoch 7.72: Loss = 0.881683
Epoch 7.73: Loss = 0.809464
Epoch 7.74: Loss = 0.952911
Epoch 7.75: Loss = 1.06911
Epoch 7.76: Loss = 0.910797
Epoch 7.77: Loss = 0.917953
Epoch 7.78: Loss = 0.820267
Epoch 7.79: Loss = 0.862503
Epoch 7.80: Loss = 0.941544
Epoch 7.81: Loss = 0.781418
Epoch 7.82: Loss = 0.879913
Epoch 7.83: Loss = 0.755905
Epoch 7.84: Loss = 0.961258
Epoch 7.85: Loss = 0.939087
Epoch 7.86: Loss = 0.842773
Epoch 7.87: Loss = 0.944794
Epoch 7.88: Loss = 0.943024
Epoch 7.89: Loss = 0.875687
Epoch 7.90: Loss = 0.899582
Epoch 7.91: Loss = 1.00096
Epoch 7.92: Loss = 0.902939
Epoch 7.93: Loss = 0.858734
Epoch 7.94: Loss = 0.843613
Epoch 7.95: Loss = 0.904129
Epoch 7.96: Loss = 0.781647
Epoch 7.97: Loss = 0.748077
Epoch 7.98: Loss = 0.916626
Epoch 7.99: Loss = 0.897873
Epoch 7.100: Loss = 0.776154
Epoch 7.101: Loss = 0.91188
Epoch 7.102: Loss = 0.940857
Epoch 7.103: Loss = 1.04042
Epoch 7.104: Loss = 1.09262
Epoch 7.105: Loss = 0.852203
Epoch 7.106: Loss = 0.838852
Epoch 7.107: Loss = 0.807587
Epoch 7.108: Loss = 0.827408
Epoch 7.109: Loss = 1.101
Epoch 7.110: Loss = 0.825714
Epoch 7.111: Loss = 0.868835
Epoch 7.112: Loss = 0.894745
Epoch 7.113: Loss = 0.838882
Epoch 7.114: Loss = 0.795288
Epoch 7.115: Loss = 0.843948
Epoch 7.116: Loss = 1.03717
Epoch 7.117: Loss = 0.841385
Epoch 7.118: Loss = 0.978241
Epoch 7.119: Loss = 1.03697
Epoch 7.120: Loss = 0.877762
TRAIN LOSS = 0.872009
TRAIN ACC = 77.916 % (46752/60000)
Loss = 0.880676
Loss = 1.01096
Loss = 0.876068
Loss = 0.826324
Loss = 0.871506
Loss = 0.993866
Loss = 1.25267
Loss = 1.04274
Loss = 0.985016
Loss = 0.886444
Loss = 1.16214
Loss = 0.98262
Loss = 1.10637
Loss = 0.994843
Loss = 0.891937
Loss = 1.02762
Loss = 0.878143
Loss = 0.927826
Loss = 1.00922
Loss = 0.87941
TEST LOSS = 0.974319
TEST ACC = 467.519 % (7662/10000)
Reducing learning rate to 0.100006
Epoch 8.1: Loss = 0.835861
Epoch 8.2: Loss = 0.838654
Epoch 8.3: Loss = 0.891708
Epoch 8.4: Loss = 0.851791
Epoch 8.5: Loss = 0.915878
Epoch 8.6: Loss = 1.01103
Epoch 8.7: Loss = 0.878723
Epoch 8.8: Loss = 0.731415
Epoch 8.9: Loss = 0.791748
Epoch 8.10: Loss = 1.00888
Epoch 8.11: Loss = 0.971252
Epoch 8.12: Loss = 0.92186
Epoch 8.13: Loss = 0.88443
Epoch 8.14: Loss = 1.11653
Epoch 8.15: Loss = 0.840439
Epoch 8.16: Loss = 0.835709
Epoch 8.17: Loss = 0.913361
Epoch 8.18: Loss = 0.967941
Epoch 8.19: Loss = 0.699387
Epoch 8.20: Loss = 0.839081
Epoch 8.21: Loss = 0.991455
Epoch 8.22: Loss = 1.00862
Epoch 8.23: Loss = 1.00958
Epoch 8.24: Loss = 0.819244
Epoch 8.25: Loss = 0.934845
Epoch 8.26: Loss = 1.0407
Epoch 8.27: Loss = 1.20793
Epoch 8.28: Loss = 1.02223
Epoch 8.29: Loss = 0.907028
Epoch 8.30: Loss = 0.801514
Epoch 8.31: Loss = 0.894699
Epoch 8.32: Loss = 0.920624
Epoch 8.33: Loss = 0.832657
Epoch 8.34: Loss = 0.989838
Epoch 8.35: Loss = 0.827438
Epoch 8.36: Loss = 0.992004
Epoch 8.37: Loss = 0.949249
Epoch 8.38: Loss = 0.969086
Epoch 8.39: Loss = 0.823074
Epoch 8.40: Loss = 0.970139
Epoch 8.41: Loss = 0.985397
Epoch 8.42: Loss = 0.90239
Epoch 8.43: Loss = 1.17738
Epoch 8.44: Loss = 0.88562
Epoch 8.45: Loss = 1.09917
Epoch 8.46: Loss = 0.922577
Epoch 8.47: Loss = 0.966446
Epoch 8.48: Loss = 1.09032
Epoch 8.49: Loss = 0.988373
Epoch 8.50: Loss = 0.947556
Epoch 8.51: Loss = 0.894852
Epoch 8.52: Loss = 0.865875
Epoch 8.53: Loss = 0.860474
Epoch 8.54: Loss = 0.913452
Epoch 8.55: Loss = 0.897552
Epoch 8.56: Loss = 0.961914
Epoch 8.57: Loss = 0.914536
Epoch 8.58: Loss = 0.76297
Epoch 8.59: Loss = 0.950653
Epoch 8.60: Loss = 0.97345
Epoch 8.61: Loss = 0.787628
Epoch 8.62: Loss = 1.0202
Epoch 8.63: Loss = 1.0116
Epoch 8.64: Loss = 0.943115
Epoch 8.65: Loss = 0.808395
Epoch 8.66: Loss = 0.885406
Epoch 8.67: Loss = 1.00397
Epoch 8.68: Loss = 0.793381
Epoch 8.69: Loss = 1.09564
Epoch 8.70: Loss = 0.792389
Epoch 8.71: Loss = 0.962463
Epoch 8.72: Loss = 0.803406
Epoch 8.73: Loss = 0.598892
Epoch 8.74: Loss = 0.980042
Epoch 8.75: Loss = 0.883102
Epoch 8.76: Loss = 1.08171
Epoch 8.77: Loss = 0.779449
Epoch 8.78: Loss = 0.909348
Epoch 8.79: Loss = 0.99408
Epoch 8.80: Loss = 0.961868
Epoch 8.81: Loss = 1.00339
Epoch 8.82: Loss = 0.678345
Epoch 8.83: Loss = 0.9814
Epoch 8.84: Loss = 0.83815
Epoch 8.85: Loss = 1.03453
Epoch 8.86: Loss = 0.836639
Epoch 8.87: Loss = 0.920364
Epoch 8.88: Loss = 0.896667
Epoch 8.89: Loss = 1.05592
Epoch 8.90: Loss = 0.996475
Epoch 8.91: Loss = 0.747894
Epoch 8.92: Loss = 0.835571
Epoch 8.93: Loss = 0.881973
Epoch 8.94: Loss = 0.950058
Epoch 8.95: Loss = 0.876984
Epoch 8.96: Loss = 0.978622
Epoch 8.97: Loss = 1.07205
Epoch 8.98: Loss = 0.853226
Epoch 8.99: Loss = 0.927872
Epoch 8.100: Loss = 0.894394
Epoch 8.101: Loss = 1.05287
Epoch 8.102: Loss = 0.921356
Epoch 8.103: Loss = 1.03972
Epoch 8.104: Loss = 1.11143
Epoch 8.105: Loss = 0.909653
Epoch 8.106: Loss = 0.755859
Epoch 8.107: Loss = 0.897751
Epoch 8.108: Loss = 1.01227
Epoch 8.109: Loss = 0.860184
Epoch 8.110: Loss = 0.913544
Epoch 8.111: Loss = 1.00066
Epoch 8.112: Loss = 1.00383
Epoch 8.113: Loss = 1.05093
Epoch 8.114: Loss = 0.943451
Epoch 8.115: Loss = 1.00172
Epoch 8.116: Loss = 0.852554
Epoch 8.117: Loss = 0.96431
Epoch 8.118: Loss = 0.907181
Epoch 8.119: Loss = 1.06123
Epoch 8.120: Loss = 1.10583
TRAIN LOSS = 0.927856
TRAIN ACC = 77.6443 % (46589/60000)
Loss = 0.894623
Loss = 1.02817
Loss = 0.847839
Loss = 0.802521
Loss = 0.834824
Loss = 1.14868
Loss = 1.30667
Loss = 1.08585
Loss = 1.07025
Loss = 0.986176
Loss = 1.17574
Loss = 1.07771
Loss = 1.09773
Loss = 1.04581
Loss = 0.964706
Loss = 1.06982
Loss = 0.970322
Loss = 1.01245
Loss = 1.12666
Loss = 0.861267
TEST LOSS = 1.02039
TEST ACC = 465.889 % (7671/10000)
Reducing learning rate to 0.100006
Epoch 9.1: Loss = 0.807144
Epoch 9.2: Loss = 0.9776
Epoch 9.3: Loss = 1.04895
Epoch 9.4: Loss = 1.06232
Epoch 9.5: Loss = 0.869537
Epoch 9.6: Loss = 0.776764
Epoch 9.7: Loss = 0.961853
Epoch 9.8: Loss = 0.939178
Epoch 9.9: Loss = 0.85704
Epoch 9.10: Loss = 0.815094
Epoch 9.11: Loss = 0.980057
Epoch 9.12: Loss = 0.859161
Epoch 9.13: Loss = 1.02054
Epoch 9.14: Loss = 0.836502
Epoch 9.15: Loss = 1.00052
Epoch 9.16: Loss = 1.15454
Epoch 9.17: Loss = 0.853134
Epoch 9.18: Loss = 1.07216
Epoch 9.19: Loss = 0.683838
Epoch 9.20: Loss = 0.874054
Epoch 9.21: Loss = 0.745773
Epoch 9.22: Loss = 0.922974
Epoch 9.23: Loss = 0.85173
Epoch 9.24: Loss = 0.851944
Epoch 9.25: Loss = 0.897415
Epoch 9.26: Loss = 1.08505
Epoch 9.27: Loss = 0.946808
Epoch 9.28: Loss = 1.0031
Epoch 9.29: Loss = 1.08713
Epoch 9.30: Loss = 0.877823
Epoch 9.31: Loss = 0.919846
Epoch 9.32: Loss = 0.975388
Epoch 9.33: Loss = 0.854843
Epoch 9.34: Loss = 1.06851
Epoch 9.35: Loss = 1.11922
Epoch 9.36: Loss = 0.904099
Epoch 9.37: Loss = 0.917938
Epoch 9.38: Loss = 1.1293
Epoch 9.39: Loss = 0.923859
Epoch 9.40: Loss = 1.1554
Epoch 9.41: Loss = 1.07994
Epoch 9.42: Loss = 0.852997
Epoch 9.43: Loss = 0.94194
Epoch 9.44: Loss = 1.13747
Epoch 9.45: Loss = 0.873932
Epoch 9.46: Loss = 0.914993
Epoch 9.47: Loss = 0.857788
Epoch 9.48: Loss = 0.775375
Epoch 9.49: Loss = 0.968628
Epoch 9.50: Loss = 1.07907
Epoch 9.51: Loss = 0.964233
Epoch 9.52: Loss = 1.05429
Epoch 9.53: Loss = 0.945313
Epoch 9.54: Loss = 1.03343
Epoch 9.55: Loss = 0.888748
Epoch 9.56: Loss = 1.07628
Epoch 9.57: Loss = 1.00911
Epoch 9.58: Loss = 1.0072
Epoch 9.59: Loss = 1.06046
Epoch 9.60: Loss = 1.04552
Epoch 9.61: Loss = 0.86554
Epoch 9.62: Loss = 0.953308
Epoch 9.63: Loss = 1.03159
Epoch 9.64: Loss = 1.13545
Epoch 9.65: Loss = 0.96933
Epoch 9.66: Loss = 0.956833
Epoch 9.67: Loss = 0.986252
Epoch 9.68: Loss = 0.830994
Epoch 9.69: Loss = 0.88504
Epoch 9.70: Loss = 1.0885
Epoch 9.71: Loss = 1.10605
Epoch 9.72: Loss = 1.1066
Epoch 9.73: Loss = 1.17404
Epoch 9.74: Loss = 0.75589
Epoch 9.75: Loss = 1.14279
Epoch 9.76: Loss = 0.992386
Epoch 9.77: Loss = 0.958176
Epoch 9.78: Loss = 1.10258
Epoch 9.79: Loss = 1.03955
Epoch 9.80: Loss = 1.15039
Epoch 9.81: Loss = 0.922745
Epoch 9.82: Loss = 0.977036
Epoch 9.83: Loss = 0.920029
Epoch 9.84: Loss = 1.08006
Epoch 9.85: Loss = 1.04259
Epoch 9.86: Loss = 0.979477
Epoch 9.87: Loss = 1.08499
Epoch 9.88: Loss = 1.04039
Epoch 9.89: Loss = 1.05878
Epoch 9.90: Loss = 0.989655
Epoch 9.91: Loss = 0.921371
Epoch 9.92: Loss = 0.954742
Epoch 9.93: Loss = 0.880112
Epoch 9.94: Loss = 1.10327
Epoch 9.95: Loss = 1.05154
Epoch 9.96: Loss = 1.01996
Epoch 9.97: Loss = 0.912323
Epoch 9.98: Loss = 1.23065
Epoch 9.99: Loss = 1.00333
Epoch 9.100: Loss = 0.994843
Epoch 9.101: Loss = 0.954544
Epoch 9.102: Loss = 0.894608
Epoch 9.103: Loss = 1.05655
Epoch 9.104: Loss = 0.9328
Epoch 9.105: Loss = 1.09947
Epoch 9.106: Loss = 1.08987
Epoch 9.107: Loss = 1.05748
Epoch 9.108: Loss = 1.1104
Epoch 9.109: Loss = 1.30649
Epoch 9.110: Loss = 0.883179
Epoch 9.111: Loss = 1.00385
Epoch 9.112: Loss = 0.954727
Epoch 9.113: Loss = 1.01993
Epoch 9.114: Loss = 0.876663
Epoch 9.115: Loss = 0.816971
Epoch 9.116: Loss = 1.21819
Epoch 9.117: Loss = 0.970459
Epoch 9.118: Loss = 1.01543
Epoch 9.119: Loss = 1.12143
Epoch 9.120: Loss = 0.942993
TRAIN LOSS = 0.983185
TRAIN ACC = 77.8488 % (46711/60000)
Loss = 0.980392
Loss = 1.09775
Loss = 0.896347
Loss = 0.876846
Loss = 0.884995
Loss = 1.18584
Loss = 1.37822
Loss = 1.21886
Loss = 1.12531
Loss = 1.0984
Loss = 1.26636
Loss = 1.13237
Loss = 1.19766
Loss = 1.06754
Loss = 1.02676
Loss = 1.15756
Loss = 0.956665
Loss = 1.121
Loss = 1.15466
Loss = 0.921753
TEST LOSS = 1.08726
TEST ACC = 467.11 % (7597/10000)
Reducing learning rate to 0.100006
Epoch 10.1: Loss = 1.03203
Epoch 10.2: Loss = 1.01469
Epoch 10.3: Loss = 0.979919
Epoch 10.4: Loss = 1.03465
Epoch 10.5: Loss = 1.11658
Epoch 10.6: Loss = 1.25989
Epoch 10.7: Loss = 0.901886
Epoch 10.8: Loss = 1.01071
Epoch 10.9: Loss = 0.861145
Epoch 10.10: Loss = 0.875351
Epoch 10.11: Loss = 0.963058
Epoch 10.12: Loss = 1.1805
Epoch 10.13: Loss = 0.915298
Epoch 10.14: Loss = 1.02921
Epoch 10.15: Loss = 1.03416
Epoch 10.16: Loss = 1.29453
Epoch 10.17: Loss = 1.09222
Epoch 10.18: Loss = 1.07642
Epoch 10.19: Loss = 1.10255
Epoch 10.20: Loss = 1.0493
Epoch 10.21: Loss = 1.20613
Epoch 10.22: Loss = 1.02885
Epoch 10.23: Loss = 0.828461
Epoch 10.24: Loss = 1.25348
Epoch 10.25: Loss = 0.987259
Epoch 10.26: Loss = 1.12245
Epoch 10.27: Loss = 1.12469
Epoch 10.28: Loss = 1.1826
Epoch 10.29: Loss = 1.11644
Epoch 10.30: Loss = 0.829483
Epoch 10.31: Loss = 1.16313
Epoch 10.32: Loss = 1.22758
Epoch 10.33: Loss = 1.0555
Epoch 10.34: Loss = 0.899719
Epoch 10.35: Loss = 0.971069
Epoch 10.36: Loss = 0.849289
Epoch 10.37: Loss = 0.879486
Epoch 10.38: Loss = 0.917267
Epoch 10.39: Loss = 1.0063
Epoch 10.40: Loss = 0.922333
Epoch 10.41: Loss = 1.01141
Epoch 10.42: Loss = 0.996109
Epoch 10.43: Loss = 1.11253
Epoch 10.44: Loss = 0.901077
Epoch 10.45: Loss = 1.10902
Epoch 10.46: Loss = 1.02867
Epoch 10.47: Loss = 1.14636
Epoch 10.48: Loss = 1.12199
Epoch 10.49: Loss = 1.01585
Epoch 10.50: Loss = 1.23775
Epoch 10.51: Loss = 0.931534
Epoch 10.52: Loss = 1.11424
Epoch 10.53: Loss = 0.913742
Epoch 10.54: Loss = 1.20628
Epoch 10.55: Loss = 1.07767
Epoch 10.56: Loss = 0.931396
Epoch 10.57: Loss = 0.96019
Epoch 10.58: Loss = 0.947861
Epoch 10.59: Loss = 1.1931
Epoch 10.60: Loss = 1.01996
Epoch 10.61: Loss = 1.03868
Epoch 10.62: Loss = 0.992874
Epoch 10.63: Loss = 1.19662
Epoch 10.64: Loss = 0.804474
Epoch 10.65: Loss = 1.26352
Epoch 10.66: Loss = 1.17993
Epoch 10.67: Loss = 1.06888
Epoch 10.68: Loss = 0.952255
Epoch 10.69: Loss = 1.04651
Epoch 10.70: Loss = 0.971222
Epoch 10.71: Loss = 1.0407
Epoch 10.72: Loss = 1.07802
Epoch 10.73: Loss = 1.10426
Epoch 10.74: Loss = 1.12262
Epoch 10.75: Loss = 1.10498
Epoch 10.76: Loss = 1.01685
Epoch 10.77: Loss = 1.11032
Epoch 10.78: Loss = 0.97673
Epoch 10.79: Loss = 0.908386
Epoch 10.80: Loss = 1.14297
Epoch 10.81: Loss = 1.02412
Epoch 10.82: Loss = 1.26488
Epoch 10.83: Loss = 0.990417
Epoch 10.84: Loss = 0.972366
Epoch 10.85: Loss = 1.15279
Epoch 10.86: Loss = 1.13582
Epoch 10.87: Loss = 0.735733
Epoch 10.88: Loss = 1.44243
Epoch 10.89: Loss = 0.993744
Epoch 10.90: Loss = 1.05551
Epoch 10.91: Loss = 1.12784
Epoch 10.92: Loss = 1.03423
Epoch 10.93: Loss = 1.14265
Epoch 10.94: Loss = 1.04758
Epoch 10.95: Loss = 1.10373
Epoch 10.96: Loss = 1.25276
Epoch 10.97: Loss = 1.0248
Epoch 10.98: Loss = 0.951385
Epoch 10.99: Loss = 1.03375
Epoch 10.100: Loss = 1.18315
Epoch 10.101: Loss = 0.963821
Epoch 10.102: Loss = 1.00729
Epoch 10.103: Loss = 0.983704
Epoch 10.104: Loss = 1.19887
Epoch 10.105: Loss = 0.967392
Epoch 10.106: Loss = 1.09985
Epoch 10.107: Loss = 1.07156
Epoch 10.108: Loss = 0.993896
Epoch 10.109: Loss = 0.901672
Epoch 10.110: Loss = 0.899796
Epoch 10.111: Loss = 1.17697
Epoch 10.112: Loss = 1.0462
Epoch 10.113: Loss = 1.04483
Epoch 10.114: Loss = 0.941406
Epoch 10.115: Loss = 0.852005
Epoch 10.116: Loss = 1.07635
Epoch 10.117: Loss = 1.02187
Epoch 10.118: Loss = 0.995102
Epoch 10.119: Loss = 0.991776
Epoch 10.120: Loss = 1.09462
TRAIN LOSS = 1.04579
TRAIN ACC = 77.4307 % (46460/60000)
Loss = 0.984161
Loss = 1.14174
Loss = 0.945236
Loss = 0.974823
Loss = 1.0928
Loss = 1.17842
Loss = 1.36903
Loss = 1.28925
Loss = 1.16162
Loss = 1.13358
Loss = 1.32057
Loss = 1.24719
Loss = 1.18967
Loss = 1.16023
Loss = 1.09631
Loss = 1.23323
Loss = 0.96254
Loss = 1.15305
Loss = 1.32715
Loss = 1.01633
TEST LOSS = 1.14885
TEST ACC = 464.6 % (7595/10000)
