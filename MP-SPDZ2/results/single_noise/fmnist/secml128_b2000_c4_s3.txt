Setting up connection 0
***********************************************************
Training FMNIST
Model: Dense([60000, 1, 128]) => Dense([60000, 1, 128]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 3
***********************************************************
Epoch 1.1: Loss = 2.30569
Epoch 1.2: Loss = 2.09518
Epoch 1.3: Loss = 1.9388
Epoch 1.4: Loss = 1.804
Epoch 1.5: Loss = 1.65941
Epoch 1.6: Loss = 1.51601
Epoch 1.7: Loss = 1.39813
Epoch 1.8: Loss = 1.32695
Epoch 1.9: Loss = 1.23727
Epoch 1.10: Loss = 1.17149
Epoch 1.11: Loss = 1.14386
Epoch 1.12: Loss = 1.05144
Epoch 1.13: Loss = 1.06044
Epoch 1.14: Loss = 1.00926
Epoch 1.15: Loss = 0.999588
Epoch 1.16: Loss = 0.993301
Epoch 1.17: Loss = 1.0267
Epoch 1.18: Loss = 1.01559
Epoch 1.19: Loss = 0.999756
Epoch 1.20: Loss = 0.930252
Epoch 1.21: Loss = 1.01527
Epoch 1.22: Loss = 0.993439
Epoch 1.23: Loss = 0.960419
Epoch 1.24: Loss = 0.891602
Epoch 1.25: Loss = 0.881836
Epoch 1.26: Loss = 0.800552
Epoch 1.27: Loss = 0.871521
Epoch 1.28: Loss = 0.857498
Epoch 1.29: Loss = 0.882614
Epoch 1.30: Loss = 0.790482
TRAIN LOSS = 1.18762
TRAIN ACC = 59.2514 % (35553/60000)
Loss = 0.824387
Loss = 0.881348
Loss = 0.835388
Loss = 0.842026
Loss = 0.847214
TEST LOSS = 0.846072
TEST ACC = 355.53 % (7060/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.864975
Epoch 2.2: Loss = 0.763565
Epoch 2.3: Loss = 0.758484
Epoch 2.4: Loss = 0.788147
Epoch 2.5: Loss = 0.790039
Epoch 2.6: Loss = 0.784683
Epoch 2.7: Loss = 0.807648
Epoch 2.8: Loss = 0.818695
Epoch 2.9: Loss = 0.740753
Epoch 2.10: Loss = 0.774323
Epoch 2.11: Loss = 0.725876
Epoch 2.12: Loss = 0.734436
Epoch 2.13: Loss = 0.796722
Epoch 2.14: Loss = 0.725403
Epoch 2.15: Loss = 0.717651
Epoch 2.16: Loss = 0.708374
Epoch 2.17: Loss = 0.628876
Epoch 2.18: Loss = 0.693085
Epoch 2.19: Loss = 0.791946
Epoch 2.20: Loss = 0.747314
Epoch 2.21: Loss = 0.743546
Epoch 2.22: Loss = 0.730118
Epoch 2.23: Loss = 0.747131
Epoch 2.24: Loss = 0.769501
Epoch 2.25: Loss = 0.732071
Epoch 2.26: Loss = 0.706467
Epoch 2.27: Loss = 0.744141
Epoch 2.28: Loss = 0.703018
Epoch 2.29: Loss = 0.70372
Epoch 2.30: Loss = 0.675369
TRAIN LOSS = 0.747223
TRAIN ACC = 73.7793 % (44269/60000)
Loss = 0.766266
Loss = 0.861404
Loss = 0.811584
Loss = 0.796021
Loss = 0.809219
TEST LOSS = 0.808899
TEST ACC = 442.69 % (7328/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.789612
Epoch 3.2: Loss = 0.822586
Epoch 3.3: Loss = 0.792084
Epoch 3.4: Loss = 0.807922
Epoch 3.5: Loss = 0.795624
Epoch 3.6: Loss = 0.780457
Epoch 3.7: Loss = 0.761017
Epoch 3.8: Loss = 0.800095
Epoch 3.9: Loss = 0.771835
Epoch 3.10: Loss = 0.775131
Epoch 3.11: Loss = 0.720245
Epoch 3.12: Loss = 0.687241
Epoch 3.13: Loss = 0.693985
Epoch 3.14: Loss = 0.745926
Epoch 3.15: Loss = 0.74559
Epoch 3.16: Loss = 0.776962
Epoch 3.17: Loss = 0.794006
Epoch 3.18: Loss = 0.817886
Epoch 3.19: Loss = 0.802582
Epoch 3.20: Loss = 0.73381
Epoch 3.21: Loss = 0.84082
Epoch 3.22: Loss = 0.768448
Epoch 3.23: Loss = 0.717651
Epoch 3.24: Loss = 0.726807
Epoch 3.25: Loss = 0.699936
Epoch 3.26: Loss = 0.74472
Epoch 3.27: Loss = 0.707413
Epoch 3.28: Loss = 0.681305
Epoch 3.29: Loss = 0.742065
Epoch 3.30: Loss = 0.700119
TRAIN LOSS = 0.758148
TRAIN ACC = 74.9191 % (44954/60000)
Loss = 0.719131
Loss = 0.809814
Loss = 0.778488
Loss = 0.74794
Loss = 0.756561
TEST LOSS = 0.762387
TEST ACC = 449.539 % (7505/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.744308
Epoch 4.2: Loss = 0.71553
Epoch 4.3: Loss = 0.784683
Epoch 4.4: Loss = 0.817108
Epoch 4.5: Loss = 0.710266
Epoch 4.6: Loss = 0.645172
Epoch 4.7: Loss = 0.687103
Epoch 4.8: Loss = 0.632294
Epoch 4.9: Loss = 0.64743
Epoch 4.10: Loss = 0.700211
Epoch 4.11: Loss = 0.725998
Epoch 4.12: Loss = 0.787033
Epoch 4.13: Loss = 0.733627
Epoch 4.14: Loss = 0.883881
Epoch 4.15: Loss = 0.801529
Epoch 4.16: Loss = 0.73024
Epoch 4.17: Loss = 0.742172
Epoch 4.18: Loss = 0.880142
Epoch 4.19: Loss = 0.83905
Epoch 4.20: Loss = 0.754608
Epoch 4.21: Loss = 0.640717
Epoch 4.22: Loss = 0.693787
Epoch 4.23: Loss = 0.597397
Epoch 4.24: Loss = 0.71701
Epoch 4.25: Loss = 0.716507
Epoch 4.26: Loss = 0.703796
Epoch 4.27: Loss = 0.74826
Epoch 4.28: Loss = 0.751373
Epoch 4.29: Loss = 0.755951
Epoch 4.30: Loss = 0.676575
TRAIN LOSS = 0.732147
TRAIN ACC = 76.8448 % (46109/60000)
Loss = 0.72789
Loss = 0.83519
Loss = 0.80658
Loss = 0.769836
Loss = 0.772354
TEST LOSS = 0.78237
TEST ACC = 461.089 % (7571/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.790497
Epoch 5.2: Loss = 0.673874
Epoch 5.3: Loss = 0.691544
Epoch 5.4: Loss = 0.689682
Epoch 5.5: Loss = 0.724121
Epoch 5.6: Loss = 0.730484
Epoch 5.7: Loss = 0.643219
Epoch 5.8: Loss = 0.704361
Epoch 5.9: Loss = 0.654785
Epoch 5.10: Loss = 0.648956
Epoch 5.11: Loss = 0.721573
Epoch 5.12: Loss = 0.672211
Epoch 5.13: Loss = 0.718445
Epoch 5.14: Loss = 0.714752
Epoch 5.15: Loss = 0.741867
Epoch 5.16: Loss = 0.757507
Epoch 5.17: Loss = 0.712357
Epoch 5.18: Loss = 0.7099
Epoch 5.19: Loss = 0.676559
Epoch 5.20: Loss = 0.707718
Epoch 5.21: Loss = 0.654724
Epoch 5.22: Loss = 0.619247
Epoch 5.23: Loss = 0.714096
Epoch 5.24: Loss = 0.603348
Epoch 5.25: Loss = 0.646774
Epoch 5.26: Loss = 0.693558
Epoch 5.27: Loss = 0.62944
Epoch 5.28: Loss = 0.695984
Epoch 5.29: Loss = 0.684631
Epoch 5.30: Loss = 0.572006
TRAIN LOSS = 0.68663
TRAIN ACC = 78.7338 % (47242/60000)
Loss = 0.637497
Loss = 0.7509
Loss = 0.733963
Loss = 0.693863
Loss = 0.701981
TEST LOSS = 0.703641
TEST ACC = 472.42 % (7894/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.604675
Epoch 6.2: Loss = 0.656372
Epoch 6.3: Loss = 0.628754
Epoch 6.4: Loss = 0.595856
Epoch 6.5: Loss = 0.64978
Epoch 6.6: Loss = 0.637177
Epoch 6.7: Loss = 0.710022
Epoch 6.8: Loss = 0.61676
Epoch 6.9: Loss = 0.71524
Epoch 6.10: Loss = 0.720505
Epoch 6.11: Loss = 0.730606
Epoch 6.12: Loss = 0.735962
Epoch 6.13: Loss = 0.663483
Epoch 6.14: Loss = 0.588852
Epoch 6.15: Loss = 0.688232
Epoch 6.16: Loss = 0.636017
Epoch 6.17: Loss = 0.60112
Epoch 6.18: Loss = 0.720581
Epoch 6.19: Loss = 0.633102
Epoch 6.20: Loss = 0.698425
Epoch 6.21: Loss = 0.779221
Epoch 6.22: Loss = 0.71521
Epoch 6.23: Loss = 0.730408
Epoch 6.24: Loss = 0.78862
Epoch 6.25: Loss = 0.675278
Epoch 6.26: Loss = 0.68898
Epoch 6.27: Loss = 0.753708
Epoch 6.28: Loss = 0.734222
Epoch 6.29: Loss = 0.743622
Epoch 6.30: Loss = 0.650497
TRAIN LOSS = 0.68306
TRAIN ACC = 79.425 % (47657/60000)
Loss = 0.651321
Loss = 0.768402
Loss = 0.757492
Loss = 0.705109
Loss = 0.715469
TEST LOSS = 0.719559
TEST ACC = 476.569 % (7914/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.700592
Epoch 7.2: Loss = 0.681992
Epoch 7.3: Loss = 0.669876
Epoch 7.4: Loss = 0.654327
Epoch 7.5: Loss = 0.839294
Epoch 7.6: Loss = 0.635757
Epoch 7.7: Loss = 0.634644
Epoch 7.8: Loss = 0.582184
Epoch 7.9: Loss = 0.670715
Epoch 7.10: Loss = 0.715073
Epoch 7.11: Loss = 0.6492
Epoch 7.12: Loss = 0.650772
Epoch 7.13: Loss = 0.693298
Epoch 7.14: Loss = 0.696686
Epoch 7.15: Loss = 0.733566
Epoch 7.16: Loss = 0.717804
Epoch 7.17: Loss = 0.691086
Epoch 7.18: Loss = 0.643509
Epoch 7.19: Loss = 0.720398
Epoch 7.20: Loss = 0.689926
Epoch 7.21: Loss = 0.690033
Epoch 7.22: Loss = 0.645691
Epoch 7.23: Loss = 0.640472
Epoch 7.24: Loss = 0.698059
Epoch 7.25: Loss = 0.651779
Epoch 7.26: Loss = 0.658813
Epoch 7.27: Loss = 0.694351
Epoch 7.28: Loss = 0.715836
Epoch 7.29: Loss = 0.679504
Epoch 7.30: Loss = 0.591614
TRAIN LOSS = 0.677917
TRAIN ACC = 79.9683 % (47983/60000)
Loss = 0.655426
Loss = 0.762283
Loss = 0.773575
Loss = 0.707703
Loss = 0.724075
TEST LOSS = 0.724612
TEST ACC = 479.829 % (7924/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.635513
Epoch 8.2: Loss = 0.728622
Epoch 8.3: Loss = 0.635162
Epoch 8.4: Loss = 0.718216
Epoch 8.5: Loss = 0.720581
Epoch 8.6: Loss = 0.75206
Epoch 8.7: Loss = 0.675644
Epoch 8.8: Loss = 0.725784
Epoch 8.9: Loss = 0.647415
Epoch 8.10: Loss = 0.629227
Epoch 8.11: Loss = 0.613953
Epoch 8.12: Loss = 0.704498
Epoch 8.13: Loss = 0.638611
Epoch 8.14: Loss = 0.690445
Epoch 8.15: Loss = 0.692657
Epoch 8.16: Loss = 0.657455
Epoch 8.17: Loss = 0.651733
Epoch 8.18: Loss = 0.655029
Epoch 8.19: Loss = 0.640228
Epoch 8.20: Loss = 0.585403
Epoch 8.21: Loss = 0.609375
Epoch 8.22: Loss = 0.556198
Epoch 8.23: Loss = 0.674652
Epoch 8.24: Loss = 0.656647
Epoch 8.25: Loss = 0.641296
Epoch 8.26: Loss = 0.623093
Epoch 8.27: Loss = 0.659744
Epoch 8.28: Loss = 0.659576
Epoch 8.29: Loss = 0.723343
Epoch 8.30: Loss = 0.674881
TRAIN LOSS = 0.662582
TRAIN ACC = 80.8548 % (48515/60000)
Loss = 0.646866
Loss = 0.75824
Loss = 0.765244
Loss = 0.692444
Loss = 0.710892
TEST LOSS = 0.714737
TEST ACC = 485.149 % (7958/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.729355
Epoch 9.2: Loss = 0.747192
Epoch 9.3: Loss = 0.674393
Epoch 9.4: Loss = 0.648254
Epoch 9.5: Loss = 0.722107
Epoch 9.6: Loss = 0.645355
Epoch 9.7: Loss = 0.63591
Epoch 9.8: Loss = 0.674164
Epoch 9.9: Loss = 0.752502
Epoch 9.10: Loss = 0.719879
Epoch 9.11: Loss = 0.60405
Epoch 9.12: Loss = 0.732407
Epoch 9.13: Loss = 0.716125
Epoch 9.14: Loss = 0.704941
Epoch 9.15: Loss = 0.68573
Epoch 9.16: Loss = 0.629028
Epoch 9.17: Loss = 0.662949
Epoch 9.18: Loss = 0.575958
Epoch 9.19: Loss = 0.664536
Epoch 9.20: Loss = 0.604599
Epoch 9.21: Loss = 0.708252
Epoch 9.22: Loss = 0.625702
Epoch 9.23: Loss = 0.684082
Epoch 9.24: Loss = 0.608612
Epoch 9.25: Loss = 0.66217
Epoch 9.26: Loss = 0.6371
Epoch 9.27: Loss = 0.671463
Epoch 9.28: Loss = 0.654404
Epoch 9.29: Loss = 0.651108
Epoch 9.30: Loss = 0.614258
TRAIN LOSS = 0.668243
TRAIN ACC = 80.9296 % (48560/60000)
Loss = 0.611816
Loss = 0.746826
Loss = 0.741135
Loss = 0.685928
Loss = 0.699783
TEST LOSS = 0.697098
TEST ACC = 485.599 % (8058/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.648422
Epoch 10.2: Loss = 0.574036
Epoch 10.3: Loss = 0.660553
Epoch 10.4: Loss = 0.626221
Epoch 10.5: Loss = 0.668365
Epoch 10.6: Loss = 0.683395
Epoch 10.7: Loss = 0.690414
Epoch 10.8: Loss = 0.681458
Epoch 10.9: Loss = 0.632599
Epoch 10.10: Loss = 0.681458
Epoch 10.11: Loss = 0.627258
Epoch 10.12: Loss = 0.580521
Epoch 10.13: Loss = 0.703598
Epoch 10.14: Loss = 0.596268
Epoch 10.15: Loss = 0.717712
Epoch 10.16: Loss = 0.597702
Epoch 10.17: Loss = 0.749039
Epoch 10.18: Loss = 0.648102
Epoch 10.19: Loss = 0.760971
Epoch 10.20: Loss = 0.636887
Epoch 10.21: Loss = 0.646408
Epoch 10.22: Loss = 0.585861
Epoch 10.23: Loss = 0.63559
Epoch 10.24: Loss = 0.666473
Epoch 10.25: Loss = 0.664169
Epoch 10.26: Loss = 0.709778
Epoch 10.27: Loss = 0.580185
Epoch 10.28: Loss = 0.681534
Epoch 10.29: Loss = 0.656281
Epoch 10.30: Loss = 0.71402
TRAIN LOSS = 0.65686
TRAIN ACC = 81.366 % (48822/60000)
Loss = 0.63353
Loss = 0.73465
Loss = 0.724564
Loss = 0.681976
Loss = 0.670609
TEST LOSS = 0.689065
TEST ACC = 488.219 % (7962/10000)
