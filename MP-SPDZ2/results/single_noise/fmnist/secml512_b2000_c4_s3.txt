Setting up connection 0
***********************************************************
Training FMNIST
Model: Dense([60000, 1, 512]) => Dense([60000, 1, 512]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 3
***********************************************************
Epoch 1.1: Loss = 2.36977
Epoch 1.2: Loss = 2.0466
Epoch 1.3: Loss = 1.83897
Epoch 1.4: Loss = 1.65862
Epoch 1.5: Loss = 1.49628
Epoch 1.6: Loss = 1.34195
Epoch 1.7: Loss = 1.28763
Epoch 1.8: Loss = 1.15373
Epoch 1.9: Loss = 1.09761
Epoch 1.10: Loss = 1.04915
Epoch 1.11: Loss = 1.01257
Epoch 1.12: Loss = 0.982849
Epoch 1.13: Loss = 0.941559
Epoch 1.14: Loss = 0.921524
Epoch 1.15: Loss = 0.923111
Epoch 1.16: Loss = 0.941406
Epoch 1.17: Loss = 0.935944
Epoch 1.18: Loss = 0.92807
Epoch 1.19: Loss = 0.932587
Epoch 1.20: Loss = 0.855423
Epoch 1.21: Loss = 0.889069
Epoch 1.22: Loss = 0.800156
Epoch 1.23: Loss = 0.859619
Epoch 1.24: Loss = 0.828217
Epoch 1.25: Loss = 0.840805
Epoch 1.26: Loss = 0.798096
Epoch 1.27: Loss = 0.744934
Epoch 1.28: Loss = 0.776428
Epoch 1.29: Loss = 0.732452
Epoch 1.30: Loss = 0.762924
TRAIN LOSS = 1.09161
TRAIN ACC = 63.9771 % (38388/60000)
Loss = 0.764191
Loss = 0.852783
Loss = 0.796509
Loss = 0.808853
Loss = 0.80278
TEST LOSS = 0.805023
TEST ACC = 383.879 % (7172/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.800934
Epoch 2.2: Loss = 0.732712
Epoch 2.3: Loss = 0.790863
Epoch 2.4: Loss = 0.6922
Epoch 2.5: Loss = 0.803909
Epoch 2.6: Loss = 0.730347
Epoch 2.7: Loss = 0.734314
Epoch 2.8: Loss = 0.759079
Epoch 2.9: Loss = 0.708481
Epoch 2.10: Loss = 0.803818
Epoch 2.11: Loss = 0.737152
Epoch 2.12: Loss = 0.832581
Epoch 2.13: Loss = 0.760437
Epoch 2.14: Loss = 0.727295
Epoch 2.15: Loss = 0.697372
Epoch 2.16: Loss = 0.822586
Epoch 2.17: Loss = 0.716064
Epoch 2.18: Loss = 0.769287
Epoch 2.19: Loss = 0.731476
Epoch 2.20: Loss = 0.856903
Epoch 2.21: Loss = 0.71666
Epoch 2.22: Loss = 0.848114
Epoch 2.23: Loss = 0.752548
Epoch 2.24: Loss = 0.734528
Epoch 2.25: Loss = 0.611145
Epoch 2.26: Loss = 0.747391
Epoch 2.27: Loss = 0.696732
Epoch 2.28: Loss = 0.757324
Epoch 2.29: Loss = 0.710449
Epoch 2.30: Loss = 0.73468
TRAIN LOSS = 0.750595
TRAIN ACC = 74.9359 % (44964/60000)
Loss = 0.655151
Loss = 0.731781
Loss = 0.703232
Loss = 0.687103
Loss = 0.676636
TEST LOSS = 0.69078
TEST ACC = 449.64 % (7578/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.683624
Epoch 3.2: Loss = 0.733551
Epoch 3.3: Loss = 0.685867
Epoch 3.4: Loss = 0.677155
Epoch 3.5: Loss = 0.690048
Epoch 3.6: Loss = 0.708191
Epoch 3.7: Loss = 0.765015
Epoch 3.8: Loss = 0.805862
Epoch 3.9: Loss = 0.702957
Epoch 3.10: Loss = 0.787323
Epoch 3.11: Loss = 0.826309
Epoch 3.12: Loss = 0.944748
Epoch 3.13: Loss = 0.796692
Epoch 3.14: Loss = 0.780975
Epoch 3.15: Loss = 0.649506
Epoch 3.16: Loss = 0.699966
Epoch 3.17: Loss = 0.746948
Epoch 3.18: Loss = 0.765015
Epoch 3.19: Loss = 0.767029
Epoch 3.20: Loss = 0.827927
Epoch 3.21: Loss = 0.763535
Epoch 3.22: Loss = 0.683411
Epoch 3.23: Loss = 0.718475
Epoch 3.24: Loss = 0.750366
Epoch 3.25: Loss = 0.665604
Epoch 3.26: Loss = 0.695679
Epoch 3.27: Loss = 0.729187
Epoch 3.28: Loss = 0.695435
Epoch 3.29: Loss = 0.634705
Epoch 3.30: Loss = 0.656052
TRAIN LOSS = 0.734589
TRAIN ACC = 76.5717 % (45945/60000)
Loss = 0.631454
Loss = 0.72464
Loss = 0.701233
Loss = 0.686661
Loss = 0.675934
TEST LOSS = 0.683984
TEST ACC = 459.45 % (7779/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.653763
Epoch 4.2: Loss = 0.637695
Epoch 4.3: Loss = 0.602158
Epoch 4.4: Loss = 0.677368
Epoch 4.5: Loss = 0.698532
Epoch 4.6: Loss = 0.72554
Epoch 4.7: Loss = 0.7379
Epoch 4.8: Loss = 0.804855
Epoch 4.9: Loss = 0.714813
Epoch 4.10: Loss = 0.776398
Epoch 4.11: Loss = 0.761795
Epoch 4.12: Loss = 0.745102
Epoch 4.13: Loss = 0.657867
Epoch 4.14: Loss = 0.767517
Epoch 4.15: Loss = 0.669342
Epoch 4.16: Loss = 0.789139
Epoch 4.17: Loss = 0.659134
Epoch 4.18: Loss = 0.791611
Epoch 4.19: Loss = 0.628403
Epoch 4.20: Loss = 0.802521
Epoch 4.21: Loss = 0.701675
Epoch 4.22: Loss = 0.877548
Epoch 4.23: Loss = 0.868973
Epoch 4.24: Loss = 0.751022
Epoch 4.25: Loss = 0.671906
Epoch 4.26: Loss = 0.805679
Epoch 4.27: Loss = 0.756165
Epoch 4.28: Loss = 0.798828
Epoch 4.29: Loss = 0.741379
Epoch 4.30: Loss = 0.756409
TRAIN LOSS = 0.73439
TRAIN ACC = 77.6505 % (46592/60000)
Loss = 0.693161
Loss = 0.779999
Loss = 0.77298
Loss = 0.73909
Loss = 0.719925
TEST LOSS = 0.741031
TEST ACC = 465.919 % (7736/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.669998
Epoch 5.2: Loss = 0.762299
Epoch 5.3: Loss = 0.730545
Epoch 5.4: Loss = 0.799225
Epoch 5.5: Loss = 0.703629
Epoch 5.6: Loss = 0.767029
Epoch 5.7: Loss = 0.718796
Epoch 5.8: Loss = 0.680695
Epoch 5.9: Loss = 0.666428
Epoch 5.10: Loss = 0.668701
Epoch 5.11: Loss = 0.635651
Epoch 5.12: Loss = 0.589645
Epoch 5.13: Loss = 0.709961
Epoch 5.14: Loss = 0.707138
Epoch 5.15: Loss = 0.661194
Epoch 5.16: Loss = 0.802887
Epoch 5.17: Loss = 0.777603
Epoch 5.18: Loss = 0.706131
Epoch 5.19: Loss = 0.658585
Epoch 5.20: Loss = 0.711243
Epoch 5.21: Loss = 0.698517
Epoch 5.22: Loss = 0.733139
Epoch 5.23: Loss = 0.684158
Epoch 5.24: Loss = 0.753616
Epoch 5.25: Loss = 0.712692
Epoch 5.26: Loss = 0.806244
Epoch 5.27: Loss = 0.706619
Epoch 5.28: Loss = 0.672272
Epoch 5.29: Loss = 0.669418
Epoch 5.30: Loss = 0.693741
TRAIN LOSS = 0.708603
TRAIN ACC = 79.0466 % (47430/60000)
Loss = 0.659683
Loss = 0.757568
Loss = 0.754105
Loss = 0.72261
Loss = 0.703369
TEST LOSS = 0.719467
TEST ACC = 474.3 % (7904/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.707047
Epoch 6.2: Loss = 0.772552
Epoch 6.3: Loss = 0.66246
Epoch 6.4: Loss = 0.721634
Epoch 6.5: Loss = 0.613342
Epoch 6.6: Loss = 0.76088
Epoch 6.7: Loss = 0.572968
Epoch 6.8: Loss = 0.663986
Epoch 6.9: Loss = 0.668396
Epoch 6.10: Loss = 0.664215
Epoch 6.11: Loss = 0.619247
Epoch 6.12: Loss = 0.78714
Epoch 6.13: Loss = 0.829559
Epoch 6.14: Loss = 0.698914
Epoch 6.15: Loss = 0.644043
Epoch 6.16: Loss = 0.669159
Epoch 6.17: Loss = 0.673813
Epoch 6.18: Loss = 0.800568
Epoch 6.19: Loss = 0.833084
Epoch 6.20: Loss = 0.678024
Epoch 6.21: Loss = 0.609894
Epoch 6.22: Loss = 0.708206
Epoch 6.23: Loss = 0.704544
Epoch 6.24: Loss = 0.751221
Epoch 6.25: Loss = 0.63327
Epoch 6.26: Loss = 0.774261
Epoch 6.27: Loss = 0.693237
Epoch 6.28: Loss = 0.785446
Epoch 6.29: Loss = 0.62912
Epoch 6.30: Loss = 0.706589
TRAIN LOSS = 0.701233
TRAIN ACC = 79.8492 % (47912/60000)
Loss = 0.653915
Loss = 0.735916
Loss = 0.737473
Loss = 0.701065
Loss = 0.676834
TEST LOSS = 0.70104
TEST ACC = 479.12 % (7900/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.68132
Epoch 7.2: Loss = 0.792282
Epoch 7.3: Loss = 0.715408
Epoch 7.4: Loss = 0.661102
Epoch 7.5: Loss = 0.658112
Epoch 7.6: Loss = 0.785309
Epoch 7.7: Loss = 0.736069
Epoch 7.8: Loss = 0.741592
Epoch 7.9: Loss = 0.658569
Epoch 7.10: Loss = 0.639389
Epoch 7.11: Loss = 0.691711
Epoch 7.12: Loss = 0.619965
Epoch 7.13: Loss = 0.76561
Epoch 7.14: Loss = 0.587891
Epoch 7.15: Loss = 0.683609
Epoch 7.16: Loss = 0.671219
Epoch 7.17: Loss = 0.712814
Epoch 7.18: Loss = 0.634079
Epoch 7.19: Loss = 0.66745
Epoch 7.20: Loss = 0.782776
Epoch 7.21: Loss = 0.717438
Epoch 7.22: Loss = 0.623016
Epoch 7.23: Loss = 0.671326
Epoch 7.24: Loss = 0.706146
Epoch 7.25: Loss = 0.657745
Epoch 7.26: Loss = 0.703583
Epoch 7.27: Loss = 0.608185
Epoch 7.28: Loss = 0.681076
Epoch 7.29: Loss = 0.694855
Epoch 7.30: Loss = 0.8423
TRAIN LOSS = 0.693085
TRAIN ACC = 80.2383 % (48145/60000)
Loss = 0.611404
Loss = 0.702026
Loss = 0.709351
Loss = 0.66539
Loss = 0.653442
TEST LOSS = 0.668323
TEST ACC = 481.45 % (8024/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.676056
Epoch 8.2: Loss = 0.680099
Epoch 8.3: Loss = 0.633759
Epoch 8.4: Loss = 0.836761
Epoch 8.5: Loss = 0.734619
Epoch 8.6: Loss = 0.648224
Epoch 8.7: Loss = 0.67981
Epoch 8.8: Loss = 0.665405
Epoch 8.9: Loss = 0.655182
Epoch 8.10: Loss = 0.598618
Epoch 8.11: Loss = 0.705261
Epoch 8.12: Loss = 0.681839
Epoch 8.13: Loss = 0.72525
Epoch 8.14: Loss = 0.679382
Epoch 8.15: Loss = 0.718521
Epoch 8.16: Loss = 0.583008
Epoch 8.17: Loss = 0.686874
Epoch 8.18: Loss = 0.573105
Epoch 8.19: Loss = 0.798553
Epoch 8.20: Loss = 0.729721
Epoch 8.21: Loss = 0.736862
Epoch 8.22: Loss = 0.619522
Epoch 8.23: Loss = 0.612595
Epoch 8.24: Loss = 0.659729
Epoch 8.25: Loss = 0.628784
Epoch 8.26: Loss = 0.644516
Epoch 8.27: Loss = 0.690628
Epoch 8.28: Loss = 0.720703
Epoch 8.29: Loss = 0.726639
Epoch 8.30: Loss = 0.695892
TRAIN LOSS = 0.680878
TRAIN ACC = 80.7495 % (48452/60000)
Loss = 0.681076
Loss = 0.791611
Loss = 0.773849
Loss = 0.753738
Loss = 0.721527
TEST LOSS = 0.74436
TEST ACC = 484.518 % (7946/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.671768
Epoch 9.2: Loss = 0.702805
Epoch 9.3: Loss = 0.727463
Epoch 9.4: Loss = 0.733627
Epoch 9.5: Loss = 0.718323
Epoch 9.6: Loss = 0.68515
Epoch 9.7: Loss = 0.64032
Epoch 9.8: Loss = 0.609955
Epoch 9.9: Loss = 0.650955
Epoch 9.10: Loss = 0.647644
Epoch 9.11: Loss = 0.691116
Epoch 9.12: Loss = 0.716187
Epoch 9.13: Loss = 0.813019
Epoch 9.14: Loss = 0.818298
Epoch 9.15: Loss = 0.752533
Epoch 9.16: Loss = 0.675079
Epoch 9.17: Loss = 0.713226
Epoch 9.18: Loss = 0.626007
Epoch 9.19: Loss = 0.706223
Epoch 9.20: Loss = 0.571686
Epoch 9.21: Loss = 0.721603
Epoch 9.22: Loss = 0.577347
Epoch 9.23: Loss = 0.7314
Epoch 9.24: Loss = 0.650452
Epoch 9.25: Loss = 0.762131
Epoch 9.26: Loss = 0.638855
Epoch 9.27: Loss = 0.650848
Epoch 9.28: Loss = 0.58194
Epoch 9.29: Loss = 0.637604
Epoch 9.30: Loss = 0.601288
TRAIN LOSS = 0.680847
TRAIN ACC = 81.1218 % (48675/60000)
Loss = 0.654831
Loss = 0.733643
Loss = 0.751328
Loss = 0.690857
Loss = 0.681244
TEST LOSS = 0.70238
TEST ACC = 486.749 % (7987/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.635712
Epoch 10.2: Loss = 0.775787
Epoch 10.3: Loss = 0.608139
Epoch 10.4: Loss = 0.795273
Epoch 10.5: Loss = 0.700409
Epoch 10.6: Loss = 0.610291
Epoch 10.7: Loss = 0.624939
Epoch 10.8: Loss = 0.721939
Epoch 10.9: Loss = 0.687744
Epoch 10.10: Loss = 0.709045
Epoch 10.11: Loss = 0.809418
Epoch 10.12: Loss = 0.763962
Epoch 10.13: Loss = 0.678818
Epoch 10.14: Loss = 0.647552
Epoch 10.15: Loss = 0.615356
Epoch 10.16: Loss = 0.739426
Epoch 10.17: Loss = 0.603302
Epoch 10.18: Loss = 0.651001
Epoch 10.19: Loss = 0.669312
Epoch 10.20: Loss = 0.767288
Epoch 10.21: Loss = 0.600723
Epoch 10.22: Loss = 0.642303
Epoch 10.23: Loss = 0.658936
Epoch 10.24: Loss = 0.769287
Epoch 10.25: Loss = 0.764481
Epoch 10.26: Loss = 0.644211
Epoch 10.27: Loss = 0.5737
Epoch 10.28: Loss = 0.735092
Epoch 10.29: Loss = 0.5737
Epoch 10.30: Loss = 0.62439
TRAIN LOSS = 0.680069
TRAIN ACC = 81.4499 % (48873/60000)
Loss = 0.582352
Loss = 0.677429
Loss = 0.680481
Loss = 0.638031
Loss = 0.630112
TEST LOSS = 0.641681
TEST ACC = 488.73 % (8179/10000)
