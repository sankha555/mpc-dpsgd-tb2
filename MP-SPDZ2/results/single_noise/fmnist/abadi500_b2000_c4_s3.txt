Setting up connection 0
***********************************************************
Training MNIST
Model: Dense([60000, 1, 500]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 3
***********************************************************
Epoch 1.1: Loss = 2.31798
Epoch 1.2: Loss = 1.96217
Epoch 1.3: Loss = 1.7282
Epoch 1.4: Loss = 1.51662
Epoch 1.5: Loss = 1.43973
Epoch 1.6: Loss = 1.30226
Epoch 1.7: Loss = 1.21022
Epoch 1.8: Loss = 1.10553
Epoch 1.9: Loss = 1.12283
Epoch 1.10: Loss = 1.03964
Epoch 1.11: Loss = 0.970871
Epoch 1.12: Loss = 0.957306
Epoch 1.13: Loss = 0.95517
Epoch 1.14: Loss = 0.948975
Epoch 1.15: Loss = 0.903152
Epoch 1.16: Loss = 0.87561
Epoch 1.17: Loss = 0.896347
Epoch 1.18: Loss = 0.873779
Epoch 1.19: Loss = 0.865143
Epoch 1.20: Loss = 0.807846
Epoch 1.21: Loss = 0.827271
Epoch 1.22: Loss = 0.818771
Epoch 1.23: Loss = 0.796829
Epoch 1.24: Loss = 0.778549
Epoch 1.25: Loss = 0.76326
Epoch 1.26: Loss = 0.770752
Epoch 1.27: Loss = 0.797333
Epoch 1.28: Loss = 0.735168
Epoch 1.29: Loss = 0.719543
Epoch 1.30: Loss = 0.700119
TRAIN LOSS = 1.05025
TRAIN ACC = 64.0091 % (38408/60000)
Loss = 0.726349
Loss = 0.797043
Loss = 0.749451
Loss = 0.765762
Loss = 0.756531
TEST LOSS = 0.759027
TEST ACC = 384.079 % (7290/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.738663
Epoch 2.2: Loss = 0.727631
Epoch 2.3: Loss = 0.708923
Epoch 2.4: Loss = 0.747757
Epoch 2.5: Loss = 0.706833
Epoch 2.6: Loss = 0.74765
Epoch 2.7: Loss = 0.716766
Epoch 2.8: Loss = 0.686386
Epoch 2.9: Loss = 0.696655
Epoch 2.10: Loss = 0.716644
Epoch 2.11: Loss = 0.707108
Epoch 2.12: Loss = 0.682663
Epoch 2.13: Loss = 0.679733
Epoch 2.14: Loss = 0.683121
Epoch 2.15: Loss = 0.693314
Epoch 2.16: Loss = 0.694565
Epoch 2.17: Loss = 0.650223
Epoch 2.18: Loss = 0.691406
Epoch 2.19: Loss = 0.662857
Epoch 2.20: Loss = 0.756363
Epoch 2.21: Loss = 0.656586
Epoch 2.22: Loss = 0.676559
Epoch 2.23: Loss = 0.647491
Epoch 2.24: Loss = 0.683197
Epoch 2.25: Loss = 0.672226
Epoch 2.26: Loss = 0.622269
Epoch 2.27: Loss = 0.691238
Epoch 2.28: Loss = 0.646851
Epoch 2.29: Loss = 0.680588
Epoch 2.30: Loss = 0.648117
TRAIN LOSS = 0.690689
TRAIN ACC = 76.3382 % (45805/60000)
Loss = 0.644455
Loss = 0.725281
Loss = 0.689713
Loss = 0.691391
Loss = 0.686417
TEST LOSS = 0.687451
TEST ACC = 458.049 % (7621/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.643753
Epoch 3.2: Loss = 0.624084
Epoch 3.3: Loss = 0.685379
Epoch 3.4: Loss = 0.602127
Epoch 3.5: Loss = 0.654739
Epoch 3.6: Loss = 0.644608
Epoch 3.7: Loss = 0.659088
Epoch 3.8: Loss = 0.603058
Epoch 3.9: Loss = 0.710052
Epoch 3.10: Loss = 0.681931
Epoch 3.11: Loss = 0.646591
Epoch 3.12: Loss = 0.683075
Epoch 3.13: Loss = 0.614563
Epoch 3.14: Loss = 0.596436
Epoch 3.15: Loss = 0.630157
Epoch 3.16: Loss = 0.588654
Epoch 3.17: Loss = 0.680389
Epoch 3.18: Loss = 0.6716
Epoch 3.19: Loss = 0.635468
Epoch 3.20: Loss = 0.595093
Epoch 3.21: Loss = 0.72403
Epoch 3.22: Loss = 0.651901
Epoch 3.23: Loss = 0.644012
Epoch 3.24: Loss = 0.6586
Epoch 3.25: Loss = 0.660782
Epoch 3.26: Loss = 0.651947
Epoch 3.27: Loss = 0.677139
Epoch 3.28: Loss = 0.642929
Epoch 3.29: Loss = 0.660706
Epoch 3.30: Loss = 0.62294
TRAIN LOSS = 0.648209
TRAIN ACC = 78.4225 % (47056/60000)
Loss = 0.607742
Loss = 0.693695
Loss = 0.664383
Loss = 0.658356
Loss = 0.650848
TEST LOSS = 0.655005
TEST ACC = 470.56 % (7825/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.585144
Epoch 4.2: Loss = 0.647263
Epoch 4.3: Loss = 0.625656
Epoch 4.4: Loss = 0.659454
Epoch 4.5: Loss = 0.573074
Epoch 4.6: Loss = 0.642212
Epoch 4.7: Loss = 0.641144
Epoch 4.8: Loss = 0.697784
Epoch 4.9: Loss = 0.636841
Epoch 4.10: Loss = 0.604431
Epoch 4.11: Loss = 0.631912
Epoch 4.12: Loss = 0.631577
Epoch 4.13: Loss = 0.629745
Epoch 4.14: Loss = 0.606827
Epoch 4.15: Loss = 0.61026
Epoch 4.16: Loss = 0.635315
Epoch 4.17: Loss = 0.632034
Epoch 4.18: Loss = 0.656616
Epoch 4.19: Loss = 0.598877
Epoch 4.20: Loss = 0.681335
Epoch 4.21: Loss = 0.628723
Epoch 4.22: Loss = 0.699478
Epoch 4.23: Loss = 0.617004
Epoch 4.24: Loss = 0.667374
Epoch 4.25: Loss = 0.620316
Epoch 4.26: Loss = 0.585495
Epoch 4.27: Loss = 0.622513
Epoch 4.28: Loss = 0.609512
Epoch 4.29: Loss = 0.647598
Epoch 4.30: Loss = 0.609177
TRAIN LOSS = 0.631165
TRAIN ACC = 79.5761 % (47748/60000)
Loss = 0.591385
Loss = 0.690308
Loss = 0.663055
Loss = 0.654739
Loss = 0.646912
TEST LOSS = 0.64928
TEST ACC = 477.48 % (7910/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.651291
Epoch 5.2: Loss = 0.594254
Epoch 5.3: Loss = 0.675644
Epoch 5.4: Loss = 0.621552
Epoch 5.5: Loss = 0.624252
Epoch 5.6: Loss = 0.590744
Epoch 5.7: Loss = 0.636246
Epoch 5.8: Loss = 0.592636
Epoch 5.9: Loss = 0.620087
Epoch 5.10: Loss = 0.64183
Epoch 5.11: Loss = 0.601883
Epoch 5.12: Loss = 0.588791
Epoch 5.13: Loss = 0.577454
Epoch 5.14: Loss = 0.686081
Epoch 5.15: Loss = 0.609421
Epoch 5.16: Loss = 0.64122
Epoch 5.17: Loss = 0.61673
Epoch 5.18: Loss = 0.6539
Epoch 5.19: Loss = 0.533524
Epoch 5.20: Loss = 0.641525
Epoch 5.21: Loss = 0.572769
Epoch 5.22: Loss = 0.619629
Epoch 5.23: Loss = 0.63707
Epoch 5.24: Loss = 0.611618
Epoch 5.25: Loss = 0.590775
Epoch 5.26: Loss = 0.654388
Epoch 5.27: Loss = 0.63118
Epoch 5.28: Loss = 0.583939
Epoch 5.29: Loss = 0.601593
Epoch 5.30: Loss = 0.592636
TRAIN LOSS = 0.616501
TRAIN ACC = 80.3116 % (48189/60000)
Loss = 0.567245
Loss = 0.675812
Loss = 0.643814
Loss = 0.627686
Loss = 0.625717
TEST LOSS = 0.628055
TEST ACC = 481.889 % (7971/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.599319
Epoch 6.2: Loss = 0.595276
Epoch 6.3: Loss = 0.624695
Epoch 6.4: Loss = 0.613251
Epoch 6.5: Loss = 0.602295
Epoch 6.6: Loss = 0.593796
Epoch 6.7: Loss = 0.637421
Epoch 6.8: Loss = 0.582092
Epoch 6.9: Loss = 0.596786
Epoch 6.10: Loss = 0.594482
Epoch 6.11: Loss = 0.610703
Epoch 6.12: Loss = 0.626404
Epoch 6.13: Loss = 0.539536
Epoch 6.14: Loss = 0.646088
Epoch 6.15: Loss = 0.594742
Epoch 6.16: Loss = 0.621292
Epoch 6.17: Loss = 0.556015
Epoch 6.18: Loss = 0.566254
Epoch 6.19: Loss = 0.586121
Epoch 6.20: Loss = 0.6492
Epoch 6.21: Loss = 0.577484
Epoch 6.22: Loss = 0.657471
Epoch 6.23: Loss = 0.644592
Epoch 6.24: Loss = 0.667053
Epoch 6.25: Loss = 0.60524
Epoch 6.26: Loss = 0.665924
Epoch 6.27: Loss = 0.628677
Epoch 6.28: Loss = 0.643494
Epoch 6.29: Loss = 0.578156
Epoch 6.30: Loss = 0.59375
TRAIN LOSS = 0.60994
TRAIN ACC = 80.7663 % (48462/60000)
Loss = 0.57074
Loss = 0.678207
Loss = 0.647736
Loss = 0.629501
Loss = 0.623108
TEST LOSS = 0.629858
TEST ACC = 484.619 % (7984/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.564301
Epoch 7.2: Loss = 0.63176
Epoch 7.3: Loss = 0.603943
Epoch 7.4: Loss = 0.662872
Epoch 7.5: Loss = 0.593414
Epoch 7.6: Loss = 0.608154
Epoch 7.7: Loss = 0.55455
Epoch 7.8: Loss = 0.637054
Epoch 7.9: Loss = 0.623978
Epoch 7.10: Loss = 0.624695
Epoch 7.11: Loss = 0.600143
Epoch 7.12: Loss = 0.535263
Epoch 7.13: Loss = 0.56575
Epoch 7.14: Loss = 0.597702
Epoch 7.15: Loss = 0.621231
Epoch 7.16: Loss = 0.59845
Epoch 7.17: Loss = 0.570282
Epoch 7.18: Loss = 0.61348
Epoch 7.19: Loss = 0.571136
Epoch 7.20: Loss = 0.616699
Epoch 7.21: Loss = 0.658295
Epoch 7.22: Loss = 0.603973
Epoch 7.23: Loss = 0.605057
Epoch 7.24: Loss = 0.575058
Epoch 7.25: Loss = 0.636765
Epoch 7.26: Loss = 0.595306
Epoch 7.27: Loss = 0.576263
Epoch 7.28: Loss = 0.6259
Epoch 7.29: Loss = 0.515472
Epoch 7.30: Loss = 0.561432
TRAIN LOSS = 0.598297
TRAIN ACC = 81.3843 % (48833/60000)
Loss = 0.559998
Loss = 0.666168
Loss = 0.65271
Loss = 0.614975
Loss = 0.622757
TEST LOSS = 0.623321
TEST ACC = 488.329 % (8047/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.61087
Epoch 8.2: Loss = 0.582626
Epoch 8.3: Loss = 0.589447
Epoch 8.4: Loss = 0.601257
Epoch 8.5: Loss = 0.609726
Epoch 8.6: Loss = 0.619049
Epoch 8.7: Loss = 0.595581
Epoch 8.8: Loss = 0.57608
Epoch 8.9: Loss = 0.581711
Epoch 8.10: Loss = 0.600739
Epoch 8.11: Loss = 0.54892
Epoch 8.12: Loss = 0.608887
Epoch 8.13: Loss = 0.594818
Epoch 8.14: Loss = 0.566849
Epoch 8.15: Loss = 0.614883
Epoch 8.16: Loss = 0.563278
Epoch 8.17: Loss = 0.62999
Epoch 8.18: Loss = 0.53479
Epoch 8.19: Loss = 0.633041
Epoch 8.20: Loss = 0.564148
Epoch 8.21: Loss = 0.589188
Epoch 8.22: Loss = 0.567017
Epoch 8.23: Loss = 0.576263
Epoch 8.24: Loss = 0.622864
Epoch 8.25: Loss = 0.5858
Epoch 8.26: Loss = 0.568863
Epoch 8.27: Loss = 0.634415
Epoch 8.28: Loss = 0.569046
Epoch 8.29: Loss = 0.609406
Epoch 8.30: Loss = 0.611771
TRAIN LOSS = 0.592056
TRAIN ACC = 81.7963 % (49080/60000)
Loss = 0.583908
Loss = 0.702042
Loss = 0.682159
Loss = 0.664673
Loss = 0.65773
TEST LOSS = 0.658102
TEST ACC = 490.799 % (8071/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.631866
Epoch 9.2: Loss = 0.625366
Epoch 9.3: Loss = 0.539368
Epoch 9.4: Loss = 0.602829
Epoch 9.5: Loss = 0.56044
Epoch 9.6: Loss = 0.580704
Epoch 9.7: Loss = 0.594681
Epoch 9.8: Loss = 0.553314
Epoch 9.9: Loss = 0.583847
Epoch 9.10: Loss = 0.552231
Epoch 9.11: Loss = 0.547226
Epoch 9.12: Loss = 0.580017
Epoch 9.13: Loss = 0.591721
Epoch 9.14: Loss = 0.571793
Epoch 9.15: Loss = 0.607437
Epoch 9.16: Loss = 0.60376
Epoch 9.17: Loss = 0.657181
Epoch 9.18: Loss = 0.602219
Epoch 9.19: Loss = 0.625854
Epoch 9.20: Loss = 0.568588
Epoch 9.21: Loss = 0.667618
Epoch 9.22: Loss = 0.584625
Epoch 9.23: Loss = 0.629257
Epoch 9.24: Loss = 0.625107
Epoch 9.25: Loss = 0.586929
Epoch 9.26: Loss = 0.589828
Epoch 9.27: Loss = 0.625473
Epoch 9.28: Loss = 0.637344
Epoch 9.29: Loss = 0.590591
Epoch 9.30: Loss = 0.584641
TRAIN LOSS = 0.596756
TRAIN ACC = 81.9443 % (49169/60000)
Loss = 0.573334
Loss = 0.670822
Loss = 0.665482
Loss = 0.617905
Loss = 0.624619
TEST LOSS = 0.630432
TEST ACC = 491.689 % (8037/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.672729
Epoch 10.2: Loss = 0.683517
Epoch 10.3: Loss = 0.553574
Epoch 10.4: Loss = 0.632721
Epoch 10.5: Loss = 0.568222
Epoch 10.6: Loss = 0.575912
Epoch 10.7: Loss = 0.54689
Epoch 10.8: Loss = 0.606949
Epoch 10.9: Loss = 0.618927
Epoch 10.10: Loss = 0.575714
Epoch 10.11: Loss = 0.56575
Epoch 10.12: Loss = 0.561752
Epoch 10.13: Loss = 0.614563
Epoch 10.14: Loss = 0.559372
Epoch 10.15: Loss = 0.573364
Epoch 10.16: Loss = 0.554276
Epoch 10.17: Loss = 0.548904
Epoch 10.18: Loss = 0.669739
Epoch 10.19: Loss = 0.558426
Epoch 10.20: Loss = 0.590866
Epoch 10.21: Loss = 0.557526
Epoch 10.22: Loss = 0.548935
Epoch 10.23: Loss = 0.550522
Epoch 10.24: Loss = 0.630356
Epoch 10.25: Loss = 0.619995
Epoch 10.26: Loss = 0.567047
Epoch 10.27: Loss = 0.572083
Epoch 10.28: Loss = 0.611374
Epoch 10.29: Loss = 0.597626
Epoch 10.30: Loss = 0.61792
TRAIN LOSS = 0.590195
TRAIN ACC = 82.1915 % (49317/60000)
Loss = 0.560638
Loss = 0.675812
Loss = 0.659821
Loss = 0.633423
Loss = 0.631378
TEST LOSS = 0.632214
TEST ACC = 493.169 % (8111/10000)
