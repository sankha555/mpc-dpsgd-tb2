***********************************************************
Training MNIST
Model: Dense([60000, 1, 1000]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 600
Num Epochs: 15
Learning Rate: 0.1 to 0.05 over 10 epochs
***********************************************************
Epoch 1.1: Loss = 2.31227
Epoch 1.2: Loss = 2.1707
Epoch 1.3: Loss = 2.0434
Epoch 1.4: Loss = 1.92828
Epoch 1.5: Loss = 1.82336
Epoch 1.6: Loss = 1.72221
Epoch 1.7: Loss = 1.63348
Epoch 1.8: Loss = 1.52527
Epoch 1.9: Loss = 1.46654
Epoch 1.10: Loss = 1.40199
Epoch 1.11: Loss = 1.33038
Epoch 1.12: Loss = 1.28978
Epoch 1.13: Loss = 1.23045
Epoch 1.14: Loss = 1.15784
Epoch 1.15: Loss = 1.11534
Epoch 1.16: Loss = 1.11401
Epoch 1.17: Loss = 1.06317
Epoch 1.18: Loss = 0.976898
Epoch 1.19: Loss = 1.03954
Epoch 1.20: Loss = 0.947006
Epoch 1.21: Loss = 0.89679
Epoch 1.22: Loss = 0.901413
Epoch 1.23: Loss = 0.884277
Epoch 1.24: Loss = 0.930801
Epoch 1.25: Loss = 0.813416
Epoch 1.26: Loss = 0.830399
Epoch 1.27: Loss = 0.797028
Epoch 1.28: Loss = 0.785324
Epoch 1.29: Loss = 0.76181
Epoch 1.30: Loss = 0.861862
Epoch 1.31: Loss = 0.735046
Epoch 1.32: Loss = 0.738846
Epoch 1.33: Loss = 0.735153
Epoch 1.34: Loss = 0.701431
Epoch 1.35: Loss = 0.70369
Epoch 1.36: Loss = 0.680527
Epoch 1.37: Loss = 0.679443
Epoch 1.38: Loss = 0.65834
Epoch 1.39: Loss = 0.68541
Epoch 1.40: Loss = 0.65213
Epoch 1.41: Loss = 0.622391
Epoch 1.42: Loss = 0.659897
Epoch 1.43: Loss = 0.672058
Epoch 1.44: Loss = 0.654236
Epoch 1.45: Loss = 0.614166
Epoch 1.46: Loss = 0.599274
Epoch 1.47: Loss = 0.582474
Epoch 1.48: Loss = 0.575851
Epoch 1.49: Loss = 0.612091
Epoch 1.50: Loss = 0.605667
Epoch 1.51: Loss = 0.573517
Epoch 1.52: Loss = 0.58197
Epoch 1.53: Loss = 0.543655
Epoch 1.54: Loss = 0.582794
Epoch 1.55: Loss = 0.583847
Epoch 1.56: Loss = 0.538284
Epoch 1.57: Loss = 0.53775
Epoch 1.58: Loss = 0.554688
Epoch 1.59: Loss = 0.586014
Epoch 1.60: Loss = 0.54129
Epoch 1.61: Loss = 0.520752
Epoch 1.62: Loss = 0.571564
Epoch 1.63: Loss = 0.528366
Epoch 1.64: Loss = 0.518127
Epoch 1.65: Loss = 0.514832
Epoch 1.66: Loss = 0.522369
Epoch 1.67: Loss = 0.485382
Epoch 1.68: Loss = 0.523666
Epoch 1.69: Loss = 0.555603
Epoch 1.70: Loss = 0.463821
Epoch 1.71: Loss = 0.509674
Epoch 1.72: Loss = 0.524307
Epoch 1.73: Loss = 0.487885
Epoch 1.74: Loss = 0.518219
Epoch 1.75: Loss = 0.450073
Epoch 1.76: Loss = 0.517776
Epoch 1.77: Loss = 0.455429
Epoch 1.78: Loss = 0.5159
Epoch 1.79: Loss = 0.439362
Epoch 1.80: Loss = 0.417023
Epoch 1.81: Loss = 0.493973
Epoch 1.82: Loss = 0.467087
Epoch 1.83: Loss = 0.465378
Epoch 1.84: Loss = 0.449905
Epoch 1.85: Loss = 0.48584
Epoch 1.86: Loss = 0.473297
Epoch 1.87: Loss = 0.451096
Epoch 1.88: Loss = 0.468109
Epoch 1.89: Loss = 0.441071
Epoch 1.90: Loss = 0.465286
Epoch 1.91: Loss = 0.469757
Epoch 1.92: Loss = 0.427322
Epoch 1.93: Loss = 0.402573
Epoch 1.94: Loss = 0.399979
Epoch 1.95: Loss = 0.469727
Epoch 1.96: Loss = 0.450928
Epoch 1.97: Loss = 0.443085
Epoch 1.98: Loss = 0.451736
Epoch 1.99: Loss = 0.447647
Epoch 1.100: Loss = 0.436676
TRAIN LOSS = 0.756485
TRAIN ACC = 82.6355 % (49584/60000)
Loss = 0.462692
Loss = 0.476639
Loss = 0.594421
Loss = 0.551971
Loss = 0.453094
Loss = 0.46376
Loss = 0.549454
Loss = 0.506653
Loss = 0.382721
Loss = 0.320801
Loss = 0.315521
Loss = 0.336563
Loss = 0.291794
Loss = 0.327362
Loss = 0.152618
Loss = 0.276428
Loss = 0.588135
TEST LOSS = 0.411275
TEST ACC = 495.839 % (8949/10000)
Reducing learning rate to 0.0944519
Epoch 2.1: Loss = 0.4245
Epoch 2.2: Loss = 0.430161
Epoch 2.3: Loss = 0.395737
Epoch 2.4: Loss = 0.429276
Epoch 2.5: Loss = 0.379196
Epoch 2.6: Loss = 0.428177
Epoch 2.7: Loss = 0.470123
Epoch 2.8: Loss = 0.4272
Epoch 2.9: Loss = 0.422363
Epoch 2.10: Loss = 0.443756
Epoch 2.11: Loss = 0.415558
Epoch 2.12: Loss = 0.430435
Epoch 2.13: Loss = 0.391312
Epoch 2.14: Loss = 0.371597
Epoch 2.15: Loss = 0.45816
Epoch 2.16: Loss = 0.412186
Epoch 2.17: Loss = 0.45607
Epoch 2.18: Loss = 0.395401
Epoch 2.19: Loss = 0.455322
Epoch 2.20: Loss = 0.463272
Epoch 2.21: Loss = 0.395203
Epoch 2.22: Loss = 0.445816
Epoch 2.23: Loss = 0.428131
Epoch 2.24: Loss = 0.440887
Epoch 2.25: Loss = 0.335419
Epoch 2.26: Loss = 0.475693
Epoch 2.27: Loss = 0.380707
Epoch 2.28: Loss = 0.383423
Epoch 2.29: Loss = 0.339325
Epoch 2.30: Loss = 0.410217
Epoch 2.31: Loss = 0.355133
Epoch 2.32: Loss = 0.409042
Epoch 2.33: Loss = 0.388489
Epoch 2.34: Loss = 0.340546
Epoch 2.35: Loss = 0.402802
Epoch 2.36: Loss = 0.404922
Epoch 2.37: Loss = 0.358963
Epoch 2.38: Loss = 0.362656
Epoch 2.39: Loss = 0.378464
Epoch 2.40: Loss = 0.379669
Epoch 2.41: Loss = 0.377121
Epoch 2.42: Loss = 0.372757
Epoch 2.43: Loss = 0.374741
Epoch 2.44: Loss = 0.343124
Epoch 2.45: Loss = 0.382843
Epoch 2.46: Loss = 0.388382
Epoch 2.47: Loss = 0.386871
Epoch 2.48: Loss = 0.33371
Epoch 2.49: Loss = 0.355713
Epoch 2.50: Loss = 0.369629
Epoch 2.51: Loss = 0.378876
Epoch 2.52: Loss = 0.367126
Epoch 2.53: Loss = 0.369446
Epoch 2.54: Loss = 0.387238
Epoch 2.55: Loss = 0.383331
Epoch 2.56: Loss = 0.394867
Epoch 2.57: Loss = 0.401642
Epoch 2.58: Loss = 0.382492
Epoch 2.59: Loss = 0.334686
Epoch 2.60: Loss = 0.372269
Epoch 2.61: Loss = 0.406738
Epoch 2.62: Loss = 0.377151
Epoch 2.63: Loss = 0.367554
Epoch 2.64: Loss = 0.360153
Epoch 2.65: Loss = 0.338486
Epoch 2.66: Loss = 0.342819
Epoch 2.67: Loss = 0.371933
Epoch 2.68: Loss = 0.344803
Epoch 2.69: Loss = 0.379242
Epoch 2.70: Loss = 0.356216
Epoch 2.71: Loss = 0.373398
Epoch 2.72: Loss = 0.330093
Epoch 2.73: Loss = 0.345612
Epoch 2.74: Loss = 0.353455
Epoch 2.75: Loss = 0.36026
Epoch 2.76: Loss = 0.37027
Epoch 2.77: Loss = 0.355225
Epoch 2.78: Loss = 0.387939
Epoch 2.79: Loss = 0.337891
Epoch 2.80: Loss = 0.371765
Epoch 2.81: Loss = 0.424347
Epoch 2.82: Loss = 0.401718
Epoch 2.83: Loss = 0.380341
Epoch 2.84: Loss = 0.376572
Epoch 2.85: Loss = 0.348343
Epoch 2.86: Loss = 0.355606
Epoch 2.87: Loss = 0.373795
Epoch 2.88: Loss = 0.360199
Epoch 2.89: Loss = 0.398651
Epoch 2.90: Loss = 0.380859
Epoch 2.91: Loss = 0.342331
Epoch 2.92: Loss = 0.299347
Epoch 2.93: Loss = 0.364197
Epoch 2.94: Loss = 0.369003
Epoch 2.95: Loss = 0.346313
Epoch 2.96: Loss = 0.406158
Epoch 2.97: Loss = 0.351288
Epoch 2.98: Loss = 0.381226
Epoch 2.99: Loss = 0.374237
Epoch 2.100: Loss = 0.369766
TRAIN LOSS = 0.384079
TRAIN ACC = 89.682 % (53812/60000)
Loss = 0.370758
Loss = 0.385178
Loss = 0.50441
Loss = 0.466705
Loss = 0.364563
Loss = 0.367493
Loss = 0.471695
Loss = 0.414993
Loss = 0.311081
Loss = 0.245956
Loss = 0.277893
Loss = 0.259598
Loss = 0.206284
Loss = 0.268631
Loss = 0.0960693
Loss = 0.21431
Loss = 0.502167
TEST LOSS = 0.333624
TEST ACC = 538.12 % (9109/10000)
Reducing learning rate to 0.0888977
Epoch 3.1: Loss = 0.345078
Epoch 3.2: Loss = 0.400574
Epoch 3.3: Loss = 0.322006
Epoch 3.4: Loss = 0.332001
Epoch 3.5: Loss = 0.342331
Epoch 3.6: Loss = 0.363174
Epoch 3.7: Loss = 0.327271
Epoch 3.8: Loss = 0.326416
Epoch 3.9: Loss = 0.428833
Epoch 3.10: Loss = 0.364471
Epoch 3.11: Loss = 0.322235
Epoch 3.12: Loss = 0.405655
Epoch 3.13: Loss = 0.308228
Epoch 3.14: Loss = 0.325592
Epoch 3.15: Loss = 0.355301
Epoch 3.16: Loss = 0.392242
Epoch 3.17: Loss = 0.355179
Epoch 3.18: Loss = 0.349503
Epoch 3.19: Loss = 0.336533
Epoch 3.20: Loss = 0.339355
Epoch 3.21: Loss = 0.335251
Epoch 3.22: Loss = 0.316177
Epoch 3.23: Loss = 0.317474
Epoch 3.24: Loss = 0.360184
Epoch 3.25: Loss = 0.367203
Epoch 3.26: Loss = 0.314133
Epoch 3.27: Loss = 0.35405
Epoch 3.28: Loss = 0.314529
Epoch 3.29: Loss = 0.36084
Epoch 3.30: Loss = 0.332657
Epoch 3.31: Loss = 0.351212
Epoch 3.32: Loss = 0.331329
Epoch 3.33: Loss = 0.349533
Epoch 3.34: Loss = 0.347412
Epoch 3.35: Loss = 0.323975
Epoch 3.36: Loss = 0.310593
Epoch 3.37: Loss = 0.310593
Epoch 3.38: Loss = 0.314224
Epoch 3.39: Loss = 0.336777
Epoch 3.40: Loss = 0.294235
Epoch 3.41: Loss = 0.322968
Epoch 3.42: Loss = 0.342972
Epoch 3.43: Loss = 0.346649
Epoch 3.44: Loss = 0.308624
Epoch 3.45: Loss = 0.290955
Epoch 3.46: Loss = 0.299606
Epoch 3.47: Loss = 0.306274
Epoch 3.48: Loss = 0.359299
Epoch 3.49: Loss = 0.276474
Epoch 3.50: Loss = 0.336502
Epoch 3.51: Loss = 0.279526
Epoch 3.52: Loss = 0.324219
Epoch 3.53: Loss = 0.378021
Epoch 3.54: Loss = 0.344711
Epoch 3.55: Loss = 0.326416
Epoch 3.56: Loss = 0.305466
Epoch 3.57: Loss = 0.307114
Epoch 3.58: Loss = 0.363876
Epoch 3.59: Loss = 0.305267
Epoch 3.60: Loss = 0.32016
Epoch 3.61: Loss = 0.314133
Epoch 3.62: Loss = 0.319992
Epoch 3.63: Loss = 0.383072
Epoch 3.64: Loss = 0.3237
Epoch 3.65: Loss = 0.283081
Epoch 3.66: Loss = 0.325134
Epoch 3.67: Loss = 0.306808
Epoch 3.68: Loss = 0.337814
Epoch 3.69: Loss = 0.308029
Epoch 3.70: Loss = 0.348099
Epoch 3.71: Loss = 0.271378
Epoch 3.72: Loss = 0.265137
Epoch 3.73: Loss = 0.340576
Epoch 3.74: Loss = 0.297943
Epoch 3.75: Loss = 0.317184
Epoch 3.76: Loss = 0.310059
Epoch 3.77: Loss = 0.359406
Epoch 3.78: Loss = 0.294708
Epoch 3.79: Loss = 0.30867
Epoch 3.80: Loss = 0.354492
Epoch 3.81: Loss = 0.359619
Epoch 3.82: Loss = 0.291382
Epoch 3.83: Loss = 0.35054
Epoch 3.84: Loss = 0.353302
Epoch 3.85: Loss = 0.296631
Epoch 3.86: Loss = 0.354126
Epoch 3.87: Loss = 0.24498
Epoch 3.88: Loss = 0.28241
Epoch 3.89: Loss = 0.313507
Epoch 3.90: Loss = 0.311569
Epoch 3.91: Loss = 0.289856
Epoch 3.92: Loss = 0.339508
Epoch 3.93: Loss = 0.343323
Epoch 3.94: Loss = 0.346634
Epoch 3.95: Loss = 0.295898
Epoch 3.96: Loss = 0.269028
Epoch 3.97: Loss = 0.286743
Epoch 3.98: Loss = 0.329681
Epoch 3.99: Loss = 0.426376
Epoch 3.100: Loss = 0.319931
TRAIN LOSS = 0.329056
TRAIN ACC = 90.9531 % (54574/60000)
Loss = 0.326767
Loss = 0.346756
Loss = 0.460648
Loss = 0.430222
Loss = 0.322891
Loss = 0.330292
Loss = 0.429382
Loss = 0.370499
Loss = 0.266602
Loss = 0.22789
Loss = 0.241776
Loss = 0.219833
Loss = 0.171692
Loss = 0.23764
Loss = 0.0771332
Loss = 0.184509
Loss = 0.447113
TEST LOSS = 0.296556
TEST ACC = 545.74 % (9184/10000)
Reducing learning rate to 0.0833435
Epoch 4.1: Loss = 0.303268
Epoch 4.2: Loss = 0.277084
Epoch 4.3: Loss = 0.276123
Epoch 4.4: Loss = 0.336212
Epoch 4.5: Loss = 0.255173
Epoch 4.6: Loss = 0.241638
Epoch 4.7: Loss = 0.315994
Epoch 4.8: Loss = 0.312103
Epoch 4.9: Loss = 0.313614
Epoch 4.10: Loss = 0.299591
Epoch 4.11: Loss = 0.321976
Epoch 4.12: Loss = 0.36232
Epoch 4.13: Loss = 0.327423
Epoch 4.14: Loss = 0.275864
Epoch 4.15: Loss = 0.313095
Epoch 4.16: Loss = 0.318802
Epoch 4.17: Loss = 0.289093
Epoch 4.18: Loss = 0.279907
Epoch 4.19: Loss = 0.292816
Epoch 4.20: Loss = 0.329971
Epoch 4.21: Loss = 0.283401
Epoch 4.22: Loss = 0.3479
Epoch 4.23: Loss = 0.31543
Epoch 4.24: Loss = 0.290207
Epoch 4.25: Loss = 0.276581
Epoch 4.26: Loss = 0.282242
Epoch 4.27: Loss = 0.302307
Epoch 4.28: Loss = 0.326477
Epoch 4.29: Loss = 0.298553
Epoch 4.30: Loss = 0.285156
Epoch 4.31: Loss = 0.315781
Epoch 4.32: Loss = 0.310684
Epoch 4.33: Loss = 0.284424
Epoch 4.34: Loss = 0.286591
Epoch 4.35: Loss = 0.305618
Epoch 4.36: Loss = 0.319901
Epoch 4.37: Loss = 0.268387
Epoch 4.38: Loss = 0.283737
Epoch 4.39: Loss = 0.300461
Epoch 4.40: Loss = 0.34903
Epoch 4.41: Loss = 0.348404
Epoch 4.42: Loss = 0.280563
Epoch 4.43: Loss = 0.278259
Epoch 4.44: Loss = 0.291702
Epoch 4.45: Loss = 0.259003
Epoch 4.46: Loss = 0.367706
Epoch 4.47: Loss = 0.303497
Epoch 4.48: Loss = 0.282471
Epoch 4.49: Loss = 0.294235
Epoch 4.50: Loss = 0.294952
Epoch 4.51: Loss = 0.288605
Epoch 4.52: Loss = 0.311554
Epoch 4.53: Loss = 0.310471
Epoch 4.54: Loss = 0.307648
Epoch 4.55: Loss = 0.292145
Epoch 4.56: Loss = 0.290253
Epoch 4.57: Loss = 0.303467
Epoch 4.58: Loss = 0.258453
Epoch 4.59: Loss = 0.306641
Epoch 4.60: Loss = 0.314804
Epoch 4.61: Loss = 0.317642
Epoch 4.62: Loss = 0.279175
Epoch 4.63: Loss = 0.269135
Epoch 4.64: Loss = 0.312256
Epoch 4.65: Loss = 0.299118
Epoch 4.66: Loss = 0.323029
Epoch 4.67: Loss = 0.306046
Epoch 4.68: Loss = 0.276779
Epoch 4.69: Loss = 0.336426
Epoch 4.70: Loss = 0.264984
Epoch 4.71: Loss = 0.335526
Epoch 4.72: Loss = 0.305847
Epoch 4.73: Loss = 0.266693
Epoch 4.74: Loss = 0.292328
Epoch 4.75: Loss = 0.292938
Epoch 4.76: Loss = 0.317902
Epoch 4.77: Loss = 0.289734
Epoch 4.78: Loss = 0.31987
Epoch 4.79: Loss = 0.307297
Epoch 4.80: Loss = 0.280426
Epoch 4.81: Loss = 0.337173
Epoch 4.82: Loss = 0.30336
Epoch 4.83: Loss = 0.26973
Epoch 4.84: Loss = 0.283936
Epoch 4.85: Loss = 0.299271
Epoch 4.86: Loss = 0.30719
Epoch 4.87: Loss = 0.300812
Epoch 4.88: Loss = 0.341019
Epoch 4.89: Loss = 0.280853
Epoch 4.90: Loss = 0.329987
Epoch 4.91: Loss = 0.260971
Epoch 4.92: Loss = 0.307495
Epoch 4.93: Loss = 0.271393
Epoch 4.94: Loss = 0.298294
Epoch 4.95: Loss = 0.286865
Epoch 4.96: Loss = 0.320541
Epoch 4.97: Loss = 0.31044
Epoch 4.98: Loss = 0.24971
Epoch 4.99: Loss = 0.259567
Epoch 4.100: Loss = 0.28154
TRAIN LOSS = 0.29953
TRAIN ACC = 91.687 % (55014/60000)
Loss = 0.298508
Loss = 0.335159
Loss = 0.436005
Loss = 0.409485
Loss = 0.303116
Loss = 0.312744
Loss = 0.411499
Loss = 0.343903
Loss = 0.242035
Loss = 0.226257
Loss = 0.2314
Loss = 0.18808
Loss = 0.151962
Loss = 0.213867
Loss = 0.0656281
Loss = 0.176208
Loss = 0.417572
TEST LOSS = 0.277454
TEST ACC = 550.139 % (9235/10000)
Reducing learning rate to 0.0777893
Epoch 5.1: Loss = 0.22908
Epoch 5.2: Loss = 0.243607
Epoch 5.3: Loss = 0.280655
Epoch 5.4: Loss = 0.296463
Epoch 5.5: Loss = 0.274323
Epoch 5.6: Loss = 0.272491
Epoch 5.7: Loss = 0.331818
Epoch 5.8: Loss = 0.281754
Epoch 5.9: Loss = 0.284393
Epoch 5.10: Loss = 0.302872
Epoch 5.11: Loss = 0.272949
Epoch 5.12: Loss = 0.281326
Epoch 5.13: Loss = 0.219284
Epoch 5.14: Loss = 0.268127
Epoch 5.15: Loss = 0.33519
Epoch 5.16: Loss = 0.270721
Epoch 5.17: Loss = 0.264282
Epoch 5.18: Loss = 0.25621
Epoch 5.19: Loss = 0.250961
Epoch 5.20: Loss = 0.324905
Epoch 5.21: Loss = 0.301285
Epoch 5.22: Loss = 0.292389
Epoch 5.23: Loss = 0.275589
Epoch 5.24: Loss = 0.284775
Epoch 5.25: Loss = 0.238739
Epoch 5.26: Loss = 0.315659
Epoch 5.27: Loss = 0.260406
Epoch 5.28: Loss = 0.28038
Epoch 5.29: Loss = 0.2771
Epoch 5.30: Loss = 0.263855
Epoch 5.31: Loss = 0.279617
Epoch 5.32: Loss = 0.332825
Epoch 5.33: Loss = 0.319107
Epoch 5.34: Loss = 0.307327
Epoch 5.35: Loss = 0.299011
Epoch 5.36: Loss = 0.297729
Epoch 5.37: Loss = 0.295242
Epoch 5.38: Loss = 0.306
Epoch 5.39: Loss = 0.28508
Epoch 5.40: Loss = 0.312119
Epoch 5.41: Loss = 0.267242
Epoch 5.42: Loss = 0.262024
Epoch 5.43: Loss = 0.249985
Epoch 5.44: Loss = 0.318314
Epoch 5.45: Loss = 0.264069
Epoch 5.46: Loss = 0.315659
Epoch 5.47: Loss = 0.286545
Epoch 5.48: Loss = 0.217407
Epoch 5.49: Loss = 0.266006
Epoch 5.50: Loss = 0.310226
Epoch 5.51: Loss = 0.256485
Epoch 5.52: Loss = 0.303146
Epoch 5.53: Loss = 0.258759
Epoch 5.54: Loss = 0.295959
Epoch 5.55: Loss = 0.315811
Epoch 5.56: Loss = 0.341354
Epoch 5.57: Loss = 0.264786
Epoch 5.58: Loss = 0.27356
Epoch 5.59: Loss = 0.307297
Epoch 5.60: Loss = 0.306946
Epoch 5.61: Loss = 0.319122
Epoch 5.62: Loss = 0.290146
Epoch 5.63: Loss = 0.294922
Epoch 5.64: Loss = 0.266113
Epoch 5.65: Loss = 0.217728
Epoch 5.66: Loss = 0.239975
Epoch 5.67: Loss = 0.265137
Epoch 5.68: Loss = 0.237595
Epoch 5.69: Loss = 0.263184
Epoch 5.70: Loss = 0.263687
Epoch 5.71: Loss = 0.263351
Epoch 5.72: Loss = 0.270935
Epoch 5.73: Loss = 0.209351
Epoch 5.74: Loss = 0.226868
Epoch 5.75: Loss = 0.311691
Epoch 5.76: Loss = 0.256256
Epoch 5.77: Loss = 0.291336
Epoch 5.78: Loss = 0.281006
Epoch 5.79: Loss = 0.281723
Epoch 5.80: Loss = 0.272507
Epoch 5.81: Loss = 0.286072
Epoch 5.82: Loss = 0.269684
Epoch 5.83: Loss = 0.259842
Epoch 5.84: Loss = 0.234894
Epoch 5.85: Loss = 0.258591
Epoch 5.86: Loss = 0.295105
Epoch 5.87: Loss = 0.255234
Epoch 5.88: Loss = 0.260696
Epoch 5.89: Loss = 0.246368
Epoch 5.90: Loss = 0.302963
Epoch 5.91: Loss = 0.324722
Epoch 5.92: Loss = 0.305695
Epoch 5.93: Loss = 0.35466
Epoch 5.94: Loss = 0.283951
Epoch 5.95: Loss = 0.318481
Epoch 5.96: Loss = 0.213287
Epoch 5.97: Loss = 0.270416
Epoch 5.98: Loss = 0.286758
Epoch 5.99: Loss = 0.297058
Epoch 5.100: Loss = 0.289459
TRAIN LOSS = 0.279831
TRAIN ACC = 92.2623 % (55360/60000)
Loss = 0.281204
Loss = 0.307129
Loss = 0.410233
Loss = 0.385681
Loss = 0.285202
Loss = 0.288055
Loss = 0.389389
Loss = 0.325134
Loss = 0.232666
Loss = 0.201782
Loss = 0.229797
Loss = 0.180984
Loss = 0.13765
Loss = 0.210175
Loss = 0.0592041
Loss = 0.165482
Loss = 0.410416
TEST LOSS = 0.261803
TEST ACC = 553.6 % (9276/10000)
Reducing learning rate to 0.0722351
Epoch 6.1: Loss = 0.316605
Epoch 6.2: Loss = 0.27037
Epoch 6.3: Loss = 0.326019
Epoch 6.4: Loss = 0.246109
Epoch 6.5: Loss = 0.225937
Epoch 6.6: Loss = 0.224396
Epoch 6.7: Loss = 0.289886
Epoch 6.8: Loss = 0.274277
Epoch 6.9: Loss = 0.245361
Epoch 6.10: Loss = 0.211243
Epoch 6.11: Loss = 0.319168
Epoch 6.12: Loss = 0.232742
Epoch 6.13: Loss = 0.312057
Epoch 6.14: Loss = 0.261215
Epoch 6.15: Loss = 0.257034
Epoch 6.16: Loss = 0.279465
Epoch 6.17: Loss = 0.292465
Epoch 6.18: Loss = 0.284866
Epoch 6.19: Loss = 0.283401
Epoch 6.20: Loss = 0.264038
Epoch 6.21: Loss = 0.307495
Epoch 6.22: Loss = 0.298477
Epoch 6.23: Loss = 0.262192
Epoch 6.24: Loss = 0.276459
Epoch 6.25: Loss = 0.311142
Epoch 6.26: Loss = 0.293945
Epoch 6.27: Loss = 0.261276
Epoch 6.28: Loss = 0.24942
Epoch 6.29: Loss = 0.255157
Epoch 6.30: Loss = 0.258163
Epoch 6.31: Loss = 0.263794
Epoch 6.32: Loss = 0.269318
Epoch 6.33: Loss = 0.260849
Epoch 6.34: Loss = 0.259766
Epoch 6.35: Loss = 0.249023
Epoch 6.36: Loss = 0.262115
Epoch 6.37: Loss = 0.239075
Epoch 6.38: Loss = 0.271332
Epoch 6.39: Loss = 0.253922
Epoch 6.40: Loss = 0.290466
Epoch 6.41: Loss = 0.204681
Epoch 6.42: Loss = 0.280807
Epoch 6.43: Loss = 0.286591
Epoch 6.44: Loss = 0.246124
Epoch 6.45: Loss = 0.248764
Epoch 6.46: Loss = 0.252426
Epoch 6.47: Loss = 0.236969
Epoch 6.48: Loss = 0.265167
Epoch 6.49: Loss = 0.319504
Epoch 6.50: Loss = 0.298828
Epoch 6.51: Loss = 0.257751
Epoch 6.52: Loss = 0.279434
Epoch 6.53: Loss = 0.255951
Epoch 6.54: Loss = 0.279846
Epoch 6.55: Loss = 0.25061
Epoch 6.56: Loss = 0.298767
Epoch 6.57: Loss = 0.231461
Epoch 6.58: Loss = 0.261047
Epoch 6.59: Loss = 0.275757
Epoch 6.60: Loss = 0.266174
Epoch 6.61: Loss = 0.240234
Epoch 6.62: Loss = 0.242493
Epoch 6.63: Loss = 0.24855
Epoch 6.64: Loss = 0.259598
Epoch 6.65: Loss = 0.250046
Epoch 6.66: Loss = 0.299942
Epoch 6.67: Loss = 0.294662
Epoch 6.68: Loss = 0.254654
Epoch 6.69: Loss = 0.289169
Epoch 6.70: Loss = 0.304916
Epoch 6.71: Loss = 0.271545
Epoch 6.72: Loss = 0.233795
Epoch 6.73: Loss = 0.263962
Epoch 6.74: Loss = 0.245255
Epoch 6.75: Loss = 0.30481
Epoch 6.76: Loss = 0.268097
Epoch 6.77: Loss = 0.273071
Epoch 6.78: Loss = 0.256241
Epoch 6.79: Loss = 0.235931
Epoch 6.80: Loss = 0.284683
Epoch 6.81: Loss = 0.249863
Epoch 6.82: Loss = 0.268127
Epoch 6.83: Loss = 0.323105
Epoch 6.84: Loss = 0.220917
Epoch 6.85: Loss = 0.264038
Epoch 6.86: Loss = 0.240433
Epoch 6.87: Loss = 0.214767
Epoch 6.88: Loss = 0.299774
Epoch 6.89: Loss = 0.235672
Epoch 6.90: Loss = 0.248795
Epoch 6.91: Loss = 0.270538
Epoch 6.92: Loss = 0.235001
Epoch 6.93: Loss = 0.236191
Epoch 6.94: Loss = 0.284103
Epoch 6.95: Loss = 0.244141
Epoch 6.96: Loss = 0.232925
Epoch 6.97: Loss = 0.254745
Epoch 6.98: Loss = 0.227615
Epoch 6.99: Loss = 0.262726
Epoch 6.100: Loss = 0.287079
TRAIN LOSS = 0.265305
TRAIN ACC = 92.6407 % (55588/60000)
Loss = 0.266785
Loss = 0.292435
Loss = 0.39505
Loss = 0.370728
Loss = 0.271469
Loss = 0.275604
Loss = 0.375687
Loss = 0.309418
Loss = 0.224533
Loss = 0.193298
Loss = 0.220901
Loss = 0.169785
Loss = 0.126511
Loss = 0.194443
Loss = 0.055069
Loss = 0.15657
Loss = 0.389297
TEST LOSS = 0.249469
TEST ACC = 555.879 % (9315/10000)
Reducing learning rate to 0.0666809
Epoch 7.1: Loss = 0.221146
Epoch 7.2: Loss = 0.233185
Epoch 7.3: Loss = 0.265579
Epoch 7.4: Loss = 0.224304
Epoch 7.5: Loss = 0.234695
Epoch 7.6: Loss = 0.251816
Epoch 7.7: Loss = 0.235336
Epoch 7.8: Loss = 0.23233
Epoch 7.9: Loss = 0.297302
Epoch 7.10: Loss = 0.312698
Epoch 7.11: Loss = 0.271942
Epoch 7.12: Loss = 0.245224
Epoch 7.13: Loss = 0.221176
Epoch 7.14: Loss = 0.237045
Epoch 7.15: Loss = 0.263458
Epoch 7.16: Loss = 0.212448
Epoch 7.17: Loss = 0.237823
Epoch 7.18: Loss = 0.255539
Epoch 7.19: Loss = 0.18985
Epoch 7.20: Loss = 0.241653
Epoch 7.21: Loss = 0.274719
Epoch 7.22: Loss = 0.22966
Epoch 7.23: Loss = 0.309555
Epoch 7.24: Loss = 0.250122
Epoch 7.25: Loss = 0.246429
Epoch 7.26: Loss = 0.24411
Epoch 7.27: Loss = 0.22612
Epoch 7.28: Loss = 0.224472
Epoch 7.29: Loss = 0.289413
Epoch 7.30: Loss = 0.253525
Epoch 7.31: Loss = 0.218277
Epoch 7.32: Loss = 0.261536
Epoch 7.33: Loss = 0.27095
Epoch 7.34: Loss = 0.220123
Epoch 7.35: Loss = 0.265778
Epoch 7.36: Loss = 0.294708
Epoch 7.37: Loss = 0.308533
Epoch 7.38: Loss = 0.199387
Epoch 7.39: Loss = 0.281357
Epoch 7.40: Loss = 0.23204
Epoch 7.41: Loss = 0.267212
Epoch 7.42: Loss = 0.28067
Epoch 7.43: Loss = 0.259888
Epoch 7.44: Loss = 0.305496
Epoch 7.45: Loss = 0.250381
Epoch 7.46: Loss = 0.238983
Epoch 7.47: Loss = 0.23204
Epoch 7.48: Loss = 0.236176
Epoch 7.49: Loss = 0.281952
Epoch 7.50: Loss = 0.290344
Epoch 7.51: Loss = 0.263931
Epoch 7.52: Loss = 0.303802
Epoch 7.53: Loss = 0.282089
Epoch 7.54: Loss = 0.256943
Epoch 7.55: Loss = 0.312469
Epoch 7.56: Loss = 0.302994
Epoch 7.57: Loss = 0.235809
Epoch 7.58: Loss = 0.266312
Epoch 7.59: Loss = 0.238525
Epoch 7.60: Loss = 0.23175
Epoch 7.61: Loss = 0.231445
Epoch 7.62: Loss = 0.265305
Epoch 7.63: Loss = 0.258286
Epoch 7.64: Loss = 0.262604
Epoch 7.65: Loss = 0.220535
Epoch 7.66: Loss = 0.250168
Epoch 7.67: Loss = 0.227676
Epoch 7.68: Loss = 0.230988
Epoch 7.69: Loss = 0.215118
Epoch 7.70: Loss = 0.239059
Epoch 7.71: Loss = 0.236526
Epoch 7.72: Loss = 0.23436
Epoch 7.73: Loss = 0.258011
Epoch 7.74: Loss = 0.265671
Epoch 7.75: Loss = 0.2314
Epoch 7.76: Loss = 0.220657
Epoch 7.77: Loss = 0.247452
Epoch 7.78: Loss = 0.30751
Epoch 7.79: Loss = 0.248947
Epoch 7.80: Loss = 0.227417
Epoch 7.81: Loss = 0.241348
Epoch 7.82: Loss = 0.229416
Epoch 7.83: Loss = 0.217102
Epoch 7.84: Loss = 0.250305
Epoch 7.85: Loss = 0.227463
Epoch 7.86: Loss = 0.267456
Epoch 7.87: Loss = 0.23584
Epoch 7.88: Loss = 0.27562
Epoch 7.89: Loss = 0.223999
Epoch 7.90: Loss = 0.270203
Epoch 7.91: Loss = 0.275803
Epoch 7.92: Loss = 0.213623
Epoch 7.93: Loss = 0.273605
Epoch 7.94: Loss = 0.288956
Epoch 7.95: Loss = 0.282486
Epoch 7.96: Loss = 0.270859
Epoch 7.97: Loss = 0.231262
Epoch 7.98: Loss = 0.300201
Epoch 7.99: Loss = 0.278534
Epoch 7.100: Loss = 0.243622
TRAIN LOSS = 0.253021
TRAIN ACC = 92.9871 % (55795/60000)
Loss = 0.254898
Loss = 0.290283
Loss = 0.385132
Loss = 0.364014
Loss = 0.259201
Loss = 0.271072
Loss = 0.364395
Loss = 0.296844
Loss = 0.212036
Loss = 0.19632
Loss = 0.204132
Loss = 0.154358
Loss = 0.119263
Loss = 0.178055
Loss = 0.0527344
Loss = 0.149887
Loss = 0.369156
TEST LOSS = 0.239924
TEST ACC = 557.948 % (9340/10000)
Reducing learning rate to 0.0611267
Epoch 8.1: Loss = 0.25145
Epoch 8.2: Loss = 0.237976
Epoch 8.3: Loss = 0.294418
Epoch 8.4: Loss = 0.240097
Epoch 8.5: Loss = 0.280945
Epoch 8.6: Loss = 0.308105
Epoch 8.7: Loss = 0.222824
Epoch 8.8: Loss = 0.264847
Epoch 8.9: Loss = 0.252579
Epoch 8.10: Loss = 0.214874
Epoch 8.11: Loss = 0.200928
Epoch 8.12: Loss = 0.226852
Epoch 8.13: Loss = 0.22757
Epoch 8.14: Loss = 0.205246
Epoch 8.15: Loss = 0.257278
Epoch 8.16: Loss = 0.258301
Epoch 8.17: Loss = 0.242401
Epoch 8.18: Loss = 0.26976
Epoch 8.19: Loss = 0.181198
Epoch 8.20: Loss = 0.229218
Epoch 8.21: Loss = 0.259674
Epoch 8.22: Loss = 0.198441
Epoch 8.23: Loss = 0.261765
Epoch 8.24: Loss = 0.2146
Epoch 8.25: Loss = 0.184052
Epoch 8.26: Loss = 0.263077
Epoch 8.27: Loss = 0.290054
Epoch 8.28: Loss = 0.213516
Epoch 8.29: Loss = 0.214386
Epoch 8.30: Loss = 0.243103
Epoch 8.31: Loss = 0.201096
Epoch 8.32: Loss = 0.279053
Epoch 8.33: Loss = 0.243301
Epoch 8.34: Loss = 0.281006
Epoch 8.35: Loss = 0.209732
Epoch 8.36: Loss = 0.256409
Epoch 8.37: Loss = 0.240128
Epoch 8.38: Loss = 0.224182
Epoch 8.39: Loss = 0.223221
Epoch 8.40: Loss = 0.231964
Epoch 8.41: Loss = 0.231339
Epoch 8.42: Loss = 0.219254
Epoch 8.43: Loss = 0.267776
Epoch 8.44: Loss = 0.271255
Epoch 8.45: Loss = 0.308289
Epoch 8.46: Loss = 0.203079
Epoch 8.47: Loss = 0.264343
Epoch 8.48: Loss = 0.214676
Epoch 8.49: Loss = 0.25647
Epoch 8.50: Loss = 0.195877
Epoch 8.51: Loss = 0.274567
Epoch 8.52: Loss = 0.274658
Epoch 8.53: Loss = 0.217484
Epoch 8.54: Loss = 0.246841
Epoch 8.55: Loss = 0.265747
Epoch 8.56: Loss = 0.22316
Epoch 8.57: Loss = 0.299545
Epoch 8.58: Loss = 0.250717
Epoch 8.59: Loss = 0.21875
Epoch 8.60: Loss = 0.232727
Epoch 8.61: Loss = 0.25412
Epoch 8.62: Loss = 0.257629
Epoch 8.63: Loss = 0.224396
Epoch 8.64: Loss = 0.29245
Epoch 8.65: Loss = 0.246033
Epoch 8.66: Loss = 0.23172
Epoch 8.67: Loss = 0.278259
Epoch 8.68: Loss = 0.260651
Epoch 8.69: Loss = 0.244675
Epoch 8.70: Loss = 0.271347
Epoch 8.71: Loss = 0.235596
Epoch 8.72: Loss = 0.260452
Epoch 8.73: Loss = 0.218307
Epoch 8.74: Loss = 0.208801
Epoch 8.75: Loss = 0.236938
Epoch 8.76: Loss = 0.23645
Epoch 8.77: Loss = 0.199692
Epoch 8.78: Loss = 0.236877
Epoch 8.79: Loss = 0.300018
Epoch 8.80: Loss = 0.200729
Epoch 8.81: Loss = 0.23143
Epoch 8.82: Loss = 0.243805
Epoch 8.83: Loss = 0.256653
Epoch 8.84: Loss = 0.259613
Epoch 8.85: Loss = 0.196518
Epoch 8.86: Loss = 0.261658
Epoch 8.87: Loss = 0.23436
Epoch 8.88: Loss = 0.259552
Epoch 8.89: Loss = 0.232498
Epoch 8.90: Loss = 0.241592
Epoch 8.91: Loss = 0.206665
Epoch 8.92: Loss = 0.229401
Epoch 8.93: Loss = 0.24025
Epoch 8.94: Loss = 0.244797
Epoch 8.95: Loss = 0.239349
Epoch 8.96: Loss = 0.231125
Epoch 8.97: Loss = 0.211517
Epoch 8.98: Loss = 0.254379
Epoch 8.99: Loss = 0.307098
Epoch 8.100: Loss = 0.277603
TRAIN LOSS = 0.242905
TRAIN ACC = 93.2953 % (55979/60000)
Loss = 0.24501
Loss = 0.278671
Loss = 0.369522
Loss = 0.350815
Loss = 0.252197
Loss = 0.259766
Loss = 0.355453
Loss = 0.286728
Loss = 0.204453
Loss = 0.186432
Loss = 0.205276
Loss = 0.146545
Loss = 0.111877
Loss = 0.174545
Loss = 0.0488129
Loss = 0.147186
Loss = 0.365982
TEST LOSS = 0.232037
TEST ACC = 559.789 % (9362/10000)
Reducing learning rate to 0.0555725
Epoch 9.1: Loss = 0.235519
Epoch 9.2: Loss = 0.225937
Epoch 9.3: Loss = 0.222397
Epoch 9.4: Loss = 0.280197
Epoch 9.5: Loss = 0.282578
Epoch 9.6: Loss = 0.205978
Epoch 9.7: Loss = 0.234695
Epoch 9.8: Loss = 0.232773
Epoch 9.9: Loss = 0.205597
Epoch 9.10: Loss = 0.247253
Epoch 9.11: Loss = 0.26738
Epoch 9.12: Loss = 0.276123
Epoch 9.13: Loss = 0.209702
Epoch 9.14: Loss = 0.247482
Epoch 9.15: Loss = 0.249588
Epoch 9.16: Loss = 0.220383
Epoch 9.17: Loss = 0.280777
Epoch 9.18: Loss = 0.258606
Epoch 9.19: Loss = 0.273895
Epoch 9.20: Loss = 0.248367
Epoch 9.21: Loss = 0.207794
Epoch 9.22: Loss = 0.217834
Epoch 9.23: Loss = 0.261826
Epoch 9.24: Loss = 0.253998
Epoch 9.25: Loss = 0.274353
Epoch 9.26: Loss = 0.235611
Epoch 9.27: Loss = 0.216095
Epoch 9.28: Loss = 0.221191
Epoch 9.29: Loss = 0.237869
Epoch 9.30: Loss = 0.238907
Epoch 9.31: Loss = 0.207947
Epoch 9.32: Loss = 0.212875
Epoch 9.33: Loss = 0.265549
Epoch 9.34: Loss = 0.229416
Epoch 9.35: Loss = 0.237976
Epoch 9.36: Loss = 0.234146
Epoch 9.37: Loss = 0.228668
Epoch 9.38: Loss = 0.225677
Epoch 9.39: Loss = 0.258331
Epoch 9.40: Loss = 0.190323
Epoch 9.41: Loss = 0.254776
Epoch 9.42: Loss = 0.209869
Epoch 9.43: Loss = 0.18811
Epoch 9.44: Loss = 0.261887
Epoch 9.45: Loss = 0.263565
Epoch 9.46: Loss = 0.239456
Epoch 9.47: Loss = 0.296448
Epoch 9.48: Loss = 0.221634
Epoch 9.49: Loss = 0.260925
Epoch 9.50: Loss = 0.245255
Epoch 9.51: Loss = 0.210373
Epoch 9.52: Loss = 0.249298
Epoch 9.53: Loss = 0.223679
Epoch 9.54: Loss = 0.273682
Epoch 9.55: Loss = 0.188522
Epoch 9.56: Loss = 0.317795
Epoch 9.57: Loss = 0.260559
Epoch 9.58: Loss = 0.222778
Epoch 9.59: Loss = 0.203644
Epoch 9.60: Loss = 0.21814
Epoch 9.61: Loss = 0.263672
Epoch 9.62: Loss = 0.231522
Epoch 9.63: Loss = 0.216888
Epoch 9.64: Loss = 0.244644
Epoch 9.65: Loss = 0.214264
Epoch 9.66: Loss = 0.20787
Epoch 9.67: Loss = 0.249451
Epoch 9.68: Loss = 0.184601
Epoch 9.69: Loss = 0.239151
Epoch 9.70: Loss = 0.230286
Epoch 9.71: Loss = 0.230881
Epoch 9.72: Loss = 0.184174
Epoch 9.73: Loss = 0.226868
Epoch 9.74: Loss = 0.244125
Epoch 9.75: Loss = 0.238739
Epoch 9.76: Loss = 0.257187
Epoch 9.77: Loss = 0.205582
Epoch 9.78: Loss = 0.220612
Epoch 9.79: Loss = 0.225021
Epoch 9.80: Loss = 0.231339
Epoch 9.81: Loss = 0.250259
Epoch 9.82: Loss = 0.240738
Epoch 9.83: Loss = 0.278549
Epoch 9.84: Loss = 0.214569
Epoch 9.85: Loss = 0.221802
Epoch 9.86: Loss = 0.235199
Epoch 9.87: Loss = 0.197861
Epoch 9.88: Loss = 0.201294
Epoch 9.89: Loss = 0.253265
Epoch 9.90: Loss = 0.238708
Epoch 9.91: Loss = 0.204529
Epoch 9.92: Loss = 0.250946
Epoch 9.93: Loss = 0.226105
Epoch 9.94: Loss = 0.216751
Epoch 9.95: Loss = 0.182983
Epoch 9.96: Loss = 0.167252
Epoch 9.97: Loss = 0.236053
Epoch 9.98: Loss = 0.235809
Epoch 9.99: Loss = 0.238724
Epoch 9.100: Loss = 0.223633
TRAIN LOSS = 0.234329
TRAIN ACC = 93.512 % (56109/60000)
Loss = 0.235458
Loss = 0.273697
Loss = 0.36145
Loss = 0.340195
Loss = 0.242401
Loss = 0.251007
Loss = 0.342575
Loss = 0.276688
Loss = 0.195908
Loss = 0.185318
Loss = 0.198288
Loss = 0.139252
Loss = 0.108612
Loss = 0.173813
Loss = 0.0480042
Loss = 0.143585
Loss = 0.351089
TEST LOSS = 0.225019
TEST ACC = 561.089 % (9381/10000)
Reducing learning rate to 0.0500183
Epoch 10.1: Loss = 0.244553
Epoch 10.2: Loss = 0.287277
Epoch 10.3: Loss = 0.215256
Epoch 10.4: Loss = 0.207993
Epoch 10.5: Loss = 0.24382
Epoch 10.6: Loss = 0.201477
Epoch 10.7: Loss = 0.263474
Epoch 10.8: Loss = 0.249481
Epoch 10.9: Loss = 0.235077
Epoch 10.10: Loss = 0.22197
Epoch 10.11: Loss = 0.260101
Epoch 10.12: Loss = 0.24292
Epoch 10.13: Loss = 0.224487
Epoch 10.14: Loss = 0.207825
Epoch 10.15: Loss = 0.253891
Epoch 10.16: Loss = 0.215973
Epoch 10.17: Loss = 0.214706
Epoch 10.18: Loss = 0.276962
Epoch 10.19: Loss = 0.228348
Epoch 10.20: Loss = 0.216736
Epoch 10.21: Loss = 0.238983
Epoch 10.22: Loss = 0.252502
Epoch 10.23: Loss = 0.252655
Epoch 10.24: Loss = 0.220932
Epoch 10.25: Loss = 0.258926
Epoch 10.26: Loss = 0.232254
Epoch 10.27: Loss = 0.20961
Epoch 10.28: Loss = 0.245911
Epoch 10.29: Loss = 0.205856
Epoch 10.30: Loss = 0.202393
Epoch 10.31: Loss = 0.242737
Epoch 10.32: Loss = 0.247192
Epoch 10.33: Loss = 0.227356
Epoch 10.34: Loss = 0.23584
Epoch 10.35: Loss = 0.229507
Epoch 10.36: Loss = 0.220169
Epoch 10.37: Loss = 0.188141
Epoch 10.38: Loss = 0.208344
Epoch 10.39: Loss = 0.270523
Epoch 10.40: Loss = 0.200867
Epoch 10.41: Loss = 0.249283
Epoch 10.42: Loss = 0.273666
Epoch 10.43: Loss = 0.223282
Epoch 10.44: Loss = 0.193954
Epoch 10.45: Loss = 0.173111
Epoch 10.46: Loss = 0.211731
Epoch 10.47: Loss = 0.238937
Epoch 10.48: Loss = 0.18956
Epoch 10.49: Loss = 0.243515
Epoch 10.50: Loss = 0.203644
Epoch 10.51: Loss = 0.218445
Epoch 10.52: Loss = 0.245804
Epoch 10.53: Loss = 0.206757
Epoch 10.54: Loss = 0.288544
Epoch 10.55: Loss = 0.198776
Epoch 10.56: Loss = 0.297638
Epoch 10.57: Loss = 0.223495
Epoch 10.58: Loss = 0.229019
Epoch 10.59: Loss = 0.230301
Epoch 10.60: Loss = 0.220596
Epoch 10.61: Loss = 0.236923
Epoch 10.62: Loss = 0.258408
Epoch 10.63: Loss = 0.226532
Epoch 10.64: Loss = 0.177902
Epoch 10.65: Loss = 0.189499
Epoch 10.66: Loss = 0.20607
Epoch 10.67: Loss = 0.244293
Epoch 10.68: Loss = 0.225983
Epoch 10.69: Loss = 0.193314
Epoch 10.70: Loss = 0.240524
Epoch 10.71: Loss = 0.211487
Epoch 10.72: Loss = 0.206207
Epoch 10.73: Loss = 0.206757
Epoch 10.74: Loss = 0.250549
Epoch 10.75: Loss = 0.203491
Epoch 10.76: Loss = 0.193268
Epoch 10.77: Loss = 0.23584
Epoch 10.78: Loss = 0.192856
Epoch 10.79: Loss = 0.179245
Epoch 10.80: Loss = 0.21814
Epoch 10.81: Loss = 0.288422
Epoch 10.82: Loss = 0.211105
Epoch 10.83: Loss = 0.216782
Epoch 10.84: Loss = 0.244736
Epoch 10.85: Loss = 0.257751
Epoch 10.86: Loss = 0.231827
Epoch 10.87: Loss = 0.233978
Epoch 10.88: Loss = 0.250351
Epoch 10.89: Loss = 0.266907
Epoch 10.90: Loss = 0.228012
Epoch 10.91: Loss = 0.235016
Epoch 10.92: Loss = 0.229538
Epoch 10.93: Loss = 0.267929
Epoch 10.94: Loss = 0.197067
Epoch 10.95: Loss = 0.185394
Epoch 10.96: Loss = 0.16214
Epoch 10.97: Loss = 0.179398
Epoch 10.98: Loss = 0.19429
Epoch 10.99: Loss = 0.289246
Epoch 10.100: Loss = 0.205627
TRAIN LOSS = 0.227356
TRAIN ACC = 93.7271 % (56238/60000)
Loss = 0.230362
Loss = 0.264572
Loss = 0.354034
Loss = 0.333603
Loss = 0.235611
Loss = 0.245758
Loss = 0.335281
Loss = 0.271179
Loss = 0.194855
Loss = 0.177521
Loss = 0.19603
Loss = 0.136353
Loss = 0.103012
Loss = 0.166977
Loss = 0.0461426
Loss = 0.137833
Loss = 0.348358
TEST LOSS = 0.219682
TEST ACC = 562.379 % (9380/10000)
Epoch 11.1: Loss = 0.216629
Epoch 11.2: Loss = 0.234665
Epoch 11.3: Loss = 0.248322
Epoch 11.4: Loss = 0.242447
Epoch 11.5: Loss = 0.194214
Epoch 11.6: Loss = 0.213837
Epoch 11.7: Loss = 0.218765
Epoch 11.8: Loss = 0.225677
Epoch 11.9: Loss = 0.18222
Epoch 11.10: Loss = 0.26207
Epoch 11.11: Loss = 0.251282
Epoch 11.12: Loss = 0.220718
Epoch 11.13: Loss = 0.181732
Epoch 11.14: Loss = 0.19519
Epoch 11.15: Loss = 0.281372
Epoch 11.16: Loss = 0.254868
Epoch 11.17: Loss = 0.221436
Epoch 11.18: Loss = 0.240692
Epoch 11.19: Loss = 0.179626
Epoch 11.20: Loss = 0.225327
Epoch 11.21: Loss = 0.253784
Epoch 11.22: Loss = 0.23056
Epoch 11.23: Loss = 0.267059
Epoch 11.24: Loss = 0.181854
Epoch 11.25: Loss = 0.23558
Epoch 11.26: Loss = 0.244202
Epoch 11.27: Loss = 0.185822
Epoch 11.28: Loss = 0.250519
Epoch 11.29: Loss = 0.204453
Epoch 11.30: Loss = 0.202438
Epoch 11.31: Loss = 0.198105
Epoch 11.32: Loss = 0.23764
Epoch 11.33: Loss = 0.259384
Epoch 11.34: Loss = 0.196808
Epoch 11.35: Loss = 0.21524
Epoch 11.36: Loss = 0.204803
Epoch 11.37: Loss = 0.263336
Epoch 11.38: Loss = 0.179764
Epoch 11.39: Loss = 0.238205
Epoch 11.40: Loss = 0.250336
Epoch 11.41: Loss = 0.234299
Epoch 11.42: Loss = 0.208694
Epoch 11.43: Loss = 0.255783
Epoch 11.44: Loss = 0.252899
Epoch 11.45: Loss = 0.230179
Epoch 11.46: Loss = 0.219864
Epoch 11.47: Loss = 0.261002
Epoch 11.48: Loss = 0.222809
Epoch 11.49: Loss = 0.24762
Epoch 11.50: Loss = 0.258316
Epoch 11.51: Loss = 0.208817
Epoch 11.52: Loss = 0.249191
Epoch 11.53: Loss = 0.199203
Epoch 11.54: Loss = 0.242752
Epoch 11.55: Loss = 0.202957
Epoch 11.56: Loss = 0.15683
Epoch 11.57: Loss = 0.228699
Epoch 11.58: Loss = 0.205414
Epoch 11.59: Loss = 0.184479
Epoch 11.60: Loss = 0.178467
Epoch 11.61: Loss = 0.208511
Epoch 11.62: Loss = 0.21077
Epoch 11.63: Loss = 0.223587
Epoch 11.64: Loss = 0.265457
Epoch 11.65: Loss = 0.293488
Epoch 11.66: Loss = 0.236267
Epoch 11.67: Loss = 0.232773
Epoch 11.68: Loss = 0.179306
Epoch 11.69: Loss = 0.212875
Epoch 11.70: Loss = 0.264099
Epoch 11.71: Loss = 0.198853
Epoch 11.72: Loss = 0.18457
Epoch 11.73: Loss = 0.229721
Epoch 11.74: Loss = 0.197571
Epoch 11.75: Loss = 0.187775
Epoch 11.76: Loss = 0.237625
Epoch 11.77: Loss = 0.229858
Epoch 11.78: Loss = 0.22139
Epoch 11.79: Loss = 0.212662
Epoch 11.80: Loss = 0.203506
Epoch 11.81: Loss = 0.185425
Epoch 11.82: Loss = 0.231186
Epoch 11.83: Loss = 0.249954
Epoch 11.84: Loss = 0.221817
Epoch 11.85: Loss = 0.230469
Epoch 11.86: Loss = 0.222015
Epoch 11.87: Loss = 0.216156
Epoch 11.88: Loss = 0.154373
Epoch 11.89: Loss = 0.238937
Epoch 11.90: Loss = 0.206512
Epoch 11.91: Loss = 0.220947
Epoch 11.92: Loss = 0.201736
Epoch 11.93: Loss = 0.245697
Epoch 11.94: Loss = 0.218307
Epoch 11.95: Loss = 0.233231
Epoch 11.96: Loss = 0.252365
Epoch 11.97: Loss = 0.198669
Epoch 11.98: Loss = 0.16777
Epoch 11.99: Loss = 0.236969
Epoch 11.100: Loss = 0.184708
TRAIN LOSS = 0.221863
TRAIN ACC = 93.9026 % (56345/60000)
Loss = 0.224091
Loss = 0.259048
Loss = 0.346786
Loss = 0.32811
Loss = 0.231461
Loss = 0.239944
Loss = 0.33139
Loss = 0.265793
Loss = 0.188293
Loss = 0.174927
Loss = 0.191238
Loss = 0.132278
Loss = 0.100769
Loss = 0.159698
Loss = 0.0449829
Loss = 0.135056
Loss = 0.340332
TEST LOSS = 0.214845
TEST ACC = 563.449 % (9397/10000)
Epoch 12.1: Loss = 0.170959
Epoch 12.2: Loss = 0.197525
Epoch 12.3: Loss = 0.227203
Epoch 12.4: Loss = 0.185623
Epoch 12.5: Loss = 0.205811
Epoch 12.6: Loss = 0.22403
Epoch 12.7: Loss = 0.209747
Epoch 12.8: Loss = 0.284927
Epoch 12.9: Loss = 0.17865
Epoch 12.10: Loss = 0.165894
Epoch 12.11: Loss = 0.221298
Epoch 12.12: Loss = 0.180206
Epoch 12.13: Loss = 0.266388
Epoch 12.14: Loss = 0.233368
Epoch 12.15: Loss = 0.221954
Epoch 12.16: Loss = 0.223816
Epoch 12.17: Loss = 0.230057
Epoch 12.18: Loss = 0.178421
Epoch 12.19: Loss = 0.206604
Epoch 12.20: Loss = 0.202728
Epoch 12.21: Loss = 0.185303
Epoch 12.22: Loss = 0.190063
Epoch 12.23: Loss = 0.218231
Epoch 12.24: Loss = 0.265823
Epoch 12.25: Loss = 0.277023
Epoch 12.26: Loss = 0.18689
Epoch 12.27: Loss = 0.227997
Epoch 12.28: Loss = 0.196167
Epoch 12.29: Loss = 0.235611
Epoch 12.30: Loss = 0.22731
Epoch 12.31: Loss = 0.185333
Epoch 12.32: Loss = 0.210922
Epoch 12.33: Loss = 0.223846
Epoch 12.34: Loss = 0.174576
Epoch 12.35: Loss = 0.226715
Epoch 12.36: Loss = 0.231308
Epoch 12.37: Loss = 0.234451
Epoch 12.38: Loss = 0.193344
Epoch 12.39: Loss = 0.162903
Epoch 12.40: Loss = 0.211838
Epoch 12.41: Loss = 0.255829
Epoch 12.42: Loss = 0.19516
Epoch 12.43: Loss = 0.241882
Epoch 12.44: Loss = 0.192429
Epoch 12.45: Loss = 0.277161
Epoch 12.46: Loss = 0.194916
Epoch 12.47: Loss = 0.230362
Epoch 12.48: Loss = 0.207428
Epoch 12.49: Loss = 0.23262
Epoch 12.50: Loss = 0.230179
Epoch 12.51: Loss = 0.221146
Epoch 12.52: Loss = 0.23465
Epoch 12.53: Loss = 0.218002
Epoch 12.54: Loss = 0.221619
Epoch 12.55: Loss = 0.231781
Epoch 12.56: Loss = 0.221573
Epoch 12.57: Loss = 0.188217
Epoch 12.58: Loss = 0.237869
Epoch 12.59: Loss = 0.189362
Epoch 12.60: Loss = 0.233826
Epoch 12.61: Loss = 0.289337
Epoch 12.62: Loss = 0.189835
Epoch 12.63: Loss = 0.258896
Epoch 12.64: Loss = 0.272873
Epoch 12.65: Loss = 0.224258
Epoch 12.66: Loss = 0.171967
Epoch 12.67: Loss = 0.190079
Epoch 12.68: Loss = 0.221039
Epoch 12.69: Loss = 0.216125
Epoch 12.70: Loss = 0.256592
Epoch 12.71: Loss = 0.244568
Epoch 12.72: Loss = 0.186035
Epoch 12.73: Loss = 0.274048
Epoch 12.74: Loss = 0.210587
Epoch 12.75: Loss = 0.228699
Epoch 12.76: Loss = 0.266891
Epoch 12.77: Loss = 0.171921
Epoch 12.78: Loss = 0.240936
Epoch 12.79: Loss = 0.212646
Epoch 12.80: Loss = 0.219803
Epoch 12.81: Loss = 0.208099
Epoch 12.82: Loss = 0.21817
Epoch 12.83: Loss = 0.245499
Epoch 12.84: Loss = 0.156509
Epoch 12.85: Loss = 0.161499
Epoch 12.86: Loss = 0.231522
Epoch 12.87: Loss = 0.196899
Epoch 12.88: Loss = 0.160141
Epoch 12.89: Loss = 0.187485
Epoch 12.90: Loss = 0.230576
Epoch 12.91: Loss = 0.21376
Epoch 12.92: Loss = 0.196075
Epoch 12.93: Loss = 0.209122
Epoch 12.94: Loss = 0.212219
Epoch 12.95: Loss = 0.220627
Epoch 12.96: Loss = 0.23201
Epoch 12.97: Loss = 0.199493
Epoch 12.98: Loss = 0.213913
Epoch 12.99: Loss = 0.279007
Epoch 12.100: Loss = 0.192276
TRAIN LOSS = 0.216492
TRAIN ACC = 94.0048 % (56405/60000)
Loss = 0.2202
Loss = 0.253189
Loss = 0.341141
Loss = 0.322372
Loss = 0.226166
Loss = 0.235229
Loss = 0.326019
Loss = 0.260834
Loss = 0.185287
Loss = 0.170319
Loss = 0.188293
Loss = 0.129364
Loss = 0.0978088
Loss = 0.154327
Loss = 0.0440979
Loss = 0.131287
Loss = 0.339157
TEST LOSS = 0.210722
TEST ACC = 564.049 % (9412/10000)
Epoch 13.1: Loss = 0.218658
Epoch 13.2: Loss = 0.22673
Epoch 13.3: Loss = 0.190735
Epoch 13.4: Loss = 0.205872
Epoch 13.5: Loss = 0.240417
Epoch 13.6: Loss = 0.189865
Epoch 13.7: Loss = 0.226532
Epoch 13.8: Loss = 0.262177
Epoch 13.9: Loss = 0.204941
Epoch 13.10: Loss = 0.216293
Epoch 13.11: Loss = 0.188034
Epoch 13.12: Loss = 0.272034
Epoch 13.13: Loss = 0.179962
Epoch 13.14: Loss = 0.20723
Epoch 13.15: Loss = 0.227905
Epoch 13.16: Loss = 0.189819
Epoch 13.17: Loss = 0.166229
Epoch 13.18: Loss = 0.163788
Epoch 13.19: Loss = 0.159348
Epoch 13.20: Loss = 0.203522
Epoch 13.21: Loss = 0.234604
Epoch 13.22: Loss = 0.18988
Epoch 13.23: Loss = 0.183472
Epoch 13.24: Loss = 0.193954
Epoch 13.25: Loss = 0.241531
Epoch 13.26: Loss = 0.250198
Epoch 13.27: Loss = 0.177063
Epoch 13.28: Loss = 0.194321
Epoch 13.29: Loss = 0.242416
Epoch 13.30: Loss = 0.195129
Epoch 13.31: Loss = 0.192184
Epoch 13.32: Loss = 0.229691
Epoch 13.33: Loss = 0.212326
Epoch 13.34: Loss = 0.18483
Epoch 13.35: Loss = 0.229263
Epoch 13.36: Loss = 0.195602
Epoch 13.37: Loss = 0.170761
Epoch 13.38: Loss = 0.216293
Epoch 13.39: Loss = 0.181885
Epoch 13.40: Loss = 0.204697
Epoch 13.41: Loss = 0.164795
Epoch 13.42: Loss = 0.176315
Epoch 13.43: Loss = 0.257034
Epoch 13.44: Loss = 0.198212
Epoch 13.45: Loss = 0.23233
Epoch 13.46: Loss = 0.248367
Epoch 13.47: Loss = 0.223389
Epoch 13.48: Loss = 0.227798
Epoch 13.49: Loss = 0.216141
Epoch 13.50: Loss = 0.20665
Epoch 13.51: Loss = 0.238953
Epoch 13.52: Loss = 0.169815
Epoch 13.53: Loss = 0.193161
Epoch 13.54: Loss = 0.228622
Epoch 13.55: Loss = 0.223373
Epoch 13.56: Loss = 0.203232
Epoch 13.57: Loss = 0.216599
Epoch 13.58: Loss = 0.19725
Epoch 13.59: Loss = 0.258682
Epoch 13.60: Loss = 0.188431
Epoch 13.61: Loss = 0.201202
Epoch 13.62: Loss = 0.218079
Epoch 13.63: Loss = 0.238281
Epoch 13.64: Loss = 0.26619
Epoch 13.65: Loss = 0.292191
Epoch 13.66: Loss = 0.228912
Epoch 13.67: Loss = 0.206985
Epoch 13.68: Loss = 0.251114
Epoch 13.69: Loss = 0.183304
Epoch 13.70: Loss = 0.225784
Epoch 13.71: Loss = 0.18277
Epoch 13.72: Loss = 0.226898
Epoch 13.73: Loss = 0.219116
Epoch 13.74: Loss = 0.301407
Epoch 13.75: Loss = 0.257843
Epoch 13.76: Loss = 0.17215
Epoch 13.77: Loss = 0.193878
Epoch 13.78: Loss = 0.220123
Epoch 13.79: Loss = 0.184143
Epoch 13.80: Loss = 0.180695
Epoch 13.81: Loss = 0.187546
Epoch 13.82: Loss = 0.203354
Epoch 13.83: Loss = 0.201721
Epoch 13.84: Loss = 0.200943
Epoch 13.85: Loss = 0.210922
Epoch 13.86: Loss = 0.253738
Epoch 13.87: Loss = 0.157745
Epoch 13.88: Loss = 0.210464
Epoch 13.89: Loss = 0.239243
Epoch 13.90: Loss = 0.181427
Epoch 13.91: Loss = 0.261597
Epoch 13.92: Loss = 0.146744
Epoch 13.93: Loss = 0.245331
Epoch 13.94: Loss = 0.199493
Epoch 13.95: Loss = 0.269073
Epoch 13.96: Loss = 0.21373
Epoch 13.97: Loss = 0.182312
Epoch 13.98: Loss = 0.191818
Epoch 13.99: Loss = 0.206451
Epoch 13.100: Loss = 0.195709
TRAIN LOSS = 0.211395
TRAIN ACC = 94.1498 % (56493/60000)
Loss = 0.214081
Loss = 0.247543
Loss = 0.333298
Loss = 0.315018
Loss = 0.222443
Loss = 0.23024
Loss = 0.321289
Loss = 0.255402
Loss = 0.183197
Loss = 0.165512
Loss = 0.188263
Loss = 0.12561
Loss = 0.0943909
Loss = 0.151535
Loss = 0.0421906
Loss = 0.130753
Loss = 0.331085
TEST LOSS = 0.206489
TEST ACC = 564.929 % (9414/10000)
Epoch 14.1: Loss = 0.189697
Epoch 14.2: Loss = 0.212357
Epoch 14.3: Loss = 0.205795
Epoch 14.4: Loss = 0.151291
Epoch 14.5: Loss = 0.201447
Epoch 14.6: Loss = 0.237259
Epoch 14.7: Loss = 0.19899
Epoch 14.8: Loss = 0.229599
Epoch 14.9: Loss = 0.184158
Epoch 14.10: Loss = 0.206421
Epoch 14.11: Loss = 0.218262
Epoch 14.12: Loss = 0.183105
Epoch 14.13: Loss = 0.220444
Epoch 14.14: Loss = 0.226242
Epoch 14.15: Loss = 0.226212
Epoch 14.16: Loss = 0.206268
Epoch 14.17: Loss = 0.184433
Epoch 14.18: Loss = 0.160873
Epoch 14.19: Loss = 0.243729
Epoch 14.20: Loss = 0.185135
Epoch 14.21: Loss = 0.241669
Epoch 14.22: Loss = 0.250214
Epoch 14.23: Loss = 0.208084
Epoch 14.24: Loss = 0.175003
Epoch 14.25: Loss = 0.175171
Epoch 14.26: Loss = 0.191467
Epoch 14.27: Loss = 0.237732
Epoch 14.28: Loss = 0.228302
Epoch 14.29: Loss = 0.183578
Epoch 14.30: Loss = 0.156616
Epoch 14.31: Loss = 0.190613
Epoch 14.32: Loss = 0.205048
Epoch 14.33: Loss = 0.222946
Epoch 14.34: Loss = 0.181946
Epoch 14.35: Loss = 0.215454
Epoch 14.36: Loss = 0.19017
Epoch 14.37: Loss = 0.16684
Epoch 14.38: Loss = 0.249512
Epoch 14.39: Loss = 0.1698
Epoch 14.40: Loss = 0.219742
Epoch 14.41: Loss = 0.248215
Epoch 14.42: Loss = 0.20874
Epoch 14.43: Loss = 0.182602
Epoch 14.44: Loss = 0.22142
Epoch 14.45: Loss = 0.251663
Epoch 14.46: Loss = 0.18956
Epoch 14.47: Loss = 0.206512
Epoch 14.48: Loss = 0.228683
Epoch 14.49: Loss = 0.218414
Epoch 14.50: Loss = 0.183121
Epoch 14.51: Loss = 0.20462
Epoch 14.52: Loss = 0.205826
Epoch 14.53: Loss = 0.195557
Epoch 14.54: Loss = 0.186829
Epoch 14.55: Loss = 0.216309
Epoch 14.56: Loss = 0.197906
Epoch 14.57: Loss = 0.181961
Epoch 14.58: Loss = 0.225754
Epoch 14.59: Loss = 0.237473
Epoch 14.60: Loss = 0.222351
Epoch 14.61: Loss = 0.22345
Epoch 14.62: Loss = 0.156769
Epoch 14.63: Loss = 0.187836
Epoch 14.64: Loss = 0.203171
Epoch 14.65: Loss = 0.181793
Epoch 14.66: Loss = 0.21254
Epoch 14.67: Loss = 0.199814
Epoch 14.68: Loss = 0.219055
Epoch 14.69: Loss = 0.201111
Epoch 14.70: Loss = 0.191879
Epoch 14.71: Loss = 0.227829
Epoch 14.72: Loss = 0.225479
Epoch 14.73: Loss = 0.184601
Epoch 14.74: Loss = 0.235626
Epoch 14.75: Loss = 0.161484
Epoch 14.76: Loss = 0.204132
Epoch 14.77: Loss = 0.223831
Epoch 14.78: Loss = 0.23407
Epoch 14.79: Loss = 0.221161
Epoch 14.80: Loss = 0.203979
Epoch 14.81: Loss = 0.286987
Epoch 14.82: Loss = 0.226318
Epoch 14.83: Loss = 0.202698
Epoch 14.84: Loss = 0.218292
Epoch 14.85: Loss = 0.172104
Epoch 14.86: Loss = 0.189102
Epoch 14.87: Loss = 0.19603
Epoch 14.88: Loss = 0.196671
Epoch 14.89: Loss = 0.202011
Epoch 14.90: Loss = 0.181992
Epoch 14.91: Loss = 0.173447
Epoch 14.92: Loss = 0.221405
Epoch 14.93: Loss = 0.234894
Epoch 14.94: Loss = 0.224442
Epoch 14.95: Loss = 0.201126
Epoch 14.96: Loss = 0.248932
Epoch 14.97: Loss = 0.204544
Epoch 14.98: Loss = 0.18483
Epoch 14.99: Loss = 0.243439
Epoch 14.100: Loss = 0.21611
TRAIN LOSS = 0.206711
TRAIN ACC = 94.3069 % (56587/60000)
Loss = 0.209244
Loss = 0.243622
Loss = 0.329453
Loss = 0.311218
Loss = 0.216934
Loss = 0.226273
Loss = 0.318085
Loss = 0.250427
Loss = 0.177887
Loss = 0.165115
Loss = 0.182114
Loss = 0.121078
Loss = 0.0924835
Loss = 0.142899
Loss = 0.042099
Loss = 0.126068
Loss = 0.324326
TEST LOSS = 0.202273
TEST ACC = 565.869 % (9438/10000)
Epoch 15.1: Loss = 0.151932
Epoch 15.2: Loss = 0.188034
Epoch 15.3: Loss = 0.177719
Epoch 15.4: Loss = 0.214478
Epoch 15.5: Loss = 0.212265
Epoch 15.6: Loss = 0.174133
Epoch 15.7: Loss = 0.204407
Epoch 15.8: Loss = 0.197128
Epoch 15.9: Loss = 0.197983
Epoch 15.10: Loss = 0.187378
Epoch 15.11: Loss = 0.152908
Epoch 15.12: Loss = 0.226974
Epoch 15.13: Loss = 0.20076
Epoch 15.14: Loss = 0.208008
Epoch 15.15: Loss = 0.194534
Epoch 15.16: Loss = 0.20108
Epoch 15.17: Loss = 0.19928
Epoch 15.18: Loss = 0.178574
Epoch 15.19: Loss = 0.155746
Epoch 15.20: Loss = 0.19603
Epoch 15.21: Loss = 0.2229
Epoch 15.22: Loss = 0.24826
Epoch 15.23: Loss = 0.206467
Epoch 15.24: Loss = 0.183762
Epoch 15.25: Loss = 0.201859
Epoch 15.26: Loss = 0.188644
Epoch 15.27: Loss = 0.260315
Epoch 15.28: Loss = 0.192062
Epoch 15.29: Loss = 0.155731
Epoch 15.30: Loss = 0.17598
Epoch 15.31: Loss = 0.208755
Epoch 15.32: Loss = 0.22847
Epoch 15.33: Loss = 0.212112
Epoch 15.34: Loss = 0.179581
Epoch 15.35: Loss = 0.220016
Epoch 15.36: Loss = 0.187958
Epoch 15.37: Loss = 0.207733
Epoch 15.38: Loss = 0.208145
Epoch 15.39: Loss = 0.237122
Epoch 15.40: Loss = 0.20871
Epoch 15.41: Loss = 0.201141
Epoch 15.42: Loss = 0.178665
Epoch 15.43: Loss = 0.159225
Epoch 15.44: Loss = 0.229034
Epoch 15.45: Loss = 0.210373
Epoch 15.46: Loss = 0.210724
Epoch 15.47: Loss = 0.206863
Epoch 15.48: Loss = 0.20903
Epoch 15.49: Loss = 0.216751
Epoch 15.50: Loss = 0.208511
Epoch 15.51: Loss = 0.224197
Epoch 15.52: Loss = 0.282608
Epoch 15.53: Loss = 0.191406
Epoch 15.54: Loss = 0.205048
Epoch 15.55: Loss = 0.18718
Epoch 15.56: Loss = 0.19162
Epoch 15.57: Loss = 0.214615
Epoch 15.58: Loss = 0.202881
Epoch 15.59: Loss = 0.182327
Epoch 15.60: Loss = 0.231689
Epoch 15.61: Loss = 0.216064
Epoch 15.62: Loss = 0.21666
Epoch 15.63: Loss = 0.182495
Epoch 15.64: Loss = 0.187515
Epoch 15.65: Loss = 0.222855
Epoch 15.66: Loss = 0.21521
Epoch 15.67: Loss = 0.182831
Epoch 15.68: Loss = 0.167404
Epoch 15.69: Loss = 0.252029
Epoch 15.70: Loss = 0.20462
Epoch 15.71: Loss = 0.187698
Epoch 15.72: Loss = 0.176285
Epoch 15.73: Loss = 0.195038
Epoch 15.74: Loss = 0.213608
Epoch 15.75: Loss = 0.143661
Epoch 15.76: Loss = 0.205521
Epoch 15.77: Loss = 0.196075
Epoch 15.78: Loss = 0.234863
Epoch 15.79: Loss = 0.200256
Epoch 15.80: Loss = 0.276138
Epoch 15.81: Loss = 0.210831
Epoch 15.82: Loss = 0.213455
Epoch 15.83: Loss = 0.189789
Epoch 15.84: Loss = 0.153915
Epoch 15.85: Loss = 0.206589
Epoch 15.86: Loss = 0.201523
Epoch 15.87: Loss = 0.207474
Epoch 15.88: Loss = 0.173401
Epoch 15.89: Loss = 0.192612
Epoch 15.90: Loss = 0.245087
Epoch 15.91: Loss = 0.184509
Epoch 15.92: Loss = 0.220444
Epoch 15.93: Loss = 0.206161
Epoch 15.94: Loss = 0.183899
Epoch 15.95: Loss = 0.17926
Epoch 15.96: Loss = 0.194229
Epoch 15.97: Loss = 0.240173
Epoch 15.98: Loss = 0.175064
Epoch 15.99: Loss = 0.228333
Epoch 15.100: Loss = 0.221115
TRAIN LOSS = 0.202026
TRAIN ACC = 94.4275 % (56659/60000)
Loss = 0.205276
Loss = 0.238998
Loss = 0.326157
Loss = 0.307373
Loss = 0.213028
Loss = 0.222687
Loss = 0.313995
Loss = 0.245804
Loss = 0.175491
Loss = 0.163406
Loss = 0.17952
Loss = 0.118011
Loss = 0.0899811
Loss = 0.135635
Loss = 0.0418549
Loss = 0.123642
Loss = 0.320099
TEST LOSS = 0.198856
TEST ACC = 566.589 % (9445/10000)
